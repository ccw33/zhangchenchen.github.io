<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Solar">
<meta property="og:url" content="https://zhangchenchen.github.io/page/3/index.html">
<meta property="og:site_name" content="Solar">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Solar">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhangchenchen.github.io/page/3/"/>





  <title> Solar </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-92407570-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Solar</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/08/17/kubernetes-authentication-authorization-admission-control/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/17/kubernetes-authentication-authorization-admission-control/" itemprop="url">
                  Kubernetes-- 漫谈kubernetes 中的认证 & 授权 & 准入机制
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-17T15:37:30+08:00">
                2017-08-17
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/08/17/kubernetes-authentication-authorization-admission-control/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/17/kubernetes-authentication-authorization-admission-control/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>首先需要了解这三种机制的区别：简单来说，认证(Authenticating)是对客户端的认证，通俗点就是用户名密码验证，授权(Authorization)是对资源的授权，k8s中的资源无非是容器，最终其实就是容器的计算，网络，存储资源，当一个请求经过认证后，需要访问某一个资源（比如创建一个pod），授权检查都会通过访问策略比较该请求上下文的属性，（比如用户，资源和Namespace），根据授权规则判定该资源（比如某namespace下的pod）是否是该客户可访问的。准入(Admission Control)机制是一种在改变资源的持久化之前（比如某些资源的创建或删除，修改等之前）的机制。<br>在k8s中，这三种机制如下图：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-08-17-k8s-authorition.png" alt="k8s-authorization"></p>
<p>k8s的整体架构也是一个微服务的架构，所有的请求都是通过一个GateWay，也就是kube-apiserver这个组件（对外提供REST服务），由图中可以看出，k8s中客户端有两类，一种是普通用户，一种是集群内的Pod，这两种客户端的认证机制略有不同，后文会详述。但无论是哪一种，都需要依次经过认证，授权，准入这三个机制。</p>
<h2 id="kubernetes-中的认证机制"><a href="#kubernetes-中的认证机制" class="headerlink" title="kubernetes 中的认证机制"></a>kubernetes 中的认证机制</h2><p>需要注意的是，kubernetes虽然提供了多种认证机制，但并没有提供user 实体信息的存储，也就是说，账户体系需要我们自己去做维护。当然，也可以接入第三方账户体系（如谷歌账户），也可以使用开源的keystone去做整合。kubernetes 支持多种认证机制，可以配置成多个认证体制共存，这样，只要有一个认证通过，这个request就认证通过了。下面介绍下官网列举的几种常见认证机制：</p>
<h3 id="X509-Client-Certs"><a href="#X509-Client-Certs" class="headerlink" title="X509 Client Certs"></a>X509 Client Certs</h3><p>也叫作双向数字证书认证，HTTPS证书认证，是基于CA根证书签名的双向数字证书认证方式，是所有认证方式中最严格的认证。默认在kubeadm创建的集群中是enabled的，可以在master node上查看kube-apiserver的pod配置文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat /etc/kubernetes/manifests/kube-apiserver.json</span></div><div class="line">.................</div><div class="line">containers<span class="string">": [</span></div><div class="line">      &#123;</div><div class="line">        "name<span class="string">": "</span>kube-apiserver<span class="string">",</span></div><div class="line">        "image<span class="string">": "</span>gcr.io/google_containers/kube-apiserver-amd64:v1.5.2<span class="string">",</span></div><div class="line">        "<span class="built_in">command</span><span class="string">": [</span></div><div class="line">          "kube-apiserver<span class="string">",</span></div><div class="line">          "--insecure-bind-address=127.0.0.1<span class="string">",</span></div><div class="line">          "--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota<span class="string">",</span></div><div class="line">          "--service-cluster-ip-range=10.96.0.0/12<span class="string">",</span></div><div class="line">          "--service-account-key-file=/etc/kubernetes/pki/apiserver-key.pem<span class="string">",</span></div><div class="line">          "--client-ca-file=/etc/kubernetes/pki/ca.pem<span class="string">",</span></div><div class="line">          "--tls-cert-file=/etc/kubernetes/pki/apiserver.pem<span class="string">",</span></div><div class="line">          "--tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem<span class="string">",</span></div><div class="line">          "--token-auth-file=/etc/kubernetes/pki/tokens.csv<span class="string">",</span></div><div class="line">          "--secure-port=6443<span class="string">",</span></div><div class="line">          "--allow-privileged<span class="string">",</span></div><div class="line">          "--advertise-address=192.168.61.100<span class="string">",</span></div><div class="line">          "--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname<span class="string">",</span></div><div class="line">          "--anonymous-auth=<span class="literal">false</span><span class="string">",</span></div><div class="line">          "--etcd-servers=http://127.0.0.1:2379<span class="string">"</span></div><div class="line">        ],</div></pre></td></tr></table></figure>
<p>相关的三个启动参数：</p>
<ul>
<li>client-ca-file: 指定CA根证书文件为/etc/kubernetes/pki/ca.pem，内置CA公钥用于验证某证书是否是CA签发的证书</li>
<li>tls-private-key-file: 指定ApiServer私钥文件为/etc/kubernetes/pki/apiserver-key.pem</li>
<li>tls-cert-file：指定ApiServer证书文件为/etc/kubernetes/pki/apiserver.pem</li>
</ul>
<p>只要有这三个启动参数，就说明开启了https的认证方式，这时，如果在集群外访问 <a href="https://masterIP:6443/api" target="_blank" rel="external">https://masterIP:6443/api</a> 会提示Unauthorized，只有在客户端配置相关认证才可以访问,客户端的认证证书生成与操作可以参考<a href="https://kubernetes.io/docs/admin/authentication/#x509-client-certs" target="_blank" rel="external">Creating Certificates</a>。证书的生成是kubeadm使用openssl自动生成的，如果是手动配置双向认证，相对比较麻烦，主要配置流程如下：</p>
<ul>
<li>生成根证书、API Server服务端证书、服务端私钥、各个组件所用的客户端证书和客户端私钥。</li>
<li>修改 Kubernetes 各个服务进程的启动参数，启用双向认证模式.</li>
</ul>
<p>详细配置可以参考<a href="http://www.cnblogs.com/breg/p/5923604.html" target="_blank" rel="external">Kubernetes集群安全配置案例</a></p>
<p>注意，在启动参数中还有一个参数：–insecure-bind-address=127.0.0.1，这个参数主要用与master node上的其他核心组件，比如kube-scheduler，kube-controller-manager通过masterIP:8080与APIserver直接通信，而不用通过双向认证。这一点可以从他们的启动参数–master=127.0.0.1:8080看出。</p>
<h3 id="Static-Token-File"><a href="#Static-Token-File" class="headerlink" title="Static Token File"></a>Static Token File</h3><p>静态token文件认证，同样，在kubeadm创建的集群中也是默认enabled的，比如，上面的apiserver启动参数中，我们可以看到有参数 ：–token-auth-file=/etc/kubernetes/pki/tokens.csv ，这个静态token文件的格式为 token,user,uid,”group1,group2,group3”，如下示例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat /etc/kubernetes/pki/tokens.csv</span></div><div class="line">7db2f1c02d721320,kubeadm-node-csr,0615e0ac-7d70-11e7-ad94-fa163eb9dfdd,system:kubelet-bootstrap</div></pre></td></tr></table></figure>
<p>客户端请求的时候需要在http header中加入：”Authorization: Bearer THETOKEN”，如下实例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -k --header <span class="string">"Authorization: Bearer 7db2f1c02d721320"</span> https://192.168.21.34:6443/api</div></pre></td></tr></table></figure>
<p>或者使用brctl:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">kubectl --server=https://192.168.21.34:6443 \</div><div class="line">--token=7db2f1c02d721320 \</div><div class="line">--insecure-skip-tls-verify=<span class="literal">true</span> \</div><div class="line">cluster-info</div></pre></td></tr></table></figure>
<p>注意，如果该静态token文件更改的话，需要重启apiserver。</p>
<h3 id="Bootstrap-Tokens"><a href="#Bootstrap-Tokens" class="headerlink" title="Bootstrap Tokens"></a>Bootstrap Tokens</h3><p>bootstrap token认证目前处于alpha阶段，目前主要是kubeadm创建k8s集群时使用。使用这种认证方式，k8s会动态的管理一种type为bootstrap token的token，这些token作为secret放在kube-system namespace中。controller-manager中的tokencleaner controller会在bootstrap token 过期时进行删除。<br>使用这种认证方式，apiserver的启动参数中需要有–experimental-bootstrap-token-auth，Controller Manager的启动参数中有–controllers=*,tokencleaner 类似参数。</p>
<h3 id="Static-Password-File"><a href="#Static-Password-File" class="headerlink" title="Static Password File"></a>Static Password File</h3><p>比较简单，kubeadm默认没有开启，生产环境也不建议使用。<br>apiserver启动参数指定–basic_auth_file=/etc/kubernetes/basic_auth。然后在指定的文件中加入用户名密码等就可以了，文件格式为password,user,uid,”group1,group2,group3”。</p>
<h3 id="Service-Account-Tokens"><a href="#Service-Account-Tokens" class="headerlink" title="Service Account Tokens"></a>Service Account Tokens</h3><p>Service Account Token 是一种比较特殊的认证机制，适用于上文中提到的pod内部服务需要访问apiserver的认证情况，默认enabled。<br>还是看上文中apiserver 的启动配置参数有–service-account-key-file=/etc/kubernetes/pki/apiserver-key.pem，如果没有指明文件，默认使用–tls-private-key-file的值，即API Server的私钥。<br>service accout本身是作为一种资源在k8s集群中，我们可以通过命令行获取：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master pki]<span class="comment"># kubectl get serviceaccount --all-namespaces</span></div><div class="line">NAMESPACE     NAME        SECRETS   AGE</div><div class="line">default       default     1         7d</div><div class="line"><span class="keyword">for</span>-test      default     1         3d</div><div class="line">kube-system   default     1         7d</div><div class="line">kube-system   weave-net   1         7d</div><div class="line">sock-shop     default     1         7d</div></pre></td></tr></table></figure>
<p>可以看到k8s集群为所有的namespace创建了一个默认的service account，利用命令describe会发现service account只是关联了一个secret作为token，也就是service-account-token。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master pki]<span class="comment"># kubectl describe serviceaccount/default -n kube-system</span></div><div class="line">Name:           default</div><div class="line">Namespace:      kube-system</div><div class="line">Labels:         &lt;none&gt;</div><div class="line"></div><div class="line">Image pull secrets:     &lt;none&gt;</div><div class="line"></div><div class="line">Mountable secrets:      default-token-nbldr</div><div class="line"></div><div class="line">Tokens:                 default-token-nbldr</div><div class="line"></div><div class="line">[root@k8s-master pki]<span class="comment">#  kubectl get secret default-token-nbldr -o yaml -n kube-system</span></div><div class="line">apiVersion: v1</div><div class="line">data:</div><div class="line">  ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFM0</div><div class="line">  ........................略....................</div><div class="line">  namespace: a3ViZS1zeXN0ZW0=</div><div class="line">  token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0..................................</div><div class="line">kind: Secret</div><div class="line">metadata:</div><div class="line">  annotations:</div><div class="line">    kubernetes.io/service-account.name: default</div><div class="line">    kubernetes.io/service-account.uid: 67aae699-7d70-11e7<span class="_">-a</span>8a9-fa163eb9dfdd</div><div class="line">  creationTimestamp: 2017-08-10T02:05:38Z</div><div class="line">  name: default-token-nbldr</div><div class="line">  namespace: kube-system</div><div class="line">  resourceVersion: <span class="string">"88"</span></div><div class="line">  selfLink: /api/v1/namespaces/kube-system/secrets/default-token-nbldr</div><div class="line">  uid: 67b20b73-7d70-11e7<span class="_">-a</span>8a9-fa163eb9dfdd</div><div class="line"><span class="built_in">type</span>: kubernetes.io/service-account-token</div></pre></td></tr></table></figure>
<p>可以看到service-account-token的secret资源包含的数据有三部分：</p>
<ul>
<li><p>ca.crt，这是API Server的CA公钥证书，用于Pod中的Process对API Server的服务端数字证书进行校验时使用的；</p>
</li>
<li><p>namespace，这是Secret所在namespace的值的base64编码：# echo -n “kube-system”|base64 =&gt; “a3ViZS1zeXN0ZW0=”</p>
</li>
<li><p>token：该token就是由service-account-key-file的值签署(sign)生成。</p>
</li>
</ul>
<p>这种认证方式主要由k8s集群自己管理，用户用到的情况比较少。我们创建一个pod时，默认就会将该namespace对应的默认service account token mount到Pod中，所以无需我们操作便可以直接与apiserver通信，相关示例参考<a href="http://tonybai.com/2017/03/03/access-api-server-from-a-pod-through-serviceaccount/" target="_blank" rel="external">在Kubernetes Pod中使用Service Account访问API Server</a>，当然也可以指定多个service account token,参考<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/" target="_blank" rel="external">Configure Service Accounts for Pods</a>。</p>
<h3 id="OpenID-Connect-Tokens"><a href="#OpenID-Connect-Tokens" class="headerlink" title="OpenID Connect Tokens"></a>OpenID Connect Tokens</h3><p>类似 OAuth2的认证方式，大致认证过程如下：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-08-17-k8s-openid-token.jpg" alt="openID"></p>
<p>除了以上几种认证方式外，还有几种比如Webhook Token Authentication，Keystone Password等，详情见<a href="https://kubernetes.io/docs/admin/authentication/#x509-client-certs" target="_blank" rel="external">官网</a>。</p>
<h2 id="kubernetes-中的授权机制"><a href="#kubernetes-中的授权机制" class="headerlink" title="kubernetes 中的授权机制"></a>kubernetes 中的授权机制</h2><p>k8s中的授权策略也支持开启多个授权插件，只要一个验证通过即可。k8s授权处理主要是根据以下请求属性：</p>
<ul>
<li>user, group, extra</li>
<li>API、请求方法（如get、post、update、patch和delete）和请求路径（如/api）</li>
<li>请求资源和子资源</li>
<li>Namespace</li>
<li>API Group</li>
</ul>
<p>目前k8s支持的授权模式主要有以下几种：</p>
<ul>
<li>Node Authorization</li>
<li>ABAC Authorization</li>
<li>RBAC Authorization</li>
<li>Webhook Authorization</li>
</ul>
<h3 id="Node-Authorization"><a href="#Node-Authorization" class="headerlink" title="Node Authorization"></a>Node Authorization</h3><p>1.7+版本才release的一种授权机制，通过配合NodeRestriction control准入控制插件来限制kubelet访问node，endpoint、pod、service以及secret、configmap、PV和PVC等相关的资源。配置方式为：<br>–authorization-mode=Node,RBAC –admission-control=…,NodeRestriction,…</p>
<h3 id="ABAC-Authorization"><a href="#ABAC-Authorization" class="headerlink" title="ABAC Authorization"></a>ABAC Authorization</h3><p>ABAC(Attribute-based access control),使用这种模式需要配置参数：<br>–authorization-mode=ABAC  –authorization-policy-file=SOME_FILENAME。<br>这种模式的实现相对比较生硬，就是在master node保存一份policy文件，指定不用用户（或用户组）对不同资源的访问权限,当修改该文件后，需要重启apiserver,跟openstack 的ABAC类似。policy文件的格式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Alice can do anything to all resources:</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"apiVersion"</span>: <span class="string">"abac.authorization.kubernetes.io/v1beta1"</span>,</div><div class="line">    <span class="string">"kind"</span>: <span class="string">"Policy"</span>,</div><div class="line">    <span class="string">"spec"</span>: &#123;</div><div class="line">        <span class="string">"user"</span>: <span class="string">"alice"</span>,</div><div class="line">        <span class="string">"namespace"</span>: <span class="string">"*"</span>,</div><div class="line">        <span class="string">"resource"</span>: <span class="string">"*"</span>,</div><div class="line">        <span class="string">"apiGroup"</span>: <span class="string">"*"</span></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment"># Kubelet can read any pods:</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"apiVersion"</span>: <span class="string">"abac.authorization.kubernetes.io/v1beta1"</span>,</div><div class="line">    <span class="string">"kind"</span>: <span class="string">"Policy"</span>,</div><div class="line">    <span class="string">"spec"</span>: &#123;</div><div class="line">        <span class="string">"user"</span>: <span class="string">"kubelet"</span>,</div><div class="line">        <span class="string">"namespace"</span>: <span class="string">"*"</span>,</div><div class="line">        <span class="string">"resource"</span>: <span class="string">"pods"</span>,</div><div class="line">        <span class="string">"readonly"</span>: <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Kubelet can read and write events:</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"apiVersion"</span>: <span class="string">"abac.authorization.kubernetes.io/v1beta1"</span>,</div><div class="line">    <span class="string">"kind"</span>: <span class="string">"Policy"</span>,</div><div class="line">    <span class="string">"spec"</span>: &#123;</div><div class="line">        <span class="string">"user"</span>: <span class="string">"kubelet"</span>,</div><div class="line">        <span class="string">"namespace"</span>: <span class="string">"*"</span>,</div><div class="line">        <span class="string">"resource"</span>: <span class="string">"events"</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>使用这种模式需要配置参数：<br>–authorization-mode=ABAC  –authorization-policy-file=SOME_FILENAME</p>
<h3 id="RBAC-Authorization"><a href="#RBAC-Authorization" class="headerlink" title="RBAC Authorization"></a>RBAC Authorization</h3><p>RBAC（Role-Based Access Control）依然处于Beta阶段，通过启动参数–authorization-mode=RBAC，使用kubeadm安装k8s默认会enabled。<br>RBAC API定义了四个资源对象用于描述RBAC中用户和资源之间的连接权限：</p>
<ul>
<li>Role</li>
<li>ClusterRole</li>
<li>RoleBinding</li>
<li>ClusterRoleBinding</li>
</ul>
<p>Role是定义在某个Namespace下的资源，在这个具体的Namespace下使用。 ClusterRole与Role相似，只是ClusterRole是整个集群范围内使用的。<br>RoleBinding把Role绑定到账户主体Subject，让Subject继承Role所在namespace下的权限。 ClusterRoleBinding把ClusterRole绑定到Subject，让Subject集成ClusterRole在整个集群中的权限。</p>
<p>我们可以通过kubectl命令获取对应的Role相关资源进行增删改查：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">kubectl get roles --all-namespaces</div><div class="line"></div><div class="line">kubectl get ClusterRoles</div><div class="line"></div><div class="line">kubectl get rolebinding --all-namespaces</div><div class="line"></div><div class="line">kubectl get clusterrolebinding</div></pre></td></tr></table></figure></p>
<p>API Server已经创建一系列ClusterRole和ClusterRoleBinding。这些资源对象中名称以system:开头的，表示这个资源对象属于Kubernetes系统基础设施。 也就说RBAC默认的集群角色已经完成足够的覆盖，让集群可以完全在 RBAC的管理下运行。 修改这些资源对象可能会引起未知的后果，例如对于system:node这个ClusterRole定义了kubelet进程的权限，如果这个角色被修改，可能导致kubelet无法工作。</p>
<h3 id="Webhook-Authorization"><a href="#Webhook-Authorization" class="headerlink" title="Webhook Authorization"></a>Webhook Authorization</h3><p>用户在外部提供 HTTPS 授权服务，然后配置 apiserver 调用该服务去进行授权。apiserver配置参数：<br>–authorization-webhook-config-file=SOME_FILENAME<br>配置文件的格式跟kubeconfig的格式类似，具体参考<a href="https://kubernetes.io/docs/admin/authorization/webhook/" target="_blank" rel="external">官方文档</a></p>
<h2 id="kubernetes-中的准入机制"><a href="#kubernetes-中的准入机制" class="headerlink" title="kubernetes 中的准入机制"></a>kubernetes 中的准入机制</h2><p>Kubernetes的Admission Control实际上是一个准入控制器(Admission Controller)插件列表，发送到APIServer的请求都需要经过这个列表中的每个准入控制器插件的检查，如果某一个控制器插件准入失败，就准入失败。<br>控制器插件如下：</p>
<ul>
<li>AlwaysAdmit：允许所有请求通过</li>
<li>AlwaysPullImages：在启动容器之前总是去下载镜像，相当于每当容器启动前做一次用于是否有权使用该容器镜像的检查</li>
<li>AlwaysDeny：禁止所有请求通过，用于测试</li>
<li>DenyEscalatingExec：拒绝exec和attach命令到有升级特权的Pod的终端用户访问。如果集中包含升级特权的容器，而要限制终端用户在这些容器中执行命令的能力，推荐使用此插件</li>
<li>ImagePolicyWebhook</li>
<li>ServiceAccount：这个插件实现了serviceAccounts等等自动化，如果使用ServiceAccount对象，强烈推荐使用这个插件</li>
<li>SecurityContextDeny：将Pod定义中定义了的SecurityContext选项全部失效。SecurityContext包含在容器中定义了操作系统级别的安全选型如fsGroup，selinux等选项</li>
<li>ResourceQuota：用于namespace上的配额管理，它会观察进入的请求，确保在namespace上的配额不超标。推荐将这个插件放到准入控制器列表的最后一个。ResourceQuota准入控制器既可以限制某个namespace中创建资源的数量，又可以限制某个namespace中被Pod请求的资源总量。ResourceQuota准入控制器和ResourceQuota资源对象一起可以实现资源配额管理。</li>
<li>LimitRanger：用于Pod和容器上的配额管理，它会观察进入的请求，确保Pod和容器上的配额不会超标。准入控制器LimitRanger和资源对象LimitRange一起实现资源限制管理</li>
<li>NamespaceLifecycle：当一个请求是在一个不存在的namespace下创建资源对象时，该请求会被拒绝。当删除一个namespace时，将会删除该namespace下的所有资源对象</li>
<li>DefaultStorageClass</li>
<li>DefaultTolerationSeconds</li>
<li>PodSecurityPolicy</li>
</ul>
<p>当Kubernetes版本&gt;=1.6.0，官方建议使用这些插件：<br>–admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds<br>当Kubernetes版本&gt;=1.4.0，官方建议使用这些插件：<br>–admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota<br>以上是标准的准入插件，如果是自己定制的话，k8s1.7版 出了两个alpha features, Initializers 和 External Admission Webhooks，详情可以参考<a href="https://kubernetes.io/docs/admin/extensible-admission-controllers/" target="_blank" rel="external">Dynamic Admission Control</a>.</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://kubernetes.io/docs/admin/authentication/#x509-client-certs" target="_blank" rel="external">Authenticating</a></p>
<p><a href="https://kubernetes.io/docs/admin/authorization/" target="_blank" rel="external">authorization</a></p>
<p><a href="http://blog.frognew.com/2017/01/kubernetes-api-server-authc.html" target="_blank" rel="external">Kubernetes集群安全：Api Server认证</a></p>
<p><a href="http://blog.frognew.com/2017/05/kubernetes-apiserver-admission-control.html" target="_blank" rel="external">Kubernetes集群安全：准入控制Admission Control</a></p>
<p><a href="http://blog.frognew.com/2017/04/kubernetes-1.6-rbac.html" target="_blank" rel="external">Kubernetes 1.6新特性学习：RBAC授权</a></p>
<p><a href="http://tonybai.com/2017/03/03/access-api-server-from-a-pod-through-serviceaccount/" target="_blank" rel="external">在Kubernetes Pod中使用Service Account访问API Server</a></p>
<p><a href="http://blog.csdn.net/yan234280533/article/details/76359199" target="_blank" rel="external"> kubernetes安全控制认证与授权(二)</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/08/14/install-kubernete-by-kubreadm/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/14/install-kubernete-by-kubreadm/" itemprop="url">
                  Kubernete-- 利用kubeadm 搭建一个kubernate集群
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-14T15:38:10+08:00">
                2017-08-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/08/14/install-kubernete-by-kubreadm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/14/install-kubernete-by-kubreadm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul>
<li>利用 kubeadm 搭建一个四节点的k8s测试集群</li>
<li>利用harbor搭建一个单节点的私有镜像仓库</li>
<li>k8s集群与私有镜像仓库整合</li>
<li>部署dashboard</li>
</ul>
<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>准备以下5个节点，一个为k8s的master节点，3个为node节点，最后一个作为私有仓库镜像，系统为centos7.2：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-08-14-node.png" alt="five-nodes"></p>
<p>注：k8s的安装方式有很多，kubeadm安装方式是独立节点安装的官方推荐方式，简单可重复，但不适用于生产环境，因为没有做HA，不过可以在安装完之后继续优化做HA，参考<a href="http://tonybai.com/2017/05/15/setup-a-ha-kubernetes-cluster-based-on-kubeadm-part1/" target="_blank" rel="external">一步步打造基于Kubeadm的高可用Kubernetes集群</a>,后续会跟进这一块。</p>
<h2 id="kubernete-集群安装"><a href="#kubernete-集群安装" class="headerlink" title="kubernete 集群安装"></a>kubernete 集群安装</h2><h3 id="k8s所有节点需要执行的操作"><a href="#k8s所有节点需要执行的操作" class="headerlink" title="k8s所有节点需要执行的操作"></a>k8s所有节点需要执行的操作</h3><p>所有节点都要安装以下组件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">docker：容器运行时，被Kubernetes依赖</div><div class="line">kubelet：Kubernetes核心组件，运行在集群中的所有节点上，用来启动容器和pods</div><div class="line">kubectl：命令行工具，k8s客户端，用来控制集群，只需要安装到kube-master上,当然，也可以安装到其他节点，然后配置指定master。</div><div class="line">kubeadm：集群安装工具</div></pre></td></tr></table></figure>
<p>首先，安装docker,k8s官方建议版本为1.12，1.13以及17.03+版本还没有测试。所以这里也安装1.12版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">tee /etc/yum.repos.d/docker.repo &lt;&lt;-<span class="string">'EOF'</span></div><div class="line">[dockerrepo]</div><div class="line">name=Docker Repository</div><div class="line">baseurl=https://yum.dockerproject.org/repo/main/centos/7/</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">gpgkey=https://yum.dockerproject.org/gpg</div><div class="line">EOF</div><div class="line"></div><div class="line">setenforce 0</div><div class="line"></div><div class="line">yum update -y </div><div class="line"></div><div class="line">yum install -y docker-engine-1.12.6 docker-engine-selinux-1.12.6</div><div class="line"></div><div class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</div></pre></td></tr></table></figure>
<p>注：这里有个小坑，就是k8s dashboard在某些版本RH内核下会启动失败，参考<a href="https://github.com/rancher/rancher/issues/7436" target="_blank" rel="external">issue</a>。</p>
<p>接下来，安装kubectl, kubelet, kubeadm以及一些依赖包。</p>
<p>先把依赖包装上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y ebtables socat</div></pre></td></tr></table></figure></p>
<p>kubectl 的安装比较简单，参考<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="external">Install and Set Up kubectl</a>,可以直接下载可执行文件然后添加权限，扔到master节点的/usr/local/bin/目录下即可，注意版本要与k8s版本匹配(注：也可以直接在下文同其他三个组件一起rpm包安装)。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl <span class="_">-s</span> https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl</div><div class="line"></div><div class="line">chmod +x ./kubectl</div><div class="line"></div><div class="line">sudo mv ./kubectl /usr/<span class="built_in">local</span>/bin/kubectl</div></pre></td></tr></table></figure>
<p>因为kubelet, kubeadm的rpm安装包在gce上，需要翻墙。</p>
<p>如果服务器可以翻墙，可以直接通过yum命令安装：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</div><div class="line">[kubernetes]</div><div class="line">name=Kubernetes</div><div class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">repo_gpgcheck=1</div><div class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg</div><div class="line">        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</div><div class="line">EOF</div><div class="line"></div><div class="line">yum install -y kubelet kubeadm</div><div class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</div></pre></td></tr></table></figure></p>
<p>如果不能翻墙，只能先下载下来，然后安装，需要安装的rpm包url地址可以在这个网页中找到：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/primary.xml</div></pre></td></tr></table></figure></p>
<p>我们这里只需要安装三个rpm包，kubeadm, kubelet以及kubernetes-cni，可以直接搜索上面的网页然后找到合适版本的rpm包。我们这里安装最新版本1.7.3,对应的地址如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">https://packages.cloud.google.com/yum/pool/f7ec56b0f36a81c0f91bcf26e05f23088082b468b77dac576dc505444dd8<span class="built_in">cd</span>48-kubeadm-1.7.3-1.x86_64.rpm</div><div class="line"></div><div class="line">https://packages.cloud.google.com/yum/pool/28b76e6e1c2ec397a9b6111045316a0943da73dd5602ee8e53752cdca62409e6-kubelet-1.7.3-1.x86_64.rpm</div><div class="line"></div><div class="line">https://packages.cloud.google.com/yum/pool/e7a4403227dd24036f3b0615663a371c4e07a95be5fee53505e647fd8ae58aa6-kubernetes-cni-0.5.1-0.x86_64.rpm</div></pre></td></tr></table></figure>
<p>将这三个rpm包打包上传到四个节点上，并安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">tar xzvf /tmp/kubernetes-el7-x86_64.tar.gz</div><div class="line">kubernetes-el7-x86_64/</div><div class="line">kubernetes-el7-x86_64/567600102f687e0f27bd1fd3d8211ec1cb12e71742221526bb4e14a412f4fdb5-kubernetes-cni-0.5.0.1-0.07a8a2.x86_64.rpm</div><div class="line">kubernetes-el7-x86_64/5612db97409141d7fd839e734d9ad3864dcc16a630b2a91c312589a0a0d960d0-kubeadm-1.6.0-0.alpha.0.2074.a092d8e0f95f52.x86_64.rpm</div><div class="line">kubernetes-el7-x86_64/8a299eb1db946b2bdf01c5d5c58ef959e7a9d9a0dd706e570028ebb14d48c42e-kubelet-1.5.1-0.x86_64.rpm</div><div class="line">kubernetes-el7-x86_64/93af9d0fbd67365fa5bf3f85e3d36060138a62ab77e133e35f6cadc1fdc15299-kubectl-1.5.1-0.x86_64.rpm</div><div class="line"></div><div class="line"><span class="built_in">cd</span> kubernetes-el7-x86_64/</div><div class="line"></div><div class="line">rpm -ivh *</div><div class="line"></div><div class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</div></pre></td></tr></table></figure>
<p>接下来开始基于Kubeadm 创建k8s集群，不过在开始之前，我们先准备下需要用到的镜像，因为kubeadm创建的k8s集群中的kub-api, kube-scheduler, kube-proxy, kube-controller-manager,etcd等服务都是直接拉取镜像跑在k8s集群中，为了避免安装过程中下载镜像浪费太多时间，这里先把镜像下载好。各个版本需要下载的镜像版本也不一样。参考如下：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-08-14-k8s-image.png" alt="k8s-image"></p>
<p>我们直接用的最新版1.7.3，如果服务器可以翻墙，直接拉取镜像：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">images=(kube-proxy-amd64:v1.7.3 kube-scheduler-amd64:v1.7.3 kube-controller-manager-amd64:v1.7.3 kube-apiserver-amd64:v1.7.3 etcd-amd64:3.0.17 k8s-dns-sidecar-amd64:1.14.4 pause-amd64:3.0 k8s-dns-kube-dns-amd64:1.14.4 k8s-dns-dnsmasq-nanny-amd64:1.14.4)</div><div class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> <span class="variable">$&#123;images[@]&#125;</span> ; <span class="keyword">do</span></div><div class="line">  docker pull gcr.io/google_containers/<span class="variable">$imageName</span></div><div class="line"><span class="keyword">done</span></div></pre></td></tr></table></figure>
<p>如果不能翻墙，可以先翻墙下载下来，然后push到dockerhub上，再pull下来,注意pull下来之后，还是要更改tag为gcr.io/google_containers/$imageName形式。</p>
<h3 id="master-节点安装"><a href="#master-节点安装" class="headerlink" title="master 节点安装"></a>master 节点安装</h3><p>在master节点执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubeadm init</div></pre></td></tr></table></figure>
<p>执行完成后，会输出一个token，node节点安装时会用到。<br>这里有一个小坑：该过程一直卡在“[apiclient] Created API client, waiting for the control plane to become ready” ，可以去message里找相关log，一般是两种情况导致，一种是用了proxy，一种是<a href="https://github.com/kubernetes/kubernetes/issues/43800" target="_blank" rel="external">cgroup-driver配置错误</a>，我这边有一次是因为下载的镜像不对，kubeadm默认应该是安转最新版本，比如kubeadm1.6.x会安装1.6.9的相关组件（api-server-1.6.9.controller-manager-1.6.9等），而kubeadm1.7.x会默认安装1.7.x里面的最高版本（此时是1.7.4），所以要下载合适版本的镜像。</p>
<h3 id="node-节点安装"><a href="#node-节点安装" class="headerlink" title="node 节点安装"></a>node 节点安装</h3><p>在各node节点执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubeadm join --token=976234.e91451d4305bc282 172.16.21.53</div></pre></td></tr></table></figure>
<p>全部执行完成后，在master节点验证：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master ~<span class="comment"># kubectl get nodes</span></div><div class="line">NAME                   STATUS         AGE</div><div class="line">k8s-master.novalocal   Ready,master   4d</div><div class="line">k8s-node1.novalocal    Ready          4d</div><div class="line">k8s-node2.novalocal    Ready          4d</div><div class="line">k8s-node3.novalocal    Ready          4d</div></pre></td></tr></table></figure>
<h3 id="部署pod网络"><a href="#部署pod网络" class="headerlink" title="部署pod网络"></a>部署pod网络</h3><p>这里选择Weave Net。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master ~]<span class="comment"># kubectl apply -f https://git.io/weave-kube</span></div></pre></td></tr></table></figure>
<p>等待一段时间，利用下列命令查看部署情况。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master ~]<span class="comment"># kubectl get pods --all-namespaces</span></div></pre></td></tr></table></figure>
<h3 id="部署sock-shop微服务demo"><a href="#部署sock-shop微服务demo" class="headerlink" title="部署sock-shop微服务demo"></a>部署sock-shop微服务demo</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master ~]<span class="comment"># kubectl create namespace sock-shop</span></div><div class="line">[root@k8s-master ~]<span class="comment"># kubectl apply -n sock-shop -f "https://github.com/microservices-demo/microservices-demo/blob/master/deploy/kubernetes/complete-demo.yaml?raw=true"</span></div></pre></td></tr></table></figure>
<p>查看服务部署情况：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@k8s-master ~]<span class="comment"># kubectl get pods -n sock-shop</span></div></pre></td></tr></table></figure></p>
<p>访问172.16.21.34:30001验证。</p>
<h2 id="Harbor-安装"><a href="#Harbor-安装" class="headerlink" title="Harbor 安装"></a>Harbor 安装</h2><p>比较简单，参考<a href="https://github.com/vmware/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="external">harbor doc</a>。</p>
<p>注意：docker 默认连接镜像使用https，而harbor默认安装是走的http，所以需要修改/etc/docker/daemon.json，添加</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="string">"registry-mirrors"</span>: [<span class="string">"&lt;your accelerate address&gt;"</span>],</div><div class="line">    <span class="string">"insecure-registries"</span>: [<span class="string">"172.16.21.44"</span>]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="k8s-添加私有镜像"><a href="#k8s-添加私有镜像" class="headerlink" title="k8s 添加私有镜像"></a>k8s 添加私有镜像</h2><p>官方给出了三种解决方案：</p>
<ul>
<li>在node节点配置私有镜像的认证登录文件，其实相当于在node本地执行docker login后，在/.docker目录下生成的一个config.json文件。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat ~/.docker/config.json</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"auths"</span>: &#123;</div><div class="line">        <span class="string">"registry.cn-hangzhou.aliyuncs.com/xxxx/rbd-rest-api"</span>: &#123;</div><div class="line">            <span class="string">"auth"</span>: <span class="string">"xxxxyyyyzzzz"</span>   <span class="comment">#一个base64编码结果，不太安全</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这种方法比较繁琐，而且不安全，不推荐。</p>
<ul>
<li>利用kubectl创建docker-registry的secret</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</div><div class="line"></div><div class="line">kubectl get secret --all-namespaces   <span class="comment">#查看创建的secret</span></div></pre></td></tr></table></figure>
<p>在写dockerfile的时候指定imagePullSecrets即可，示例如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat ./deployment-with-secret.yaml</span></div><div class="line">apiVersion: extensions/v1beta1</div><div class="line">kind: Deployment</div><div class="line">metadata:</div><div class="line">  name: nginx-deployment-from-harbor</div><div class="line">  namespace: kube-public</div><div class="line">spec:</div><div class="line">  replicas: 3</div><div class="line">  template:</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        app: nginx-for-test</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: nginx-for-test</div><div class="line">        image: 172.16.21.253:10080/aisino-lib/docker.io/nginx:latest</div><div class="line">        ports:</div><div class="line">        - containerPort: 80</div><div class="line">      imagePullSecrets:</div><div class="line">      - name: harbor-k8s-secret</div></pre></td></tr></table></figure>
<ul>
<li>通过secret yaml文件创建pull image所用的secret,其实跟上述方法类似，不过是用yaml文件创建的secret.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat myregistrykey.yaml</span></div><div class="line">apiVersion: v1</div><div class="line">kind: Secret</div><div class="line">metadata:</div><div class="line">  name: myregistrykey</div><div class="line">  namespace: awesomeapps</div><div class="line">data:</div><div class="line">  .dockerconfigjson: &#123;base64 -w 0 ~/.docker/config.json&#125;</div><div class="line"><span class="built_in">type</span>: kubernetes.io/dockerconfigjson</div></pre></td></tr></table></figure>
<p>其中，dockerconfigjson后面的数据就是docker login后生成的config.json文件的base64编码输出（-w 0让base64输出在单行上，避免折行）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl create <span class="_">-f</span> myregistrykey.yaml</div></pre></td></tr></table></figure>
<p>secret使用方式与第二种方式一样，不过kubectl和yaml创建的两个secret的类型略有不同，前者是kubernetes.io/dockercfg，后者是kubernetes.io/dockerconfigjson。</p>
<h2 id="部署dashboard"><a href="#部署dashboard" class="headerlink" title="部署dashboard"></a>部署dashboard</h2><p>由<a href="https://github.com/kubernetes/dashboard" target="_blank" rel="external">README</a> 文件可知，有两种部署方式，如果是没有安装RBAC权限控制的，可以执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl create <span class="_">-f</span> https://git.io/kube-dashboard</div></pre></td></tr></table></figure>
<p>如果有RBAC的，可以执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl create <span class="_">-f</span> https://git.io/kube-dashboard-no-rbac</div></pre></td></tr></table></figure>
<p>kubeadm安装方式自从1.6+版之后自动安装RBAC，所以需要选择第二种。如果权限问题依旧（注：一般是报错serviceaccount:kube-system:default” cannot list statefulsets.apps in the namespace “default”.）可以根据该<a href="https://github.com/kubernetes/dashboard/issues/1803" target="_blank" rel="external">issue</a>,添加一个权限。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cat dashboard-rbac.yml</span></div><div class="line">kind: ClusterRoleBinding</div><div class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</div><div class="line">metadata:</div><div class="line">  name: dashboard-admin</div><div class="line">roleRef:</div><div class="line">  apiGroup: rbac.authorization.k8s.io</div><div class="line">  kind: ClusterRole</div><div class="line">  name: cluster-admin </div><div class="line">subjects:</div><div class="line">- kind: ServiceAccount</div><div class="line">  name: default</div><div class="line">  namespace: kube-system</div><div class="line"></div><div class="line"><span class="comment"># kubectl create -f dashboard-rbac.yml</span></div></pre></td></tr></table></figure>
<p>注：如果想外部可以直接访问dashboard，需要修改下yaml文件，将最后的service配置修改为nodePort,示例如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">.......................</div><div class="line">---</div><div class="line">kind: Service</div><div class="line">apiVersion: v1</div><div class="line">metadata:</div><div class="line">  labels:</div><div class="line">    k8s-app: kubernetes-dashboard</div><div class="line">  name: kubernetes-dashboard</div><div class="line">  namespace: kube-system</div><div class="line">spec:</div><div class="line">  <span class="built_in">type</span>: NodePort</div><div class="line">  ports:</div><div class="line">  - nodePort: 30002</div><div class="line">    port: 80</div><div class="line">    targetPort: 9090</div><div class="line">  selector:</div><div class="line">    k8s-app: kubernetes-dashboard</div></pre></td></tr></table></figure>
<p>这样便可以直接<a href="http://NODEIP:30002访问。关于port，nodePort" target="_blank" rel="external">http://NODEIP:30002访问。关于port，nodePort</a>, targetPort,可以参考<a href="http://blog.csdn.net/xinghun_4/article/details/50492041" target="_blank" rel="external">kubernetes中port、target port、node port的对比分析，以及kube-proxy代理</a></p>
<h2 id="部署Heapster-监控与统计"><a href="#部署Heapster-监控与统计" class="headerlink" title="部署Heapster 监控与统计"></a>部署Heapster 监控与统计</h2><p>Heapster是一个容器集群监控和性能分析工具，天然支持Kubernetes和CoreOS。<br>这里使用influxDB作为Heapster的后端存储部署，参考<a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md" target="_blank" rel="external">安装文档</a>.<br>首先下载对应版本的相关yaml文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/kubernetes/heapster/archive/v1.3.0.tar.gz</div></pre></td></tr></table></figure>
<p>解压并直接部署即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar -zxvf v1.3.0.tar.gz</div><div class="line"><span class="built_in">cd</span> heapster-1.3.0/deploy/kube-config/influxdb</div><div class="line"></div><div class="line">kubectl create <span class="_">-f</span> ./*</div></pre></td></tr></table></figure>
<p>该过程会pull相关镜像，同样，可以先翻墙pull下来再push到私有镜像仓库再使用。<br>最终完成后，所有pods都running,可以看到dashboard的界面多了仪表盘。</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-08-16-dashboard.png" alt="dashboard"></p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="external">k8s-doc-Installing kubeadm</a></p>
<p><a href="http://yoyolive.com/2017/02/27/Kubernetes-1-5-3-Local-Install/" target="_blank" rel="external">CentOS 7 安装Kubernetes 1.5.3 集群(本地安装)</a></p>
<p><a href="http://tonybai.com/2016/11/16/how-to-pull-images-from-private-registry-on-kubernetes-cluster/?utm_source=rss" target="_blank" rel="external">Kubernetes从Private Registry中拉取容器镜像的方法</a></p>
<p><a href="https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry" target="_blank" rel="external">k8s-doc-Images</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/08/08/openstack-resource-segeration/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/08/openstack-resource-segeration/" itemprop="url">
                  Openstack-- openstack 中的资源分离策略
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-08T13:54:20+08:00">
                2017-08-08
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/08/08/openstack-resource-segeration/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/08/openstack-resource-segeration/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="为什么做资源的分离"><a href="#为什么做资源的分离" class="headerlink" title="为什么做资源的分离"></a>为什么做资源的分离</h2><p>openstack 作为一个云计算框架，需要统筹计算，存储，网络等资源，本身就已经够复杂了。如果是在一个非常大的环境中，节点众多，且复杂多样，这个时候就有必要根据这些节点的差异做一些逻辑上的分离，以达到不同资源的区分，这样，做水平扩展的时候也可以根据这个逻辑分区针对性的进行扩展。</p>
<h2 id="openstack-中的资源分离策略"><a href="#openstack-中的资源分离策略" class="headerlink" title="openstack 中的资源分离策略"></a>openstack 中的资源分离策略</h2><p>openstack 的资源分离策略一定程度上借鉴了AWS的策略，整体来说，如下：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-08-08-rc-se.png" alt="resource-segeration"></p>
<h3 id="Infrastructure-segregation"><a href="#Infrastructure-segregation" class="headerlink" title="Infrastructure segregation"></a>Infrastructure segregation</h3><p>主要是理解Regions, cells, Host aggregates, Availability zones这几个概念。</p>
<ul>
<li>Regions:借鉴自AWS，更像是一个地理上的概念（比如北京的数据中心可以作为一个region,南京的数据中心作为另一个region），每个region有自己独立的endpoint，regions之间完全隔离，不同regions之间可以共享keystone/dashboard。openstack默认新建一个region，即RegionOne，如果还想建立第二个Region，可以利用 keystone endpoint­create 命令添加。<br><img src="http://oeptotikb.bkt.clouddn.com/2017-08-08-region1.png" alt="region"></li>
</ul>
<ul>
<li>Cells:cell主要是为了解决openstack 的扩展性以及规模瓶颈而引进的概念。当openstack达到一定规模后，依赖比较强的database以及AMQP便成为整个系统的瓶颈，引入cell后，每个cell有自己独立的database和AMQP。公司云平台只是一个小云，没有引入，所以不去深究。cell目前是有v1，v2两版，实现方式差异比较大，感兴趣可以参考<a href="https://www.ustack.com/news/what-is-nova-cells-v2/?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="external">Nova Cells V2如何帮助OpenStack集群突破性能瓶颈？</a>。</li>
<li>Host aggregates &amp;&amp; Availability zones：这两个概念有共通点，且要相互配合使用，都用来表示一组节点的集合，简单说，AZ(Availability zone)是一个面向用户的概念，(这里只讨论nova 范畴的AZ,cinder,neutron也有对应的AZ概念),AZ一般依据地址，网络部署或电力配置划分，可以是一个独立的机房，或者一个独立供电的机架等，用户在创建instance的时候可以指定AZ，从而使instance创建在指定的AZ中，而host aggregate是一个面向管理员的概念，主要用来给nova-scheduler调度使用，比如根据某一属性（例如含有固态硬盘）划分一个host aggregate，把所有含有固态硬盘的host都放到该host aggregate中，nova-scheduler调度时指定相关属性就可以调度到对应host aggregate中的host。</li>
</ul>
<p><img src="http://oeptotikb.bkt.clouddn.com/2018-08-08-az.png" alt="AZandHG"><br>如上图，有两个地理隔离的Region，四个AZ，以及若干个根据不同属性区分的host aggregate。host aggregate 创建的时候可以指定AZ（如果AZ没有就会自动创建一个AZ），一个host可以属于多个host aggregate，但只能属于一个AZ。如下为一个示例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nova aggregate­create storage­optimized storage­optimized-AZ  <span class="comment"># 创建一个host aggregate</span></div><div class="line">nova aggregate­<span class="built_in">set</span>­metadata <span class="variable">$aggregateID</span> fast­storage=<span class="literal">true</span> <span class="comment"># 设置 aggregate 的metadate</span></div><div class="line">nova aggregate­add­host <span class="variable">$aggregateID</span> host­1 <span class="comment">#添加host到aggregate</span></div><div class="line">nova flavor­key <span class="variable">$flavorID</span> <span class="built_in">set</span> fast­storage=<span class="literal">true</span> <span class="comment">#添加flavor的 条件</span></div></pre></td></tr></table></figure>
<h3 id="Workload-segregation"><a href="#Workload-segregation" class="headerlink" title="Workload segregation"></a>Workload segregation</h3><p>负载这一块的策略是基于server-group来做的，相对比较简单。注意，这里的server-group不再是host的集合，而是instance的集合。比如，我要创建3个instance，因为这3个instance都比较吃内存，所以想要这3个instance在不同的host上，就可以这样做：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nova server-group-create --policy anti-affinity group-1 <span class="comment"># 创建server-group，注意policy指定策略是不在同一节点</span></div><div class="line">nova boot --image IMAGE_ID --flavor 1 --hint group=group-1 inst1 <span class="comment">#创建instance1 </span></div><div class="line">nova boot --image IMAGE_ID --flavor 1 --hint group=group-1 inst2 <span class="comment">#创建instance2 </span></div><div class="line">nova boot --image IMAGE_ID --flavor 1 --hint group=group-1 inst3 <span class="comment">#创建instance3</span></div></pre></td></tr></table></figure>
<p>在nova配置文件中指定scheduler策略，有一个针对server-group的filter叫做ServerGroupAntiAffinityFilter。除了anti-affinity，还有 affinity策略，就是尽量让同一server-group的instance在同一个host上。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://www.jianshu.com/p/613d34ad6d51" target="_blank" rel="external">理解openstack中region、cell、availability zone、host aggregate 概念</a></p>
<p><a href="http://happylab.blog.51cto.com/1730296/1739180" target="_blank" rel="external">openstack运维实战系列(十二)之nova aggregate资源分组</a></p>
<p><a href="https://www.openstack.org/assets/presentation-media/divideandconquer-2.pdf" target="_blank" rel="external">DIVIDE AND CONQUER:RESOURCE SEGREGATION IN THE OPENSTACK<br>CLOUD</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/08/05/intro-to-etcd/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/05/intro-to-etcd/" itemprop="url">
                  Kubernetes-- 关于ETCD && 服务发现的一些记录
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-05T14:28:00+08:00">
                2017-08-05
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/08/05/intro-to-etcd/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/05/intro-to-etcd/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ETCD简介"><a href="#ETCD简介" class="headerlink" title="ETCD简介"></a>ETCD简介</h2><p>ETCD是一个可靠的键值对分布式存储系统，适用场景是用来存储那些写少读多，结构简单，但又比较重要的数据，这里的比较重要是指要保证数据的高可用，一致性。第一个想到的自然就是配置数据的存储与管理。当然，也可以存储其他满足上述要求的数据，比如在k8s中，ETCD会用来存储k8s各items(pods, rc, rs, deployment等)的状态。随着微服务架构的日益火热，ETCD也常作为服务发现的组件来使用。<br>ETCD 有以下几个特性：</p>
<ul>
<li>使用简单：友好的API(grpc)</li>
<li>安全：支持TLS双向通信</li>
<li>快速：支持10,000 写/秒</li>
<li>可靠： 采用raft协议作分布式选举</li>
</ul>
<h2 id="ETCD-安装"><a href="#ETCD-安装" class="headerlink" title="ETCD 安装"></a>ETCD 安装</h2><p>因为是go写的，直接下载二进制文件执行即可，如果想要尝试最新版的，可以去下载源码，自己build,参考<a href="https://coreos.com/etcd/docs/latest/dl_build.html" target="_blank" rel="external">Download and build</a>。<br>如果是构造一个cluster，也比较简单，参考<a href="https://coreos.com/etcd/docs/latest/demo.html" target="_blank" rel="external">Demo</a></p>
<p>简单记录下常用的启动参数：</p>
<ul>
<li>name：节点名称，默认为 default，在集群中应该保持唯一，一般使用 hostname</li>
<li>data-dir：服务运行数据保存的路径，默认为 ${name}.etcd</li>
<li>snapshot-count：指定有多少事务（transaction）被提交时，触发截取快照保存到磁盘</li>
<li>heartbeat-interval：leader 多久发送一次心跳到 followers。默认值是 100ms</li>
<li>eletion-timeout：重新投票的超时时间，如果 follower在该时间间隔没有收到心跳包，会触发重新投票，默认为 1000 ms</li>
<li>listen-peer-urls:和同伴通信的地址，比如 <a href="http://ip:2380" target="_blank" rel="external">http://ip:2380</a> ，如果有多个，使用逗号分隔。需要所有节点都能够访问， 所以不要使用 localhost！</li>
<li>listen-client-urls: 对外提供服务的地址：比如 <a href="http://ip:2379,http://127.0.0.1:2379" target="_blank" rel="external">http://ip:2379,http://127.0.0.1:2379</a><br>，客户端会连接到这里和 etcd 交互</li>
<li>advertise-client-urls: 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</li>
<li>initial-advertise-peer-urls: 该节点同伴监听地址，这个值会告诉集群中其他节点</li>
<li>initial-cluster: 集群中所有节点的信息，格式为 node1=<a href="http://ip1:2380,node2=http://ip2:2380" target="_blank" rel="external">http://ip1:2380,node2=http://ip2:2380</a>,…… 注意：这里的 node1是节点的–name指定的名字；后面的 ip1:2380是 –initial-advertise-peer-urls<br>指定的值。</li>
<li>initial-cluster-state：新建集群的时候，这个值为 new，假如已经存在的集群，这个值为 existing。</li>
<li>initial-cluster-token：创建集群的 token，这个值每个集群保持唯一。这样的话，如果你要重新创建集群，即使配置和之前一样，也会再次生成新的集群和节点uuid；否则会导致多个集群之间的冲突，造成未知的错误。</li>
</ul>
<p>当然，还有比如tls设置，使用etcd discovery/dns discovery 进行etcd的启动等，配置详情见官网。</p>
<h2 id="ETCD-使用"><a href="#ETCD-使用" class="headerlink" title="ETCD 使用"></a>ETCD 使用</h2><p>一般通过两种方式，rest api或者通过命令行（本质也是rest api）,下面简单介绍下这两种方式。在介绍前，先要弄懂几个概念：</p>
<ul>
<li>member： 指一个 etcd 实例。member 运行在每个 node 上，并向这一 node上的其它应用程序提供服务。</li>
<li>Cluster： Cluster 由多个 member 组成。每个 member 中的 node 遵循 raft共识协议来复制日志。Cluster 接收来自 member的提案消息，将其提交并存储于本地磁盘。</li>
<li>Peer： 同一 Cluster 中的其它 member。</li>
</ul>
<h3 id="命令行方式示例"><a href="#命令行方式示例" class="headerlink" title="命令行方式示例"></a>命令行方式示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> put foo <span class="string">"Hello World!"</span>  <span class="comment"># 写入操作</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> get foo  <span class="comment"># 读取操作</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> --write-out=<span class="string">"json"</span> get foo  <span class="comment"># 以json的方式输出</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> get web --prefix  <span class="comment"># 获取所有前缀是web 的key的value</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> del key  <span class="comment"># 删除</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> txn --interactive  <span class="comment"># 将多个命令封装在一个事务中</span></div><div class="line"></div><div class="line">compares:</div><div class="line">value(<span class="string">"user1"</span>) = <span class="string">"bad"</span>      </div><div class="line"></div><div class="line">success requests (get, put, delete):</div><div class="line">del user1  </div><div class="line"></div><div class="line">failure requests (get, put, delete):</div><div class="line">put user1 good</div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> watch stock1  <span class="comment"># 监视某个值</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> lease grant 300 <span class="comment">#设定租约</span></div><div class="line"><span class="comment"># lease 2be7547fbc6a5afa granted with TTL(300s)</span></div><div class="line"></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> put sample value --lease=2be7547fbc6a5afa <span class="comment"># 绑定租约</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> get sample <span class="comment"># 租约期限内可以获取值</span></div><div class="line"></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> lease keep-alive 2be7547fbc6a5afa <span class="comment"># 维持租约</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> lease revoke 2be7547fbc6a5afa  <span class="comment"># 撤销租约</span></div><div class="line"><span class="comment"># or after 300 seconds</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> get sample <span class="comment"># 撤销租约或者300s后获取不到值</span></div><div class="line">$ etcdctl --write-out=table --endpoints=<span class="variable">$ENDPOINTS</span> endpoint status <span class="comment"># 集群状态</span></div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> endpoint health</div><div class="line">$ etcdctl --endpoints=<span class="variable">$ENDPOINTS</span> snapshot save my.db <span class="comment"># 快照</span></div></pre></td></tr></table></figure>
<h3 id="rest-api-示例"><a href="#rest-api-示例" class="headerlink" title="rest api 示例"></a>rest api 示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">curl http://127.0.0.1:2379/v2/keys/message <span class="comment"># 获取某个key的value</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"action"</span>: <span class="string">"get"</span>,</div><div class="line">    <span class="string">"node"</span>: &#123;</div><div class="line">        <span class="string">"createdIndex"</span>: 2,</div><div class="line">        <span class="string">"key"</span>: <span class="string">"/message"</span>,</div><div class="line">        <span class="string">"modifiedIndex"</span>: 2,</div><div class="line">        <span class="string">"value"</span>: <span class="string">"Hello world"</span></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">curl http://127.0.0.1:2379/v2/keys/message -XPUT <span class="_">-d</span> value=<span class="string">"Hello etcd"</span> <span class="comment"># 更改 </span></div><div class="line">&#123;</div><div class="line">    <span class="string">"action"</span>: <span class="string">"set"</span>,</div><div class="line">    <span class="string">"node"</span>: &#123;</div><div class="line">        <span class="string">"createdIndex"</span>: 3,</div><div class="line">        <span class="string">"key"</span>: <span class="string">"/message"</span>,</div><div class="line">        <span class="string">"modifiedIndex"</span>: 3,</div><div class="line">        <span class="string">"value"</span>: <span class="string">"Hello etcd"</span></div><div class="line">    &#125;,</div><div class="line">    <span class="string">"prevNode"</span>: &#123;</div><div class="line">        <span class="string">"createdIndex"</span>: 2,</div><div class="line">        <span class="string">"key"</span>: <span class="string">"/message"</span>,</div><div class="line">        <span class="string">"value"</span>: <span class="string">"Hello world"</span>,</div><div class="line">        <span class="string">"modifiedIndex"</span>: 2</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">curl http://127.0.0.1:2379/v2/keys/message -XDELETE  <span class="comment">#删除 </span></div><div class="line">&#123;</div><div class="line">    <span class="string">"action"</span>: <span class="string">"delete"</span>,</div><div class="line">    <span class="string">"node"</span>: &#123;</div><div class="line">        <span class="string">"createdIndex"</span>: 3,</div><div class="line">        <span class="string">"key"</span>: <span class="string">"/message"</span>,</div><div class="line">        <span class="string">"modifiedIndex"</span>: 4</div><div class="line">    &#125;,</div><div class="line">    <span class="string">"prevNode"</span>: &#123;</div><div class="line">        <span class="string">"key"</span>: <span class="string">"/message"</span>,</div><div class="line">        <span class="string">"value"</span>: <span class="string">"Hello etcd"</span>,</div><div class="line">        <span class="string">"modifiedIndex"</span>: 3,</div><div class="line">        <span class="string">"createdIndex"</span>: 3</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="架构-amp-原理介绍"><a href="#架构-amp-原理介绍" class="headerlink" title="架构 &amp; 原理介绍"></a>架构 &amp; 原理介绍</h2><p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/etcd-arch-20170927110531.jpg" alt="etcd-arch"><br>etcd主要分为四个部分:</p>
<ul>
<li>HTTP Server： 用于处理用户发送的API请求以及其它etcd节点的同步与心跳信息请求。</li>
<li>Store：用于处理etcd支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是etcd对用户提供的大多数API功能的具体实现。</li>
<li>Raft：Raft强一致性算法的具体实现，是etcd的核心。</li>
<li>WAL：Write Ahead Log（预写式日志），是etcd的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd就通过WAL进行持久化存储。WAL中，所有的数据提交前都会事先记录日志。Snapshot是为了防止数据过多而进行的状态快照；Entry表示存储的具体日志内容。<br>通常，一个用户的请求发送过来，会经由HTTP Server转发给Store进行具体的事务处理，如果涉及到节点的修改，则交给Raft模块进行状态的变更、日志的记录，然后再同步给别的etcd节点以确认数据提交，最后进行数据的提交，再次同步。</li>
</ul>
<p>关于集群状态机的转变可以参考<a href="http://www.infoq.com/cn/articles/coreos-analyse-etcd" target="_blank" rel="external">CoreOS 实战：剖析 etcd</a></p>
<h2 id="服务发现工具对比"><a href="#服务发现工具对比" class="headerlink" title="服务发现工具对比"></a>服务发现工具对比</h2><p>引自<a href="http://dockone.io/article/667" target="_blank" rel="external">服务发现：Zookeeper vs etcd vs Consul</a>：</p>
<blockquote>
<blockquote>
<blockquote>
<p>所有这些工具都是基于相似的原则和架构，它们在节点上运行，需要仲裁来运行，并且都是强一致性的，都提供某种形式的键/值对存储。<br>Zookeeper是其中最老态龙钟的一个，使用年限显示出了其复杂性、资源利用和尽力达成的目标，它是为了与我们评估的其他工具所处的不同时代而设计的（即使它不是老得太多）。<br>etcd、Registrator和Confd是一个非常简单但非常强大的组合，可以解决大部分问题，如果不是全部满足服务发现需要的话。它还展示了我们可以通过组合非常简单和特定的工具来获得强大的服务发现能力，它们中的每一个都执行一个非常具体的任务，通过精心设计的API进行通讯，具备相对自治工作的能力，从架构和功能途径方面都是微服务方式。<br>Consul的不同之处在于无需第三方工具就可以原生支持多数据中心和健康检查，这并不意味着使用第三方工具不好。实际上，在这篇博客里我们通过选择那些表现更佳同时不会引入不必要的功能的的工具，尽力组合不同的工具。使用正确的工具可以获得最好的结果。如果工具引入了工作不需要的特性，那么工作效率反而会下降，另一方面，如果工具没有提供工作所需要的特性也是没有用的。Consul很好地权衡了权重，用尽量少的东西很好的达成了目标。<br>Consul使用gossip来传播集群信息的方式，使其比etcd更易于搭建，特别是对于大的数据中心。将存储数据作为服务的能力使其比etcd仅仅只有健/值对存储的特性更加完整、更有用（即使Consul也有该选项）。虽然我们可以在etcd中通过插入多个键来达成相同的目标，Consul的服务实现了一个更紧凑的结果，通常只需要一次查询就可以获得与服务相关的所有数据。除此之外，Registrator很好地实现了Consul的两个协议，使其合二为一，特别是添加Consul-template到了拼图中。Consul的Web UI更是锦上添花般地提供了服务和健康检查的可视化途径。</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://www.liuhaihua.cn/archives/404914.html" target="_blank" rel="external">etcd 使用入门</a></p>
<p><a href="https://coreos.com/etcd/docs/latest/v2/api.html" target="_blank" rel="external">etcd API</a></p>
<p><a href="https://poweruphosting.com/blog/etcd-tutorial/" target="_blank" rel="external">Etcd Tutorial- The Ultimate Reliable Key Value Storage for Networks</a></p>
<p><a href="https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products/" target="_blank" rel="external">服务发现比较:Consul vs Zookeeper vs Etcd vs Eureka</a></p>
<p><a href="http://www.infoq.com/cn/articles/coreos-analyse-etcd" target="_blank" rel="external">CoreOS 实战：剖析 etcd</a></p>
<p><a href="http://lihaoquan.me/2016/6/24/learning-etcd-1.html" target="_blank" rel="external">深入学习Etcd</a></p>
<p><a href="http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle" target="_blank" rel="external">etcd：从应用场景到实现原理的全方位解读</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/08/03/intro-to-harbor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/03/intro-to-harbor/" itemprop="url">
                  Docker-- 关于Harbor 的一些记录
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-03T11:59:11+08:00">
                2017-08-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/08/03/intro-to-harbor/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/03/intro-to-harbor/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Harbor-简介"><a href="#Harbor-简介" class="headerlink" title="Harbor 简介"></a>Harbor 简介</h2><p><a href="https://github.com/vmware/harbor" target="_blank" rel="external">Harbor</a> 是 Vmware China研发开源的企业级私有容器Registry,基于docker官方的解决方案<a href="https://github.com/docker/distribution" target="_blank" rel="external">Distribution</a>。目前来说，已经成为企业级私有容器仓库的首选（主要是可供选择的本来就不多，可能是因为镜像管理不像容器编排那样是必争之地）。相对于Docker Distribution，Harbor添加了安全，认证，管理等功能，性能以及安全性都得到提升，主要 features如下：</p>
<ul>
<li>基于角色的访问控制：用户和镜像仓库通过project来组织管理，一个用户对同一project的不同镜像仓库会有不同处理权限。</li>
<li>基于策略的镜像复制：多个registry实例可以实现镜像同步复制，对于load-balancing,高可用，多数据中心，混合云的情景非常有用。</li>
<li>支持 LDAP/AD</li>
<li>镜像删除 &amp; 垃圾回收</li>
<li>镜像的认证</li>
<li>友好的UI</li>
<li>日志审计：所有的操作都是可追踪的</li>
<li>RESTful API</li>
<li>易部署 </li>
</ul>
<h2 id="Harbor-架构与原理"><a href="#Harbor-架构与原理" class="headerlink" title="Harbor 架构与原理"></a>Harbor 架构与原理</h2><h3 id="Harbor-整体架构"><a href="#Harbor-整体架构" class="headerlink" title="Harbor 整体架构"></a>Harbor 整体架构</h3><p>Harbor 是以容器的方式运行，以docker-compose的规范形式组织各个组件，并通过docker-compose工具进行启停。<br>Harbor共有五个组件，分别如下：</p>
<ul>
<li>Proxy:Harbor服务的所有请求都由该服务接受并转发，其实就是一个前置的反向代理Nginx，类似于微服务概念中的API-gateway.</li>
<li>Registry: 即docker 官方的Registry镜像生成的容器示例，真正负责存贮镜像的地方，处理docker pull/push。针对不同的用户对不同的镜像操作权限不同，registry强制每个请求必须含有一个token以验证权限，如果没有token，会返回一个token服务地址。</li>
<li>Core Services: 主要提供UI,webhook(设置在registry上以获取镜像状态)，token服务。</li>
<li>Database:数据库服务Mysql，存储用户，权限，审计日志，镜像信息等。</li>
<li>Log Collector: 日志收集，跑一个Rsylogd服务。</li>
</ul>
<p>架构图如下：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-08-03.harbor-arc.jpg" alt="harbor-arch"></p>
<p>这五个容器之间通过docker-link相连，即通过容器名字互相访问，暴露Proxy服务的端口给终端用户访问。</p>
<h3 id="Harbor-工作原理"><a href="#Harbor-工作原理" class="headerlink" title="Harbor 工作原理"></a>Harbor 工作原理</h3><p>以docker login 与 docker push为例讲解：</p>
<p>客户端 输入docker login 之后，流程如下图：<br><img src="http://oeptotikb.bkt.clouddn.com/2017-08-03-harbor-flow1.jpg" alt="docker-login-flow"></p>
<p>(a) 首先，这个登录请求会被Proxy容器接收到，根据预先设置的匹配规则，该请求会被转发给后端Registry容器。<br>(b) Registry接收到请求后，解析请求，因为配置了基于token的认证，所以会查找token，发现请求没有token 后，返回错误代码401以及token服务的地址URL。<br>(c) Docker客户端接收到错误请求后，转而向token服务地址发送请求，并根据HTTP协议的BasicAuthentication 规范，将用户名密码组合并编码，放在请求头部(header)。<br>(d) 同样，该请求会先发到Proxy容器，继而转发给ui/token的容器,该容器接受请求，将请求头解码，获取到用户名密码。<br>(e) ui/token的容器获取到用户名密码后，通过查询数据库进行比对验证(如果是LDAP 的认证方式,就是与LDAP服务进行校验)，比对成功后，返回成功的状态码，并用密钥生成token，一并发送给Docker客户端。</p>
<p>客户端 登陆成功后，输入docker push xxxxxx 之后，流程如下图（便于说明省略Docker client与Proxy之间通信）：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-08-03-harbor-flow-2.jpg" alt="docker-push-flow"></p>
<p>(a) 同样，首先与Registery通信，返回一个token服务的地址URL.<br>(b) Docker客户端会与token服务通信，指明要申请一个push image操作的token。<br>(c) token服务访问数据库验证当前用户是否有该操作的权限，如果有，会将image信息以及push操作进行编码，用私钥签名，生成token返回给Docker客户端。<br>(d) Docker客户端再次与Registry通信，不过这次会将token放到请求header中，Registry收到请求后利用公钥解码并核对，核对成功，便可以开始push 操作了。</p>
<h2 id="Harbor-安装"><a href="#Harbor-安装" class="headerlink" title="Harbor 安装"></a>Harbor 安装</h2><p>比较简单：</p>
<ol>
<li>准备：python&gt;=2.7, docker&gt;=1.10, docker-compose&gt;=1.6.0</li>
<li>下载离线安装包</li>
<li>修改配置文件 harbor.cfg</li>
<li>执行脚本install.sh </li>
</ol>
<p>参考<a href="https://github.com/vmware/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="external">Installation and Configuration Guide</a></p>
<h2 id="Harbor-高可用"><a href="#Harbor-高可用" class="headerlink" title="Harbor 高可用"></a>Harbor 高可用</h2><p>对于Harbor高可用方案，目前并没有最佳实践，不过我看issues上有不少相关内容，可以参考<a href="https://github.com/vmware/harbor/issues/327" target="_blank" rel="external">Harbor HA feature design proposal/discussion</a>。<br>其实，私有云相对来说对镜像的请求并非高频，在做HA的时候还是结合实际情况，切勿为了HA而HA,还要综合考量成本，安全等因素。</p>
<p>这部分内容暂且留个坑，以后再写。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://segmentfault.com/a/1190000007705296" target="_blank" rel="external">VMware Harbor：基于 Docker Distribution 的企业级 Registry 服务</a></p>
<p><a href="http://tonybai.com/2017/06/09/setup-a-high-availability-private-registry-based-on-harbor-and-cephfs/" target="_blank" rel="external">基于Harbor和CephFS搭建高可用Private Registr</a></p>
<p><a href="https://github.com/vmware/harbor" target="_blank" rel="external">vmware/harbor</a></p>
<p><a href="http://jaminzhang.github.io/docker/Enterprise-class-private-Docker-Container-Registry-Harbor-deploying/" target="_blank" rel="external">Docker 企业级私有镜像仓库 Harbor 部署</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/07/20/few-problems-met-in-openstack/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/few-problems-met-in-openstack/" itemprop="url">
                  Openstack-- 最近遇到的几个Openstack问题小结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-20T16:59:11+08:00">
                2017-07-20
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/07/20/few-problems-met-in-openstack/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/20/few-problems-met-in-openstack/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="win7虚拟机CPU核数不变问题"><a href="#win7虚拟机CPU核数不变问题" class="headerlink" title="win7虚拟机CPU核数不变问题"></a>win7虚拟机CPU核数不变问题</h2><p>问题描述：虚拟机镜像为win7系统，配置为4cpu的时候，发现设备管理器显示为4cpu，但是任务管理器智能识别2cpu，如下图。</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-07-24-renwu.png" alt="shebei"></p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-07-24-shebei.png" alt="renwu"></p>
<p>问题解决：刚开始以为是win7系统引导项中限制到2核，更改后问题没有解决，更换镜像后问题依旧，后经过搜索得出答案:首先需要了解kvm的cpu虚拟化原理，可以参考<a href="http://www.cnblogs.com/sammyliu/p/4543597.html" target="_blank" rel="external">KVM 介绍（2）：CPU 和内存虚拟化</a>,简单来说，一个KVM虚拟机就是一个Linux qemu-kvm进程，内存就是该进程的地址空间的一部分，虚拟机的vcpu作为线程运行在该进程的上下文，逻辑关系如下：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-07-24-kvm-topology.jpg" alt="kvm-topology"><br>我们用kvm命令创建虚拟机时有几个概念，<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kvm -m 2048 -smp 4,sockets=4,cores=1,threads=1 -drive file=win7_x64_pure</div></pre></td></tr></table></figure></p>
<p>其中，smp 指定为4 ，默认后面什么都不加的话，相当于是sockets=4,cores=1,threads=1，简单解释下socket是cpu的物理单位，core是每个cpu中的物理内核，thread是利用超线程技术实现的一个core虚拟化出的逻辑cpu个数。也就是说，客户机操作系统看到的cpu核数是上述三个数值的乘积，至于使用多socket，还是多core，可以参考<a href="http://frankdenneman.nl/2013/09/18/vcpu-configuration-performance-impact-between-virtual-sockets-and-virtual-cores/" target="_blank" rel="external">vCPU configuration. Performance impact between virtual sockets and virtual cores?</a>。<br>回到之前的问题，openstack默认的max-sockets是4，也就是说只要socket没有特殊指定，且小于等于4，那么逻辑核数就是socket的个数。比如，创建一个4核的kvm虚拟机，那么openstack默认对应kvm命令为kvm -smp 4,sockets=4,cores=1,threads=1。而在某些客户机操作系统会限制物理 CPU （这里即socket）的数目,比如win7操作系统限制2个win，Windows Server 2008 R2 Standard Edition 限制4个。这种情况下，我们就需要更改cpu topology,比如win7,为了实现4核，可以利用以下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kvm -m 2048 -smp 4,sockets=2,cores=1,threads=2 -drive file=win7_x64_pure</div></pre></td></tr></table></figure></p>
<p>更多cpu topology 的知识，参考<a href="https://wiki.openstack.org/wiki/VirtDriverGuestCPUTopology" target="_blank" rel="external">VirtDriverGuestCPUTopology</a>。<br>回到openstack的话，我们可以给镜像添加合适的 max-sockets来解决此类问题，在win 7的镜像里加上一个属性, hw_max_sockets=2即可。</p>
<h2 id="虚拟机调整配额失败"><a href="#虚拟机调整配额失败" class="headerlink" title="虚拟机调整配额失败"></a>虚拟机调整配额失败</h2><p>问题描述：如题，对已经启动的虚拟机调整配额，没有反应。<br>问题解决：找到对应计算节点，查看nova-compute日志发现错误原因，错误日志如下：<br><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-07-24-error-log.png" alt="nova-compute-error"></p>
<p>无法ssh到目标节点，查阅相关资料后，得出resize命令需要设置nova用户在节点之间的passwordless authentication，解决如下：</p>
<ul>
<li>sudo -u nova ssh-keygen   # 生成nova的密钥</li>
<li><p>ssh-copy-id nova@<serverip> #复制公钥到目的节点</serverip></p>
<p>tips:复制公钥的过程中如果报错“This account is currently not available”，可能是因为用户nova的shell禁止登录了，修改/etc/passwd 中nova对应的shell登录部分由“/sbin /nologin”改成“/bin/bash”。</p>
</li>
</ul>
<h2 id="ceph-节点资源耗尽"><a href="#ceph-节点资源耗尽" class="headerlink" title="ceph 节点资源耗尽"></a>ceph 节点资源耗尽</h2><p>问题描述：公司有个生产环境的云平台，因为前期的滥用，导致存储资源耗费非常严重，已经出现2个计算节点near full，这会导致出现一系列问题，比如虚拟机卡顿，无法访问等问题。<br>解决方案：</p>
<ul>
<li>删除不用的虚拟机，镜像等垃圾文件，如果出现无法删除的情况，直接利用rbd命令尝试下，如果还是无法删除，应该是对应osd达到full状态而拒绝客户端操作命令了，只能换个方法。</li>
<li>如果条件允许的话，最好是增加OSD节点，然后再平衡就OK了，不过再平衡的时间太长，对于线上业务是无法接受的。</li>
<li>通过rewight命令手动修改对应osd wight值，比如，对于处于near full/full状态的osd，我们减小其对应的weight值，适当增大有较多剩余空间的osd的weight值。调整的过程中不要一下全部更改，需要调整一下，看下效果，避免因为改动过大出现大范围的再平衡导致时间过长。</li>
<li>在osd 再平衡期间，增加mon-osd-full-ratio/mon osd nearfull ratio值（未验证） </li>
</ul>
<h2 id="Failed-to-allocate-the-network-s-not-rescheduling"><a href="#Failed-to-allocate-the-network-s-not-rescheduling" class="headerlink" title="Failed to allocate the network(s), not rescheduling."></a>Failed to allocate the network(s), not rescheduling.</h2><p>创建虚拟机的时候报如标题所述错误，查看详细日志，可以看出是Virtual Interface creation failed.</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-08-09-CREATIO-INTERFACE-FAIL.png" alt="virtual-interface-fail"></p>
<p>自然想到可能是Virtual Interface 创建失败导致创建虚拟机失败，查看neutron-server日志，发现如下信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2017-08-09 11:21:08.499 154120 WARNING neutron.notifiers.nova [-] Nova returned NotFound <span class="keyword">for</span> event: [&#123;<span class="string">'tag'</span>: u<span class="string">'a653baaf-828d-4641-aabb-1a82c5163889'</span>, <span class="string">'name'</span>: <span class="string">'network-vif-deleted'</span>, <span class="string">'server_uuid'</span>: u<span class="string">'4fdf7471-bece-4d93-       a044-a4052284c69b'</span>&#125;]</div></pre></td></tr></table></figure></p>
<p>也就是说nova没有接受到network-vif-deleted的event，查看具体出错代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_domain_and_network</span><span class="params">(self, context, xml, instance, network_info,</span></span></div><div class="line">                               disk_info, block_device_info=None,</div><div class="line">                               power_on=True, reboot=False,</div><div class="line">                               vifs_already_plugged=False):</div><div class="line">   ...............................................................</div><div class="line">    <span class="keyword">except</span> eventlet.timeout.Timeout:</div><div class="line">        <span class="comment"># We never heard from Neutron</span></div><div class="line">        LOG.warn(_LW(<span class="string">'Timeout waiting for vif plugging callback for '</span></div><div class="line">                     <span class="string">'instance %(uuid)s'</span>), &#123;<span class="string">'uuid'</span>: instance.uuid&#125;,</div><div class="line">                 instance=instance)</div><div class="line">        <span class="keyword">if</span> CONF.vif_plugging_is_fatal:   <span class="comment">#关键在这行</span></div><div class="line">            <span class="keyword">if</span> guest:</div><div class="line">                guest.poweroff()</div><div class="line">            self.cleanup(context, instance, network_info=network_info,</div><div class="line">                         block_device_info=block_device_info)</div><div class="line">            <span class="keyword">raise</span> exception.VirtualInterfaceCreateException()</div></pre></td></tr></table></figure>
<p>可以看到在nova-compute调用_create_domain_and_network函数的时候，会一直等待vif 的创建eventlet（由openvswitch-agent创建并返回evetlet），等待timeout时间之后，如果配置文件中vif_plugging_is_fatal=True,就会创建失败并回滚，如果vif_plugging_is_fatal=False就会略过。<br>明白原理后就简单了，只需修改nova配置文件中vif_plugging_is_fatal=False就可以了，至于为什么nova没有收到eventlet，还有待深入。这一部分可以参考<a href="http://blog.csdn.net/bc_vnetwork/article/details/52231418" target="_blank" rel="external">nova network-vif-plugged事件分析1</a>.</p>
<p>注：排错过程有个小插曲，我修改完配置文件后再重启nova-compute还是没效果，果断打断点调试，结果发现断点直接略过了，百思不得其解，折腾半天后，发现是有一个残留的nova-compute的进程一直在跑，kill掉之后，再启动就可以了。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://www.cnblogs.com/sammyliu/p/4543597.html" target="_blank" rel="external">KVM 介绍（2）：CPU 和内存虚拟化</a></p>
<p><a href="http://www.pystack.org/openstack-windows7-cpu-core-count-display-inconsistencies/" target="_blank" rel="external">Openstack Windows7 CPU核数显示不一致</a></p>
<p><a href="http://frankdenneman.nl/2013/09/18/vcpu-configuration-performance-impact-between-virtual-sockets-and-virtual-cores/" target="_blank" rel="external">vCPU configuration. Performance impact between virtual sockets and virtual cores?</a></p>
<p><a href="http://lists.openstack.org/pipermail/openstack-operators/2013-January/002424.html" target="_blank" rel="external">Host key verification failed on VM Resize</a></p>
<p><a href="http://docs.ceph.com/docs/master/cephfs/full/" target="_blank" rel="external">HANDLING A FULL CEPH FILESYSTEM</a></p>
<p><a href="http://xiaoquqi.github.io/blog/2015/05/12/ceph-osd-is-full/" target="_blank" rel="external">Ceph集群磁盘没有剩余空间的解决方法</a></p>
<p><a href="http://blog.csdn.net/bc_vnetwork/article/details/52231418" target="_blank" rel="external">nova network-vif-plugged事件分析1</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/06/30/tangle-with-nova-network/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/30/tangle-with-nova-network/" itemprop="url">
                  Openstack-- nova-network 网络实现一窥
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-30T09:16:11+08:00">
                2017-06-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/30/tangle-with-nova-network/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/06/30/tangle-with-nova-network/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="引出"><a href="#引出" class="headerlink" title="引出"></a>引出</h2><p>nova-network 是Neutron（或Quantum）之前，openstack 的网络管理项目，随着Neutron项目的愈发成熟，nova-network 也随之逐渐被弃用。<br>不过，其实 nova-network 还是非常好用的，相对neutron 来说，简单轻便，也经受过生产环境的验证。而且，可以通过简单配置将虚拟机二层网络与真实物理网络打通，实现利用fixed-ip就可以直接访问虚拟机的单网络环境。<br>本文主要总结下 nova-network 的网络管理以及实现原理，并与neutron 做一下比较。</p>
<h2 id="nova-network-网络类型"><a href="#nova-network-网络类型" class="headerlink" title="nova-network 网络类型"></a>nova-network 网络类型</h2><p>nova-network 支持两种网络类型（确切地说是三种，这里将Flat与FlatDHCP看做一类），分别是Flat/FlatDHCP 和 Vlan类型。</p>
<h3 id="FlatManager-and-FlatDHCPManager"><a href="#FlatManager-and-FlatDHCPManager" class="headerlink" title="FlatManager and FlatDHCPManager"></a>FlatManager and FlatDHCPManager</h3><p>顾名思义，flat即扁平化，也就是说所有的虚拟机都在一个大的二层网络空间内，这种网络模式一般生产环境中很少用，多用于POC阶段。<br>关于flat networking，我在openstack 上找到一篇<a href="https://wiki.openstack.org/wiki/UnderstandingFlatNetworking" target="_blank" rel="external">wiki</a>，讲解的比较清楚。可惜wiki 上只有讲解flat的，没有其他网络类型。</p>
<p>这里借上文中的一张图简单说下flat这种网络类型，以多节点，多网卡为例：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-FlatNetworkMultInterface.png" alt="multi-host-1"></p>
<p>由图看出，计算节点内都有一个网桥br100与 物理网卡eth0相连，计算节点内的虚拟机通过该网桥与控制节点的对应物理网卡连接实现通信。<br>虚拟机实现南北通信大致如下图：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-MultiInterfaceOutbound_2.png" alt="multi-host-2"></p>
<p>flatDHCP 其实就是在计算节点再运行一个dnsmasp来提供DHCP服务，就不需要借助外部的DHCP服务，两者对比大致如下：</p>
<p>flat networking :</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-flatdhcp.png" alt="flat"></p>
<p>flatDHCP networking:</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/QQ%E6%88%AA%E5%9B%BE20170630144105.png" alt="flat-dhcp"></p>
<h3 id="VlanManager"><a href="#VlanManager" class="headerlink" title="VlanManager"></a>VlanManager</h3><p>flat networking 有一个很大的缺点就是所有虚拟机都在一个二层网络，没有租户间的网络隔离，不够灵活，且广播风暴的影响太大，这种情况下，vlan 就出现了。</p>
<p>vlan 网络或给每个租户创建一个（或多个）二层网络，且这些二层网络相互隔离。不过这种网络类型需要支持vlan tag的交换机才可以使用。</p>
<h2 id="nova-network-网络实现原理"><a href="#nova-network-网络实现原理" class="headerlink" title="nova-network 网络实现原理"></a>nova-network 网络实现原理</h2><p>简单介绍下各自的实现原理</p>
<h3 id="Flat-FlatDHCP网络实现原理"><a href="#Flat-FlatDHCP网络实现原理" class="headerlink" title="Flat/FlatDHCP网络实现原理"></a>Flat/FlatDHCP网络实现原理</h3><p>Flat类型的基本上上文已经讲了，主要看下flatDHCP 的实现：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-flat-dhcp-real.png" alt="flat-dhcp"></p>
<p>跟flat类似，不过在计算节点的网桥上会有一个dnsmasq进程监听并实现该节点的虚拟机IP动态分配。<br>还有一点要注意的是，不同计算节点的虚拟机内网关也不同，比如，上图中，vm_1与vm_2的网关都是10.10.0.1，但在右边计算节点的vm_3 和vm_4的网关却是10.10.0.4。</p>
<h3 id="Vlan实现原理"><a href="#Vlan实现原理" class="headerlink" title="Vlan实现原理"></a>Vlan实现原理</h3><p>一图胜千言：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-vlanmanager-2-hosts-2-tenants.png" alt="multi-host-vlan"></p>
<p>上面这幅图就是vlan模式部署最为广泛的场景，即multi-node模式，也就是说不光是网络节点需要运行nova-network服务，计算节点也要运行nova-network（还需要运行nova-api以提供metadata服务），这样就避免出现SPOF,也可以达到分流的作用（跟neutron 的DVR很类似，估计DVR就是借鉴了这里）。<br>需要注意的是每个vlan网桥都是租户独占的，且会创建vlan接口如vlan102,依据802.1q协议打vlanid，与网关eth0连接。Dnsmasq监听网桥网关，负责fixedip的分配。switch port设定为chunk mode。eth0负责vm之间的数据通信，另一网卡如eth1负责外网访问。上图只是显示了一个网卡，如下图是一个多网卡的情况：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-30-multi-host-vlan.png" alt="vlan-multi-host"></p>
<h2 id="nova-network-vs-neutron"><a href="#nova-network-vs-neutron" class="headerlink" title="nova-network vs neutron"></a>nova-network vs neutron</h2><p>之前总结过一篇关于<a href="https://zhangchenchen.github.io/2017/02/12/neutron-layer2-3-realization-discovry/">neutron 实现二三层网络的总结</a>,就功能性来说，nova-network 只支持两种网络类型，neutron增加了overlay network 的支持，如vxlan/gre, 突破了vlan id个数限制从而支持更多数目的二层网络。而且nova-network 即使是不同租户间，也不允许使用相同的网段，因为租户网络是通过ip+vlan的形式来区分，neutron 就完全可以。<br>但也不是nova-network 就一文不取，相比于neutron网络，虽说没有neutron那么多的功能插件，仅有bridge，但是其稳定性已得到大多数用户的验证，对于小规模的私有云(1千台虚机的规模)，nova-network是可以考虑的。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.mirantis.com/blog/openstack-networking-flatmanager-and-flatdhcpmanager/" target="_blank" rel="external">OpenStack Networking – FlatManager and FlatDHCPManager</a></p>
<p><a href="https://www.mirantis.com/blog/openstack-networking-vlanmanager/" target="_blank" rel="external">Openstack Networking for Scalability and Multi-tenancy with VlanManager</a></p>
<p><a href="https://github.com/gc3-uzh-ch/gridka-school/blob/master/tutorial/nova_network.rst" target="_blank" rel="external">Network service - easy version - nova-network</a></p>
<p><a href="https://docs.openstack.org/admin-guide/compute-networking-nova.html" target="_blank" rel="external">Networking with nova-network</a></p>
<p><a href="http://blog.csdn.net/beginning1126/article/details/41172365" target="_blank" rel="external">openstack 网络架构 nova-network + neutron</a></p>
<p><a href="https://wiki.openstack.org/wiki/UnderstandingFlatNetworking" target="_blank" rel="external">UnderstandingFlatNetworking</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/06/26/cobbler-test-with-virtualbox/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/26/cobbler-test-with-virtualbox/" itemprop="url">
                  Devops-- 借助virtualbox 初次实践 cobbler
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-26T00:16:11+08:00">
                2017-06-26
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/26/cobbler-test-with-virtualbox/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/06/26/cobbler-test-with-virtualbox/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Cobbler-简介"><a href="#Cobbler-简介" class="headerlink" title="Cobbler 简介"></a>Cobbler 简介</h2><p>Cobbler 是由Python 语言开发，实现在网络安装环境中快速的安装linux 系统。<br>在没有出现Cobbler之前，我们通常是通过使用Kickstart 来进行自动化安装操作系统，但是kickstart 并未实现完全的自动化，我们依然需要安装配置各种服务（DHCP,TFTP,HTTP等），编写kickstart 脚本（即ks.cfg文件）等等。<br>Cobbler可以看做是在kickstart项目上的一层封装，融合了DHCP,TFTP，PXE等一系列服务，提供了CLI和web两种管理形式，使得网络安装操作系统更加方便，同时也提供了API接口方便二次开发。</p>
<h2 id="Cobbler-原理概述"><a href="#Cobbler-原理概述" class="headerlink" title="Cobbler 原理概述"></a>Cobbler 原理概述</h2><p>Cobbler 是典型的CS架构，我们只需要在服务端做好相应的安装配置，客户端设置PXE网络启动即可。整体的运作流程如下，图片来自<a href="https://wsgzao.github.io/post/cobbler/" target="_blank" rel="external">Cobbler自动化安装配置实践</a>:</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-25-cobbler-process.jpeg" alt="cobbler-process"></p>
<h2 id="Cobbler-实践"><a href="#Cobbler-实践" class="headerlink" title="Cobbler 实践"></a>Cobbler 实践</h2><p>本次试验借助 VirtualBox 实现：</p>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ul>
<li>下载 centos7-minimal 镜像，并使用该镜像开启一个虚拟机guest#1</li>
<li>注意网络配置 两个网卡，一个是bridge模式，便于利用xshell等工具连接，一个是设为内部网络。</li>
<li>安装完毕后，设置第二个网卡的静态IP，不要与第一个网卡的网络重复，之后会用第二个网卡所在的局域网进行网络安装。</li>
</ul>
<h3 id="Cobbler-安装"><a href="#Cobbler-安装" class="headerlink" title="Cobbler 安装"></a>Cobbler 安装</h3><p>参照 官网<a href="https://cobbler.github.io/manuals/2.6.0/2/2/2_-_RHEL_and_CentOS.html" target="_blank" rel="external">Red Hat Entperise Linux</a></p>
<p>注：安装需要用到 epel源，因为是Centos，只需 yum install epel-release 即可。</p>
<h3 id="Cobbler-配置"><a href="#Cobbler-配置" class="headerlink" title="Cobbler 配置"></a>Cobbler 配置</h3><p>参考官网<a href="https://cobbler.github.io/manuals/quickstart/" target="_blank" rel="external">Cobbler Quickstart Guide</a></p>
<p>注：</p>
<ul>
<li>利用cobbler check 查看配置错误，有些地方并非必须修改。</li>
<li>server 与 next-server设置为第二块网卡的ip</li>
</ul>
<h3 id="Cobbler-各目录说明"><a href="#Cobbler-各目录说明" class="headerlink" title="Cobbler 各目录说明"></a>Cobbler 各目录说明</h3><p>配置文件目录：/etc/cobbler</p>
<ul>
<li>/etc/cobbler/settings：cobbler 主配置文件</li>
<li>/etc/cobbler/iso/：iso 模板配置文件</li>
<li>/etc/cobbler/pxe：pxe 模板文件</li>
<li>/etc/cobbler/power：电源的配置文件</li>
<li>/etc/cobbler/users.conf：Web 服务授权配置文件</li>
<li>/etc/cobbler/users.digest：用于 web 访问的用户名密码配置文件</li>
<li>/etc/cobbler/dhcp.template：DHCP 服务的配置模板</li>
<li>/etc/cobbler/dnsmasq.template：DNS 服务的配置模板</li>
<li>/etc/cobbler/tftpd.template：tftp 服务的配置模板</li>
<li>/etc/cobbler/modules.conf：Cobbler 模块配置文件</li>
</ul>
<p>数据目录：/var/lib/cobbler</p>
<ul>
<li>/var/lib/cobbler/config/：用于存放 distros、systems、profiles 等信息配置文件</li>
<li>/var/lib/cobbler/triggers：用于存放用户定义的 cobbler 命令</li>
<li>/var/lib/cobbler/kickstarts/：默认存放 kickstart 文件</li>
<li>/var/lib/cobbler/loaders：存放各种引导程序</li>
</ul>
<p>镜像数据目录：/var/www/cobbler</p>
<ul>
<li>/var/www/cobbler/ks_mirror/：导入的发行版系统的所有数据</li>
<li>/var/www/cobbler/images/：导入发行版的 Kernel 和 initrd 镜像用于远程网络启动（ks_mirror 下对应发行版 系统的软链）</li>
<li>/var/www/cobbler/repo_mirror/：repo 仓库存储目录</li>
</ul>
<p>日志目录：/var/log/cobbler/</p>
<ul>
<li>/var/log/cobbler/install.log：客户端系统安装日志</li>
<li>/var/log/cobbler/cobbler.log：cobbler日志</li>
</ul>
<h3 id="Cobbler-使用"><a href="#Cobbler-使用" class="headerlink" title="Cobbler 使用"></a>Cobbler 使用</h3><ul>
<li>利用lrzsz命令上传 centos7-minimal 镜像至虚拟机guest#1.</li>
<li><p>本地挂载镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -o loop ./CentOS-7-x86_64-Minimal-1611.iso /mnt</div></pre></td></tr></table></figure>
</li>
<li><p>导入镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cobbler import --name=centos7 --arch=x86_64 --path=/mnt</div></pre></td></tr></table></figure>
</li>
<li><p>执行 cobbler sync命令</p>
</li>
<li>virtualbox 开启另一个虚拟机，一个网卡，设置为内部网络，adaptor type 为PC-Net III （为了PXE boot）。设置启动方式为网络启动优先。</li>
</ul>
<h2 id="Cobbler-常用命令行"><a href="#Cobbler-常用命令行" class="headerlink" title="Cobbler 常用命令行"></a>Cobbler 常用命令行</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ cobbler list        <span class="comment">#列出相关cobber元素(distros和profile)</span></div><div class="line">$ cobbler check       <span class="comment">#检查cobbler配置(一般会提示需要进行怎样的配置)</span></div><div class="line">$ cobbler report      <span class="comment">#列出cobbler的详细信息</span></div><div class="line">$ cobbler distro      <span class="comment">#查看导入的相关系统发行版信息</span></div><div class="line">$ cobbler profile     <span class="comment">#查看cobbler创建的相关pofile信息</span></div><div class="line">$ cobbler sync        <span class="comment">#同步cobbler相关配置(最好每次执行完配置后都进行修改)</span></div><div class="line">$ cobbler reposync    <span class="comment">#同步repo源</span></div></pre></td></tr></table></figure>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ul>
<li>TFTP Timed out : guest#1的TFTP Server 没有启动造成。</li>
<li>failed to start switch root：<a href="https://www.centos.org/forums/viewtopic.php?t=57419" target="_blank" rel="external">dracut cant locate /dev/root</a></li>
<li>如果是某台机器需要重装系统的话，需要在该机器上安装koan，利用koan命令：koan –replace-self –server=10.45.249.102 –profile=rhel6.6-64-x86_64 进项镜像的拉取以及重装</li>
</ul>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://cobbler.github.io/" target="_blank" rel="external">Cobbler doc</a></p>
<p><a href="https://zh.wikipedia.org/wiki/Cobbler_(%E8%BD%AF%E4%BB%B6" target="_blank" rel="external">cobbler wiki</a>)</p>
<p><a href="https://wsgzao.github.io/post/cobbler/" target="_blank" rel="external">Cobbler自动化安装配置实践</a></p>
<p><a href="http://cuchadanfan.blog.51cto.com/9940284/1698348" target="_blank" rel="external">自动化运维工具Cobbler</a></p>
<p><a href="http://www.webscalability.com/blog/2013/03/testing-out-cobbler-with-virtuabox/" target="_blank" rel="external">Testing out cobbler with virtuabox</a></p>
<p><a href="http://www.bijishequ.com/detail/50880?p=" target="_blank" rel="external">主机自动化部署之cobbler总结</a></p>
<p> <strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/06/20/neutron-dvr/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/neutron-dvr/" itemprop="url">
                  openstack-- neutron 分布式虚拟路由（DVR）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-20T14:30:32+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/20/neutron-dvr/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/06/20/neutron-dvr/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="引出"><a href="#引出" class="headerlink" title="引出"></a>引出</h2><p>公司有个测试云平台的虚拟机密码初始化出现了问题，根据之前的经验可能跟<a href="https://zhangchenchen.github.io/2017/02/17/openstack-instance-metadata-discovery/">这篇</a>问题一样,没想到花费了将近一天的时间才将问题解决，发现最终是跟neutron 分布式虚拟路由有关，这里记录一下。</p>
<p>问题是这样的：nova boot的时候传入 user-data（user-data中含有需要修改的密码），instance起来的时候会执行cloud-init，然后会使用EC2的datasource方式（即“169.254.169.254”）去获取user-data，然而发现密码没有更改，查看日志发现,发现获取user-data时，报错如下</p>
<blockquote>
<p>Calling ‘<a href="http://169.254.169.254/2009-04-04/meta-data/instance-id" target="_blank" rel="external">http://169.254.169.254/2009-04-04/meta-data/instance-id</a>‘ failed [0/120s]: bad status code [500]</p>
</blockquote>
<p>初步断定就是instance metadata 的某个环节网络不通。</p>
<h2 id="问题发现"><a href="#问题发现" class="headerlink" title="问题发现"></a>问题发现</h2><ul>
<li>第一步想到的就是重启下相关服务，将neutron-metada-agent,neutron-l3-agent,nova-api重启后发现问题依旧。</li>
<li>查看相关日志，没有找到有关报错信息，而且奇怪的是网络节点对应的neutron-ns-metadata-proxy-xxxxxxxxx.log都没有处理请求的日志，说明请求可能没有走到这里。</li>
<li>只能按照请求的处理步骤一步步排查，首先确定虚拟机所在的网络是有路由器相连的，所以metadata请求是走的路由器的namespace，相关知识参考<a href="https://zhangchenchen.github.io/2017/02/17/openstack-instance-metadata-discovery/">openstack– openstack instance metadata 服务机制探索</a>,网络节点对应路由器的namespace中一切正常，9697 端口的重定向，以及监听9697端口的neutron-metadata-ns-proxy进程也正常。没办法，在该路由器的namespace中对应端口抓包试试，虚拟机中发送169.254.169.254，却一点反应没有，断定请求压根就没有走到该路由器的namespace。只能返回去虚拟机实例中抓包试试，使用traceroute命令发现请求是发到对应网关的，而对应网关就应该在路由器的namespace中啊，到这里基本就蒙逼了。</li>
<li>在经过一番徒劳无功的试错后，终于找到了一点线索。我在查看neutron agent状态的时候，发现neutron-l3-agent不只是在网络节点，计算节点也存在neutron-l3-agent，立马想到neutron-l3-agent会在本地计算节点也创建虚拟路由器，所以获取metadata的请求就发送到本地计算节点的路由器 namespace，果然，本地计算节点也有一个路由器，抓包发现确实是发送到了这里，而且该节点对应网络的neutron-ns-metadata-proxy-xxxxxxxxx.log发现了 socket.error报错信息，说明neutron-ns-metadata-proxy通过 unix domian socket 转发给 neutron-metadata-agent的时候出现了问题。本能的想是不是配置错误导致的，查看l3-agent的配置文件时发现有个配置项：agent_mode = dvr ，赶紧搜了一下，终于找到了进入的正确姿势。</li>
</ul>
<h2 id="neutron-分布式虚拟路由（DVR）"><a href="#neutron-分布式虚拟路由（DVR）" class="headerlink" title="neutron 分布式虚拟路由（DVR）"></a>neutron 分布式虚拟路由（DVR）</h2><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>neutron 的DVR 是属于openstack HA的一部分，主要解决虚拟路由器的HA（即neutron-l3-agent的HA）。之前写过一篇<a href="https://zhangchenchen.github.io/2017/04/14/openstack-ha/">记录openstack的HA</a>,但没有仔细研究过neutron DVR。</p>
<p>在没有使用dvr时，我们的整体架构大致是这样的：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/neutron-arc-1.png" alt="neutron-arc1"></p>
<p>计算节点只需要安装L2 Agent就可以，而使用dvr模式后：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/2017-06-20neutro-arc-2.png" alt="neutron-arc-2"></p>
<p>计算节点除了L2 Agent外，还要安装L3 Agent以及Metadata Agent。也就是说，通过使用dvr，计算节点也有了网络节点的三层转发和NAT功能，起到了分流的作用。</p>
<h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><ul>
<li>控制节点：修改neutron.conf 如下，重启neutron-server</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[DEFAULT]</div><div class="line">router_distributed = <span class="literal">True</span></div></pre></td></tr></table></figure>
<ul>
<li>网络节点：修改 openswitch_agent.ini如下，重启Open vSwitch agent</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[DEFAULT]</div><div class="line">enable_distributed_routing = <span class="literal">True</span></div></pre></td></tr></table></figure>
<p>修改l3_agent.ini如下，重启Layer-3 agent，</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[DEFAULT]</div><div class="line">agent_mode = dvr_snat</div></pre></td></tr></table></figure>
<ul>
<li>计算节点：安装l3-agent,metadata-agent,修改 openswitch_agent.ini如下，重启Open vSwitch agent</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[DEFAULT]</div><div class="line">enable_distributed_routing = <span class="literal">True</span></div></pre></td></tr></table></figure>
<p>修改l3_agent.ini 如下，重启l3-agent</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[DEFAULT]</div><div class="line">interface_driver = openvswitch</div><div class="line">external_network_bridge =</div><div class="line">agent_mode = dvr</div></pre></td></tr></table></figure>
<p>可以通过 neutron agent-list 验证agent 是否启动。</p>
<h3 id="网络流通方向"><a href="#网络流通方向" class="headerlink" title="网络流通方向"></a>网络流通方向</h3><p><img src="https://docs.openstack.org/newton/networking-guide/_images/deploy-ovs-ha-dvr-compconn1.png" alt="deploy-ovs-ha-dvr-compconn"></p>
<p>照着这张图梳理一遍以下几种情况的网络走向：</p>
<ol>
<li><p>没有floating-ip的instance的南北向网络流通情况<br>即图中蓝色标注的线路，以图中左边计算节点的instance为例，首先通过一对veth设备与一个linux-bridge相连（该linux-bridge的存在主要是为了利用iptables实现Sec-group），又是一对veth设备，连接到OVS生成的br-int网桥，该instance在三层网络的第一跳便是到与该br-int相连的Disk router namespace的网关接口，因为没有floating-ip ，所以不会通过FIP namespace，而是通过patch设备到br-tun，再到网络节点的br-int,到达snat namespace，进行snat(源地址转换)，最后通过ovs-provider-bridge与外网联通。</p>
</li>
<li><p>有floating-ip的instance的南北向网络流通情况<br>刚开始与第一种情况类似，但是跳到本地router namespace后，接下来会跳到本地的RIP namespace，做snat,然后直接通过本地的ovs-provider-bridge连接到外网。 </p>
</li>
<li>不同子网但有虚拟路由连接的instance东西向网络<br>刚开始类似，之后在本地router namespace进行路由选择，并通过br-int,br-tun进入对应虚拟机的计算节点（该部分工作由ovs 的openflow完成，同时还完成了snat），到了 目标计算节点上，依次被 br-tun，br-int 处理，直到通过 tap 设备进入另一instance。</li>
</ol>
<p>关于详细描述以及实验可以参考<a href="https://docs.openstack.org/newton/networking-guide/deploy-ovs-ha-dvr.html#deploy-ovs-ha-dvr" target="_blank" rel="external">官方文档</a>,以及<a href="http://www.cnblogs.com/sammyliu/p/4713562.html" target="_blank" rel="external">这篇</a>。</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>回到刚开始碰到的问题，确定了问题的所在，就是在本地计算节点neutron-ns-metadata-proxy通过 unix domian socket 转发给 neutron-metadata-agent的时候出现了问题，neutron-ns-metadata-proxy是正常的，那么问题就出在neutron-metadata-agent上，果然，该agent在计算节点并没有启动，启动后正常。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openstack.org/ops-guide/ops-network-troubleshooting.html" target="_blank" rel="external">Network Troubleshooting</a></p>
<p><a href="https://developer.rackspace.com/blog/neutron-networking-l3-agent/" target="_blank" rel="external">Neutron Networking: Neutron Routers and the L3 Agent</a></p>
<p><a href="https://wiki.openstack.org/wiki/Neutron/DVR" target="_blank" rel="external">Neutron/DVR</a></p>
<p><a href="http://www.cnblogs.com/sammyliu/p/4713562.html" target="_blank" rel="external">理解 OpenStack 高可用（HA）（3）：Neutron 分布式虚拟路由（Neutron Distributed Virtual Routing）</a></p>
<p><a href="http://www.cnblogs.com/sammyliu/p/4636091.html" target="_blank" rel="external">Neutron 理解 (6): Neutron 是怎么实现虚拟三层网络的 [How Neutron implements virtual L3 network]</a></p>
<p><a href="http://blog.csdn.net/quqi99/article/details/20711303" target="_blank" rel="external">Neutron DVR实现multi-host特性打通东西南北流量提前看</a></p>
<p><a href="https://docs.openstack.org/newton/networking-guide/deploy-ovs-ha-dvr.html#deploy-ovs-ha-dvr" target="_blank" rel="external">Open vSwitch: High availability using DVR</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/06/14/python-hidden-feature/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/14/python-hidden-feature/" itemprop="url">
                  python-- python 中的一些隐藏特性
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-14T14:21:32+08:00">
                2017-06-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/14/python-hidden-feature/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/06/14/python-hidden-feature/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="引出"><a href="#引出" class="headerlink" title="引出"></a>引出</h2><p>偶然间翻到Stackoverflow上的<a href="https://stackoverflow.com/questions/101268/hidden-features-of-python#111176" target="_blank" rel="external">这个问题</a>，浏览了一下，觉得有点意思，摘录了一些感觉能用到的纪录在此。</p>
<h2 id="使用‘-’-代表函数的list-dict参数"><a href="#使用‘-’-代表函数的list-dict参数" class="headerlink" title="使用‘  * ’ 代表函数的list/dict参数"></a>使用‘ <em> *</em> ’ 代表函数的list/dict参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_point</span><span class="params">(x, y)</span>:</span></div><div class="line">    print(x,y)</div><div class="line">point_foo = [<span class="number">3</span>, <span class="number">4</span>] <span class="comment"># or (3,4)</span></div><div class="line">point_bar = &#123;<span class="string">'y'</span>: <span class="number">3</span>, <span class="string">'x'</span>: <span class="number">2</span>&#125;</div><div class="line"></div><div class="line">draw_point(*point_foo)</div><div class="line">draw_point(**point_bar)</div></pre></td></tr></table></figure>
<p>这个特性其实使用还算常见，不过pylint不建议这样使用，因为debug的时候会不清晰。</p>
<h2 id="链式比较操作"><a href="#链式比较操作" class="headerlink" title="链式比较操作"></a>链式比较操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; x = 5</div><div class="line">&gt;&gt;&gt; 1 &lt; x &lt; 10</div><div class="line">True</div><div class="line">&gt;&gt;&gt; 10 &lt; x &lt; 20 </div><div class="line">False</div><div class="line">&gt;&gt;&gt; x &lt; 10 &lt; x*10 &lt; 100</div><div class="line">True</div><div class="line">&gt;&gt;&gt; 10 &gt; x &lt;= 9</div><div class="line">True</div><div class="line">&gt;&gt;&gt; 5 == x &gt; 4 </div><div class="line">True</div></pre></td></tr></table></figure>
<p>比如最后一个比较，python会将这一句转化为 (5 == x and x &gt; 4) ，这是跟C或java不一样的。 </p>
<h2 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h2><p>装饰器用一个函数或方法封装另一个函数以增加功能或修改参数，结果等。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; def print_args(<span class="keyword">function</span>):</div><div class="line">&gt;&gt;&gt;     def wrapper(*args, **kwargs):</div><div class="line">&gt;&gt;&gt;         <span class="built_in">print</span> <span class="string">'Arguments:'</span>, args, kwargs</div><div class="line">&gt;&gt;&gt;         <span class="built_in">return</span> <span class="keyword">function</span>(*args, **kwargs)</div><div class="line">&gt;&gt;&gt;     <span class="built_in">return</span> wrapper</div><div class="line"></div><div class="line">&gt;&gt;&gt; @print_args</div><div class="line">&gt;&gt;&gt; def write(text):</div><div class="line">&gt;&gt;&gt;     <span class="built_in">print</span> text</div><div class="line"></div><div class="line">&gt;&gt;&gt; write(<span class="string">'foo'</span>)</div><div class="line">Arguments: (<span class="string">'foo'</span>,) &#123;&#125;</div><div class="line">foo</div></pre></td></tr></table></figure>
<h2 id="小心使用可变的默认参数"><a href="#小心使用可变的默认参数" class="headerlink" title="小心使用可变的默认参数"></a>小心使用可变的默认参数</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; def foo(x=[]):</div><div class="line">...     x.append(1)</div><div class="line">...     <span class="built_in">print</span> x</div><div class="line">... </div><div class="line">&gt;&gt;&gt; foo()</div><div class="line">[1]</div><div class="line">&gt;&gt;&gt; foo()</div><div class="line">[1, 1]</div><div class="line">&gt;&gt;&gt; foo()</div><div class="line">[1, 1, 1]</div></pre></td></tr></table></figure>
<p>可以加一个哨兵值来做判断：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; def foo(x=None):</div><div class="line">...     <span class="keyword">if</span> x is None:</div><div class="line">...         x = []</div><div class="line">...     x.append(1)</div><div class="line">...     <span class="built_in">print</span> x</div><div class="line">&gt;&gt;&gt; foo()</div><div class="line">[1]</div><div class="line">&gt;&gt;&gt; foo()</div><div class="line">[1]</div></pre></td></tr></table></figure>
<h2 id="利用python-正则语法树来debug正则表达式"><a href="#利用python-正则语法树来debug正则表达式" class="headerlink" title="利用python 正则语法树来debug正则表达式"></a>利用python 正则语法树来debug正则表达式</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; re.compile(<span class="string">"^\[font(?:=(?P&lt;size&gt;[-+][0-9]&#123;1,2&#125;))?\](.*?)[/font]"</span>,</div><div class="line">    re.DEBUG)</div><div class="line">at at_beginning</div><div class="line">literal 91</div><div class="line">literal 102</div><div class="line">literal 111</div><div class="line">literal 110</div><div class="line">literal 116</div><div class="line">max_repeat 0 1</div><div class="line">  subpattern None</div><div class="line">    literal 61</div><div class="line">    subpattern 1</div><div class="line">      <span class="keyword">in</span></div><div class="line">        literal 45</div><div class="line">        literal 43</div><div class="line">      max_repeat 1 2</div><div class="line">        <span class="keyword">in</span></div><div class="line">          range (48, 57)</div><div class="line">literal 93</div><div class="line">subpattern 2</div><div class="line">  min_repeat 0 65535</div><div class="line">    any None</div><div class="line"><span class="keyword">in</span></div><div class="line">  literal 47</div><div class="line">  literal 102</div><div class="line">  literal 111</div><div class="line">  literal 110</div><div class="line">  literal 116</div><div class="line"></div><div class="line">``` </div><div class="line">当然，最常用的还是使用注解的方式以增强正则的可读性。</div><div class="line"></div><div class="line">```bash</div><div class="line">&gt;&gt;&gt; re.compile(<span class="string">""</span><span class="string">"</span></div><div class="line"> ^              # start of a line</div><div class="line"> \[font         # the font tag</div><div class="line"> (?:=(?P&lt;size&gt;  # optional [font=+size]</div><div class="line"> [-+][0-9]&#123;1,2&#125; # size specification</div><div class="line"> ))?</div><div class="line"> \]             # end of tag</div><div class="line"> (.*?)          # text between the tags</div><div class="line"> \[/font\]      # end of the tag</div><div class="line"> "<span class="string">""</span>, re.DEBUG|re.VERBOSE|re.DOTALL)</div></pre></td></tr></table></figure>
<h2 id="利用enumerate-获取list的下标"><a href="#利用enumerate-获取list的下标" class="headerlink" title="利用enumerate 获取list的下标"></a>利用enumerate 获取list的下标</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>]</div><div class="line">&gt;&gt;&gt; <span class="keyword">for</span> index, item <span class="keyword">in</span> enumerate(a, start=1): <span class="built_in">print</span> index, item</div><div class="line">...</div><div class="line">1 a</div><div class="line">2 b</div><div class="line">3 c</div><div class="line">4 d</div><div class="line">5 e</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; n = ((a,b) <span class="keyword">for</span> a <span class="keyword">in</span> range(0,2) <span class="keyword">for</span> b <span class="keyword">in</span> range(4,6))</div><div class="line">&gt;&gt;&gt; <span class="keyword">for</span> i <span class="keyword">in</span> n:</div><div class="line">...   <span class="built_in">print</span> i </div><div class="line"></div><div class="line">(0, 4)</div><div class="line">(0, 5)</div><div class="line">(1, 4)</div><div class="line">(1, 5)</div></pre></td></tr></table></figure>
<p>需要注意的是，列表生成式是实实在在生成了列表存在了内存里，可以多次迭代使用，而生成器只能迭代一次。</p>
<h2 id="巧用list中的slice操作"><a href="#巧用list中的slice操作" class="headerlink" title="巧用list中的slice操作"></a>巧用list中的slice操作</h2><p>slice操作如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">a = [1,2,3,4,5]</div><div class="line">&gt;&gt;&gt; a[::2]  <span class="comment"># iterate over the whole list in 2-increments</span></div><div class="line">[1,3,5]</div></pre></td></tr></table></figure>
<p>将一个list逆序，最简洁写法：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a[::-1]</div><div class="line">[5,4,3,2,1]</div></pre></td></tr></table></figure>
<h2 id="for…else-语法"><a href="#for…else-语法" class="headerlink" title="for…else 语法"></a>for…else 语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> foo:</div><div class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">        <span class="keyword">break</span></div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">"i was never 0"</span>)</div></pre></td></tr></table></figure>
<p>上述代码如果break，那么else代码是不会执行的。上述代码的执行顺如跟下面的代码是一样的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">found = <span class="keyword">False</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> foo:</div><div class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">        found = <span class="keyword">True</span></div><div class="line">        <span class="keyword">break</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> found: </div><div class="line">    print(<span class="string">"i was never 0"</span>)</div></pre></td></tr></table></figure></p>
<h2 id="两个变量互换"><a href="#两个变量互换" class="headerlink" title="两个变量互换"></a>两个变量互换</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a = 10</div><div class="line">&gt;&gt;&gt; b = 5</div><div class="line">&gt;&gt;&gt; a, b</div><div class="line">(10, 5)</div><div class="line"></div><div class="line">&gt;&gt;&gt; a, b = b, a</div><div class="line">&gt;&gt;&gt; a, b</div><div class="line">(5, 10)</div></pre></td></tr></table></figure>
<h2 id="with-声明语句"><a href="#with-声明语句" class="headerlink" title="with 声明语句"></a>with 声明语句</h2><p>with 在Python2.5需要从<em>future</em>模块导入，2.6+已经可以直接使用。示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> with_statement</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'foo.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    f.write(<span class="string">'hello!'</span>)</div></pre></td></tr></table></figure>
<p>with 语句在这里的作用是在调用with时，会调用这个文件实例的 <strong>enter</strong> 方法，和 <strong>exit</strong> 方法，如果发生异常，异常的详细信息会传给 <strong>exit</strong> 方法处理并抛出，with在这里的主要用途是保证文件句柄最终关闭，其实with 可以看作是异常处理的一种抽象。<br>除了打开文件经常使用with外，线程锁以及数据库事务也经常用到。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://stackoverflow.com/questions/101268/hidden-features-of-python#113198" target="_blank" rel="external">Hidden features of Python </a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="pekingzcc" />
          <p class="site-author-name" itemprop="name">pekingzcc</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">94</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">41</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zhangchenchen" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">pekingzcc</span>
</div>


<div class="powered-by">
  powered by <a class="theme-link" href="https://hexo.io">Hexo</a> 
</div>

<div class="theme-info">
  theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user" ></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'pekingzcc';
      var disqus_identifier = 'page/3/index.html';

      var disqus_title = "";


      function run_disqus_script(disqus_script) {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');

      

    </script>
  









  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


</body>
</html>
