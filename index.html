<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Solar">
<meta property="og:url" content="https://zhangchenchen.github.io/index.html">
<meta property="og:site_name" content="Solar">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Solar">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhangchenchen.github.io/"/>





  <title> Solar </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-92407570-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Solar</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/05/10/mysql-on-k8s-in-production/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/05/10/mysql-on-k8s-in-production/" itemprop="url">
                  Kuberbetes-- 部署生产级MySQL到Kubernetes集群中
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-10T11:02:11+08:00">
                2018-05-10
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/10/mysql-on-k8s-in-production/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/05/10/mysql-on-k8s-in-production/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>K8s天然支持无状态应用的自动化运维（如HA,Scale等），对于有状态应用就相对比较麻烦了，本文以Mysql为例，详细梳理一下有状态应用在K8S中的部署运维。</p>
<h2 id="Mysql-HA-方案"><a href="#Mysql-HA-方案" class="headerlink" title="Mysql HA 方案"></a>Mysql HA 方案</h2><p>有状态应用在K8S中难以运维的原因是该应用本身就比较难运维（不然就不会有DBA 这样一个专门的职位了），当涉及到有状态应用时，你要考虑数据的存储，可用性，扩展性，事务，灾备等等。不过要想在K8S中部署生产级别的有状态应用，首先要知道在没有使用K8S时生产级别的应用架构方案。<br>这里还是以Mysql为例，简单说下常用的几种生产环境中的Mysql 架构方案。<br>本人不是专业的DBA,而且本身Mysql HA就是水很深的一个方向，理解有限，这里只谈大致方案，不说技术细节。</p>
<h2 id="部署Mysql-到K8S集群"><a href="#部署Mysql-到K8S集群" class="headerlink" title="部署Mysql 到K8S集群"></a>部署Mysql 到K8S集群</h2><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.slideshare.net/bytebot/best-practices-for-mysql-high-availability" target="_blank" rel="external">Best practices for MySQL High Availability </a></p>
<p><a href="http://www.clusterdb.com/mysql/choosing-the-right-mysql-high-availability-solution-webinar-replay" target="_blank" rel="external">Choosing the right MySQL High Availability Solution</a></p>
<p><a href="https://dev.mysql.com/doc/mysql-ha-scalability/en/ha-overview.html" target="_blank" rel="external">High Availability and Scalability</a></p>
<p><a href="https://juejin.im/entry/59edb5656fb9a0452404fd78" target="_blank" rel="external">用 Go 搭建 Kubernetes Operators</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/03/09/record-for-docker-storage-driver/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/09/record-for-docker-storage-driver/" itemprop="url">
                  Docker-- Docker storage driver 概述
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-09T11:57:10+08:00">
                2018-03-09
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/09/record-for-docker-storage-driver/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/09/record-for-docker-storage-driver/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Docker 配置的时候有一个很重要的配置项就是 storage driver选项，本篇博客详细介绍下storage driver这一配置项的相关内容。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>首先是 storage driver出现的原因。我们知道容器的存储大致有两种，一种是在容器外的，比如 volume，不会随着容器的消亡而消失，有自己的生命周期。还有一种是容器内的，这种存储跟对应容器的生命周期是紧密结合在一起的。而我们要说的就是容器内的存储。<br>本地的Docker引擎有一个Docker镜像层的缓存，镜像层是层层叠加的。当容器运行起来的时候就是在镜像层上起来的。基于同一个镜像运行的容器会共用一个镜像。那如何保证容器内操作后内容的独立呢，就要使用容器层以及写时复制（COW）技术。如下图：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309142857-cow.jpg" alt="cow"></p>
<p>最底层的基础镜像是ubuntu的系统镜像，再往上是分层的镜像层（比如dockerfile中的软件安装等），这些都是只读的镜像层。最上面才是可以读写的容器层，不同的容器有不同的容器层，共用相同的镜像层。当某个容器需要写操作时，会先将写的内容从镜像层复制到容器层，然后再写入（也就是写时复制），读的时候会从容器层开始，如果命中则读取，没有命中则依次往下读取。</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309145042-storage-driver.jpg" alt="storage-driver"></p>
<p>至于以上原理的具体的实现，就是storage driver做的事。</p>
<h2 id="storage-driver-的种类以及选型"><a href="#storage-driver-的种类以及选型" class="headerlink" title="storage driver 的种类以及选型"></a>storage driver 的种类以及选型</h2><p>注：本文是基于最新版Docker（V17.12），版本不同，选择也不同，具体参考官网。</p>
<p>目前为止，常用的storage driver有以下几种：AUFS，Btrfs，Device mapper，Overlayfs，ZFS，VFS。其中，</p>
<ul>
<li>VFS是接口的“原生”的实现，完全没有使用联合文件系统或者写时复制技术，而是将所有的分层依次拷贝到静态的子文件夹中，然后将最终结果挂载到容器的根文件系统。它并不适合实际或者生产环境使用，但是对于需要进行简单验证的场景，或者需要测试Docker引擎的其他部件的场景，是很有价值的。</li>
<li>Btrfs和ZFS针对特定的文件系统，也就是 backing filesystem必须相应的是Btrfs和ZFS。</li>
<li>AUFS和Overlayfs（包括Overlayfs2）都是在原有文件系统上基于联合挂载实现，而Device mapper是所有的镜像和容器存储在它自己的虚拟设备上，这些虚拟设备是一些支持写时复制策略的快照设备。</li>
</ul>
<p>具体的选择策略要根据linux 发行版，docker版本以及文件系统来决定：</p>
<p>对于Docker 社区版本来说，不同linux发行版的选择如下：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309151325-linux-distribution.jpg" alt="linux-distribution"></p>
<p>对于不同的文件系统，推荐如下：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309151640-file-system.jpg" alt="file-system"></p>
<p>综上，选择时可以如下选择：</p>
<ul>
<li>1，如果内核支持多个storage driver，可以如下考虑优先级：首先考虑特定文件系统的storage driver,即Btrfs和ZFS。否则，可以使用稳定和通用的配置，overlay2,或device mapper（需要手动配置direct-lvm，因为默认的loopback-lvm性能一般）。</li>
<li>2，依据具体的Docker 版本, 操作系统版本做选择（见上图）。</li>
<li>3，依据具体的 backing filesystem做选择（见上图）。</li>
</ul>
<h2 id="几种典型-storage-driver的原理"><a href="#几种典型-storage-driver的原理" class="headerlink" title="几种典型 storage driver的原理"></a>几种典型 storage driver的原理</h2><p>简单讲下AUFS，Overlayfs，Device mapper实现的具体原理。</p>
<h3 id="AUFS-的实现原理"><a href="#AUFS-的实现原理" class="headerlink" title="AUFS 的实现原理"></a>AUFS 的实现原理</h3><p>AUFS是一种联合文件系统，意思是它将同一个主机下的不同目录堆叠起来(类似于栈)成为一个整体，对外提供统一的视图。AUFS是用联合挂载来做到这一点。 在Docker中，AUFS实现了镜像的分层。AUFS中的分支对应镜像中的层。</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309155232-aufs.jpg" alt="aufs"></p>
<ul>
<li>aufs中文件的读写:读的时候会先去container layer读，如果没有会继续往下层读取。写的时候也是，如果container layer文件没有，先去image layer复制文件到container layer,然后再写入。因为AUFS工作在文件的层次上，也就是说AUFS对文件的操作需要将整个文件复制到读写层内，哪怕只是文件的一小部分被改变，也需要复制整个文件。</li>
<li>aufs中文件的删除:AUFS通过在最顶层(container layer)生成一个whiteout文件来删除文件。whiteout文件会掩盖下面只读层相应文件的存在，但它事实上没有被删除。</li>
</ul>
<h3 id="Overlayfs的实现原理"><a href="#Overlayfs的实现原理" class="headerlink" title="Overlayfs的实现原理"></a>Overlayfs的实现原理</h3><p>OverlayFS与AUFS相似，也是一种联合文件系统(union filesystem)，与AUFS相比，OverlayFS： 设计更简单，被加入Linux3.18版本内核 ，可能更快。</p>
<p>Overlay通过三个概念来实现它的文件系统：一个“下层目录（lower-dir）”，一个“上层目录（upper-dir）”，和一个做为文件系统合并视图的“合并（merged）”目录。受限于只有一个“下层目录”，需要额外的工作来让“下层目录”递归嵌套（下层目录自己又是另外一个overlay的联合），或者按照Docker的实现，将所有位于下层的内容都硬链接到“下层目录”中，这就可能导致inode爆炸式增长（因为有大量的分层内容和硬连接）。</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20180309160513-overlay.jpg" alt="overlay"></p>
<p>Overlay2基于Linux内核4.0和以后版本中overlay的特性，可以允许有多个下层的目录，解决了一些因为最初驱动的设计而引发的inode耗尽和一些其他问题。不过由于代码库相对还比较年轻，有待时间的检验。</p>
<p>理论情况下，overlay2 和 overlay要比aufs 和 devicemapper性能好，甚至，一些情况下，overlay2要比btrfs好。不过也有一些需要注意的方面：</p>
<ul>
<li>OverlayFS 支持页缓存（page caching）共享。意味着多个使用同一文件的容器可以共享同一页缓存，这使得overlayfs具有很高的内存使用效率。</li>
<li>同aufs一样，第一次写文件时需要复制整个文件，这会带来一些性能开销，在修改大文件时尤其明显。 </li>
<li>overlay的inode限制。</li>
</ul>
<h3 id="Device-mapper的实现原理"><a href="#Device-mapper的实现原理" class="headerlink" title="Device mapper的实现原理"></a>Device mapper的实现原理</h3><p>device mapper将所有的镜像和容器存储在它自己的虚拟设备上，这些虚拟设备是一些支持写时复制策略的快照设备。device mapper工作在块层次上而不是文件层次上，这意味着它的写时复制策略不需要拷贝整个文件。<br>device mapper创建镜像的过程如下： </p>
<ul>
<li>使用device mapper的storge driver创建一个精简配置池；精简配置池由块设备或稀疏文件创建。 </li>
<li>接下来创建一个基础设备； </li>
<li>每个镜像和镜像层都是基础设备的快照；这写快照支持写时复制策略，这意味着它们起始都是空的，当有数据写入时才耗费空间。<br><img src="http://oeptotikb.bkt.clouddn.com/20180309162425-device-mapper.jpg" alt="device-mapper"><br>镜像的每一层都是它下面一层的快照，镜像最下面一层是存在于thin pool中的base device的快照。容器是创建容器的镜像的快照。<br>device mapper跟之前的storage driver最大的不同就是它是基于块而不是基于文件，所以对文件的操作实际是对对应文件块的操作，默认每个块的大小为64KB。<br>图展示了容器中的某个进程读取块号为0x44f的数据：<br><img src="http://oeptotikb.bkt.clouddn.com/20180309163531-device-mapper.jpg" alt="device-mapper"></li>
</ul>
<p>device mapper不是最有效使用存储空间的storage driver，启动n个相同的容器就复制了n份文件在内存中，这对内存的影响很大。所以device mapper并不适合容器密度高的场景。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/" target="_blank" rel="external">Docker storage drivers</a></p>
<p><a href="https://www.centos.bz/2016/12/select-a-docker-storage-driver/" target="_blank" rel="external">Docker用户指南(4) – 存储驱动选择</a></p>
<p><a href="http://dockone.io/article/1765" target="_blank" rel="external">深入了解Docker存储驱动</a></p>
<p><a href="http://blog.csdn.net/vchy_zhao/article/details/70238690" target="_blank" rel="external">Docker之几种storage-driver比较</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/01/30/record-for-hdfs/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/30/record-for-hdfs/" itemprop="url">
                  Hadoop-- Hadoop学习之HDFS
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-30T14:57:10+08:00">
                2018-01-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/30/record-for-hdfs/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/01/30/record-for-hdfs/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最近因为项目需要将重心转移到大数据架构这一块，所以将大数据的内容大致过一下，在此记录，内容大部分来自官方文档与博客，主要基于Hadoop 的最新stable版本（2.9）。<br>学习大数据，立马想到的就是Hadoop，Hadoop是一个开源的可依赖，可扩展的分布式计算框架，采用普通PC机集群完成对大量数据的存储，计算。这个项目主要包括四个模块：</p>
<ul>
<li>Hadoop Common: Hadoop的Common utilities模块。</li>
<li>Hadoop Distributed File System (HDFS): 一个支持高可用的分布式文件系统。</li>
<li>Hadoop YARN: 任务调度和资源管理框架。</li>
<li>Hadoop MapReduce: 基于YARN的对大量数据并行处理的计算模型。<br>除了以上四个主要模块之外，Hadoop生态还有很多其他的的系统，以后再慢慢写，这里先写Hadoop生态中最重要的一个组件HDFS。</li>
</ul>
<p>先看下Hadoop里的服务角色：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20180201160125-hadoop-role.jpg" alt="hadoop-server-role"></p>
<p>Hadoop主要的任务部署分为3个部分，分别是：Client机器，主节点和从节点。主节点主要负责Hadoop两个关键功能模块HDFS、Map Reduce的监督。Job Tracker使用Map Reduce进行监控和调度数据的并行处理，namenode则负责HDFS监视和调度。从节点负责了机器运行的绝大部分，担当所有数据储存和指令计算的苦差。每个从节点既扮演着数据节点的角色又充当与他们主节点通信的守护进程。守护进程隶属于Job Tracker，数据节点则归属于名称节点。Client负责把数据加载到集群中，递交给Map Reduce做数据处理工作，并在工作结束后取回或者查看结果。</p>
<p>再看下典型的围绕hadoop 的workflow：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20180201160825hadoop-workflow.jpg" alt="hadoop-workflow"></p>
<h2 id="HDFS-Architecture"><a href="#HDFS-Architecture" class="headerlink" title="HDFS Architecture"></a>HDFS Architecture</h2><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>HDFS的整体设计架构就是master/slave，namenode负责元数据的存取，数据管理等功能，datanode负责数据存储。如下：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20180201154432-hdfs-arch.jpg" alt="hdfs-arch"></p>
<h3 id="datanode工作原理"><a href="#datanode工作原理" class="headerlink" title="datanode工作原理"></a>datanode工作原理</h3><p>数据的存储方式与ceph类似，默认都是三副本，先将大数据文件切割成固定大小（比如128M）的block，然后将这些block存放到三个不同的datanode中，namenode会记录对应文件block以及block所在位置。<br>举例一个datanode存储过程:client先做文件切割，并提交存储文件命令给namenode，namenode有一个rack awareness的功能，简单点说就是会将数据存储到不同机架上以避免机架故障（电源故障等），如果是三副本的话，首先client会写入block到某一节点A，然后另一机架中的节点B 会从A复制该数据,再然后同一机架内的另一个节点C会从B复制一份数据。这样一个pipeline既保证了数据的容灾，也能减小数据传输的延迟。</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20180201161950-data-node.jpg" alt="datanode"></p>
<h3 id="namenode工作原理"><a href="#namenode工作原理" class="headerlink" title="namenode工作原理"></a>namenode工作原理</h3><p>理解namenode，首先要理解两个文件。一个是 Edits文件，一个是FsImage映像文件，这两个文件就包含整个HDFS集群的元数据，而namenode的最大任务就是维护这两个文件。</p>
<ul>
<li>Edits文件：NameNode在本地操作系统的文件都会保存在Edits日志文件中。也就是说当文件系统中的任何元数据产生操作时，都会记录在Edits日志文件中。eg：在HDFS上创建一个文件，NameNode就会在Edits中插入一条记录。同样如果修改或者删除等操作，也会在Edits日志文件中新增一条数据。</li>
<li>FsImage映像文件：整个文件系统的名字空间，包括数据块到文件的映射，文件的属性等等，都存储在一个称为FsImage的文件中，这个文件也是放在NameNode所在的文件系统中。（注意到该文件中并没有blockmap,描述数据块Block与DataNode节点之间的对应关系的文件，这是因为每个DataNode已经持有属于自己管理的Block集合，每次blockreport都会将所有DataNode的Block集合汇总后即可构造出完整BlocksMap，所以不用持久化。）</li>
</ul>
<p>为什么会引入这两个文件呢，因为在HDFS的整个运行期里，所有元数据均在NameNode的内存集中管理，但是由于内存易失特性，一旦出现进程退出、宕机等异常情况，所有元数据都会丢失，为了更好的容错能力，NameNode会周期进行Checkpoint，将其中的一部分元数据（文件系统的目录树Namespace）刷到持久化设备上，即二进制文件FSImage，这样的话即使NameNode出现异常也能从持久化设备上恢复元数据。但是仅周期进行Checkpoint仍然无法保证所有数据的可靠，如前次Checkpoint之后写入的数据依然存在丢失的问题，所以将两次Checkpoint之间对Namespace写操作实时写入EditLog文件，通过这种方式可以保证HDFS元数据的绝对安全可靠。</p>
<p>首先看一下namenode启动时做了哪些操作（下文部分直接引用自<a href="http://blog.csdn.net/mmd0308/article/details/74674524" target="_blank" rel="external">该博客</a>）：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20180201163924-namenode.jpg" alt="namenode"></p>
<p>接下来看看check point的时候做了哪些操作,这个时候就要引入Secondary NameNode了，NameNode主要是存储文件的metadata，运行时所有数据都保存在内存中，这个的HDFS可存储的文件受限于NameNode的内存。而Secondary NameNode可以看做是NameNode的灾备（并非HA），它会定时与NameNode进行同步，定期的将fsimage映像文件和Edits日志文件进行合并，并将合并后的传入给NameNode，替换其镜像，并清空编辑日志。如果NameNode失效，需要手动的将其设置成namenode主机。<br>checkpoint的时间默认是3600秒（可配置），当Edits日志文件超过最大值时也会进行check point。checkpoint大致如下：</p>
<ul>
<li>NameNode通知Secondary NameNode进行checkpoint。</li>
<li>Secondary NameNode通知NameNode切换edits日志文件，使用一个空的。</li>
<li>Secondary NameNode通过Http获取NmaeNode上的fsimage映像文件和切换前的edits日志文件。</li>
<li>Secondary NameNode在内容中合并fsimage和Edits文件。</li>
<li>Secondary NameNode将合并之后的fsimage文件发送给NameNode。</li>
<li>NameNode用Secondary NameNode 传来的fsImage文件替换原先的fsImage文件</li>
</ul>
<h2 id="HDFS-使用"><a href="#HDFS-使用" class="headerlink" title="HDFS 使用"></a>HDFS 使用</h2><h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><p>HDFS本质是一个文件系统，所以跟Linux 的文件系统使用类似，也是增删改查，不过这里的“改”不是update，而是truncate，也就是文件截断，HDFS 不支持update操作，这与它读多写少的特性相对应。<br>对HDFS的操作可以通过shell，web 界面，libhdfs (C API)或WebHDFS (REST API)来操作。HDFS里的文件跟linux 文件类似，也有own user，group，也有读写执行权限的划分，不过这里的可执行权限只对目录有用，意思是是否有权限对该目录的子目录或文件有可读权限。每一个文件的操作命令都会进行Permission Checks，不通过则fail。<br>HDFS的具体shell命令略，可参考<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html" target="_blank" rel="external">FileSystemShell</a>。</p>
<h3 id="Quotas-设置"><a href="#Quotas-设置" class="headerlink" title="Quotas 设置"></a>Quotas 设置</h3><p>HDFS支持 administrator对quota的设置，包括：</p>
<ul>
<li>name quota: 指定目录下文件或者目录的数量限制。</li>
<li>space quota: 指定目录下文件的占用空间限制。</li>
<li>Storage Type Quotas：指定目录下Storage Type的限制。</li>
</ul>
<p>administrator可以通过命令行或其他的方式进行设置。</p>
<h3 id="透明加密"><a href="#透明加密" class="headerlink" title="透明加密"></a>透明加密</h3><p>透明加密主要是防止application与HDFS之间进行端到端的数据传输时的数据安全，不需要更改user application的任何代码。<br>详细参考<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html" target="_blank" rel="external">TransparentEncryption</a>。</p>
<h2 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS HA"></a>HDFS HA</h2><p>这里的HA主要是指namenode的HA。hadoop文档提供了两种方法，本质其实是一样的，因为namenode主要依靠FsImage和EditLog两个文件管理DataNode的数据，要想保证新的namenode能随时替换，就要保证这两个文件的一致性，FsImage是存储在磁盘上还好说，EditLog在内存里随时变化，就要保证两个namenode的EditLog文件是一样的。两个方案如下：</p>
<ul>
<li>QJM：the Quorum Journal Manager，这种方案是通过JournalNode共享EditLog的数据，使用的是Paxos算法（zookeeper就是使用的这种算法），保证活跃的NameNode与备份的NameNode之间EditLog日志一致,配合zookeeper可以实现自动切换,推荐使用。</li>
<li>NFS：Network File System 或 Conventional Shared Storage，传统共享存储，其实就是在服务器挂载一个网络存储（比如NAS），Active NameNode将EditLog的变化写到NFS，备份NameNode检查到修改就读取过来，是两个NameNode数据一致,缺点是如果namenode或者standby namenode与NFS磁盘之间的网络出了问题，HA即失效。</li>
</ul>
<p><img src="http://oeptotikb.bkt.clouddn.com/2018-2-2-HDFS-HA.jpg" alt="HDFS-HA"></p>
<p>以上是QJM HA的典型的结构图。集群中共有两个namenode(简称NN)，其中只有一个是active状态，另一个是standby状态。active 的NN负责响应DN(datanode)的请求，为了最快的切换为active状态，standby状态的NN同样也连接到所有的datenode上获取最新的块信息(blockmap)。<br>active NN会把元数据的修改(edit log)发送到多数的journal节点上(2n+1个journal节点，至少写到n+1个上)，standby NN从journal节点上读取edit log，并实时的合并到自己的namespace中。另外standby NN连接所有DN，实时的获取最新的blockmap。这样，一旦active的NN出现故障，standby NN可以立即切换为active NN.</p>
<p>具体配置参考<a href="http://www.bijishequ.com/detail/373246" target="_blank" rel="external">HADOOP(二):HDFS 高可用原理</a></p>
<h2 id="HDFS-认证与授权"><a href="#HDFS-认证与授权" class="headerlink" title="HDFS 认证与授权"></a>HDFS 认证与授权</h2><p>为了确保数据安全，认证授权这一块hadoop也下了一番功夫，一般来说，需要经历一下几个阶段：</p>
<ul>
<li>认证</li>
<li>proxy user</li>
<li>service level Authorization</li>
<li>第三方权限控制Ranger</li>
<li>Hadoop POSIX ACLs</li>
</ul>
<p><img src="http://oeptotikb.bkt.clouddn.com/2018-02-02Hadoop%20Range.png" alt="hadoop-auth"></p>
<p>认证部分有两种方式，simple和kerberos，simple不做任何处理，会由操作系统层获取用户，客户端可以通过设置环境变量HADOOP_USER_NAME来伪装用户。kerberos认证对集群里的所有机器都分发了keytab，使得集群机器进程之间不能随便访问。<br>代理部分：当客户端访问hadoop时，并不想以当前进程用户去调用，上层应用一般有自己一套用户管理体系，所以hadoop提供代理机制，让进程用户可以代理登录用户提交请求。然而，如果对代理用户不加以控制的话，那权限便相对于无限放大，比如代理超级用户：hdfs，yarn等，所以对于进程用户会设置可在哪些主机提交请求和代理哪些用户组成员。<br>权限控制首先经过Service Level Authorization，检测服务级别权限。<br>比如哪些用户可以连接namenode，resourcemanager，属于服务级别的acl控制。参考<a href="https://www.iteblog.com/archives/983.html" target="_blank" rel="external">Hadoop服务层授权控制</a><br>接着由Ranger进行目录，队列等资源的权限管控, 属于更细粒度的权限控制。如果ranger没有策略控制，则进入原始HDFS文件系统权限或者MR权限控制。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://hadoop.apache.org/" target="_blank" rel="external">Welcome to Apache Hadoop</a></p>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html" target="_blank" rel="external">HDFS Users Guide</a></p>
<p><a href="http://pangjiuzala.github.io/2015/08/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Hadoop%E9%9B%86%E7%BE%A4%E5%92%8C%E7%BD%91%E7%BB%9C/" target="_blank" rel="external">深入理解Hadoop集群和网络</a></p>
<p><a href="http://www.cnblogs.com/zhangmingcheng/p/6406792.html" target="_blank" rel="external">Hadoop2.7.3 HA高可靠性集群搭建</a></p>
<p><a href="http://blog.csdn.net/mmd0308/article/details/74674524" target="_blank" rel="external">Hadoop之HDFS分布式文件系统NameNode及Secondary NameNode详解</a></p>
<p><a href="http://komi.leanote.com/post/Hadoop-Ranger%E6%9D%83%E9%99%90%E6%B5%81%E7%A8%8B" target="_blank" rel="external">Hadoop 访问管理</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/01/26/centos7-install-cdh5.14/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/26/centos7-install-cdh5.14/" itemprop="url">
                  Bigdata-- Centos7 安装CDH5.14记录
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-26T16:57:10+08:00">
                2018-01-26
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/26/centos7-install-cdh5.14/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/01/26/centos7-install-cdh5.14/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>目标是搭建一个CDH 的测试环境，图方便在网上找了一些中文的搭建博客，结果问题百出，还是回到官网浏览，找到对应的安装文档，花了一点时间搭建，这里记录一下。<br>系统配置如下：</p>
<ul>
<li>centos7.2 minimal,8G内存，100G磁盘(master节点)</li>
<li>centos7.2 minimal,4G内存，100G磁盘(node节点)</li>
<li>centos7.2 minimal,4G内存，100G磁盘(node节点)</li>
<li>centos7.2 minimal,4G内存，100G磁盘(node节点)<br>搭建的cdh为最新的CDH5.14，感觉master内存还是太少，有点吃力。</li>
</ul>
<h2 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h2><p>CDH的搭建有多种方法，一般来说，都是先搭建Cloudera Manager,然后利用Cloudera Manager搭建CDH，如果是测试环境，可以直接利用Cloudera Manager自动化安装，这种方式使用内嵌的PostgreSQL作为metadata等数据的存储，不适于生产环境。生产环境中一般会使用Mysql或其他独立搭建的数据库（当然要做HA），所以我们会先搭建一个Mysql数据库备用。</p>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>在所有节点上都要执行的工作，包括host设置，设置yum repo，无密钥登录，ntp设置，安装jdk,关闭防火墙等等。</p>
<ul>
<li>修改 hostname，执行命令 hostname NAME,并修改 /etc/hostname文件。</li>
<li><p>修改/etc/hosts文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">10.10.10.77    cdh1</div><div class="line">10.10.10.78    cdh2</div><div class="line">10.10.10.79    cdh3</div><div class="line">10.10.10.82    cdh4</div></pre></td></tr></table></figure>
</li>
<li><p>关闭防火墙.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ systemctl stop firewalld</div><div class="line">$ systemctl <span class="built_in">disable</span> firewalld</div><div class="line">``` </div><div class="line">- 所有节点设置无密钥登录,命令大致如下，将最终的authorized_keys再覆盖回所有节点：</div><div class="line">```bash</div><div class="line">$ ssh-keygen -t rsa</div><div class="line">$ cat id_rsa.pub &gt;&gt; authorized_keys</div><div class="line">$ chmod 600 authorized_keys</div><div class="line">$ scp authorized_keys root@cdh2:~/.ssh/</div></pre></td></tr></table></figure>
</li>
<li><p>设置 yum repo.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo  <span class="comment"># 阿里yum源</span></div><div class="line">$ curl -o /etc/yum.repos.d/cloudera-manager.repo https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo  <span class="comment"># cloudera yum源</span></div></pre></td></tr></table></figure>
</li>
<li><p>ntp设置，安装ntp，编辑crontab定时同步。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ yum install ntpd</div><div class="line">$ ntpdate time1.aliyun.com</div><div class="line">$ crontab e</div><div class="line">30 02 * * *  ntpdate time1.aliyun.com</div></pre></td></tr></table></figure>
</li>
<li><p>安装jdk.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install oracle-j2sdk1.7 -y</div></pre></td></tr></table></figure>
</li>
<li><p>关闭SElinux,修改/etc/selinux/config为disabled，重启生效。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># This file controls the state of SELinux on the system.</span></div><div class="line"><span class="comment"># SELINUX= can take one of these three values:</span></div><div class="line"><span class="comment">#       enforcing - SELinux security policy is enforced.</span></div><div class="line"><span class="comment">#       permissive - SELinux prints warnings instead of enforcing.</span></div><div class="line"><span class="comment">#       disabled - SELinux is fully disabled.</span></div><div class="line">SELINUX=disabled</div><div class="line"><span class="comment"># SELINUXTYPE= type of policy in use. Possible values are:</span></div><div class="line"><span class="comment">#       targeted - Only targeted network daemons are protected.</span></div><div class="line"><span class="comment">#       strict - Full SELinux protection.</span></div><div class="line">SELINUXTYPE=targeted</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="master节点安装与配置Mysql"><a href="#master节点安装与配置Mysql" class="headerlink" title="master节点安装与配置Mysql"></a>master节点安装与配置Mysql</h3><ul>
<li><p>安装mysql.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm</div><div class="line">$ sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm</div><div class="line">$ yum update</div><div class="line">$ sudo yum install mysql-server</div><div class="line">$ sudo systemctl start mysqld</div></pre></td></tr></table></figure>
</li>
<li><p>删除/var/lib/mysql/ib_logfile0 和 /var/lib/mysql/ib_logfile1文件，并配置/etc/my.conf如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">[mysqld]</div><div class="line">transaction-isolation = READ-COMMITTED</div><div class="line"><span class="comment"># Disabling symbolic-links is recommended to prevent assorted security risks;</span></div><div class="line"><span class="comment"># to do so, uncomment this line:</span></div><div class="line"><span class="comment"># symbolic-links = 0</span></div><div class="line"></div><div class="line">key_buffer_size = 32M</div><div class="line">max_allowed_packet = 32M</div><div class="line">thread_stack = 256K</div><div class="line">thread_cache_size = 64</div><div class="line">query_cache_limit = 8M</div><div class="line">query_cache_size = 64M</div><div class="line">query_cache_type = 1</div><div class="line"></div><div class="line">max_connections = 550</div><div class="line"><span class="comment">#expire_logs_days = 10</span></div><div class="line"><span class="comment">#max_binlog_size = 100M</span></div><div class="line"></div><div class="line"><span class="comment">#log_bin should be on a disk with enough free space. Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your system</span></div><div class="line"><span class="comment">#and chown the specified folder to the mysql user.</span></div><div class="line">log_bin=/var/lib/mysql/mysql_binary_log</div><div class="line"></div><div class="line"><span class="comment"># For MySQL version 5.1.8 or later. For older versions, reference MySQL documentation for configuration help.</span></div><div class="line">binlog_format = mixed</div><div class="line"></div><div class="line">read_buffer_size = 2M</div><div class="line">read_rnd_buffer_size = 16M</div><div class="line">sort_buffer_size = 8M</div><div class="line">join_buffer_size = 8M</div><div class="line"></div><div class="line"><span class="comment"># InnoDB settings</span></div><div class="line">innodb_file_per_table = 1</div><div class="line">innodb_flush_log_at_trx_commit  = 2</div><div class="line">innodb_log_buffer_size = 64M</div><div class="line">innodb_buffer_pool_size = 4G</div><div class="line">innodb_thread_concurrency = 8</div><div class="line">innodb_flush_method = O_DIRECT</div><div class="line">innodb_log_file_size = 512M</div><div class="line"></div><div class="line">[mysqld_safe]</div><div class="line"><span class="built_in">log</span>-error=/var/<span class="built_in">log</span>/mysqld.log</div><div class="line">pid-file=/var/run/mysqld/mysqld.pid</div><div class="line"></div><div class="line">sql_mode=STRICT_ALL_TABLES</div></pre></td></tr></table></figure>
</li>
<li><p>安装 MySQL JDBC Driver从<a href="http://www.mysql.com/downloads/connector/j/5.1.html" target="_blank" rel="external">该页面</a>下载对应tar包，解压。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ tar zxvf mysql-connector-java-5.1.31.tar.gz</div><div class="line">$ mkdir -p /usr/share/java/</div><div class="line">$ cp mysql-connector-java-5.1.31/mysql-connector-java-5.1.31-bin.jar /usr/share/java/mysql-connector-java.jar</div></pre></td></tr></table></figure>
</li>
<li><p>创建对应的数据库。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mysql&gt; create database database DEFAULT CHARACTER SET utf8;</div><div class="line">Query OK, 1 row affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; grant all on database.* TO <span class="string">'user'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'password'</span>;</div><div class="line">Query OK, 0 rows affected (0.00 sec)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>数据库的名字，用户名等可以参考除了以下列出的，还需创建oozie的数据库以及用户名密码.<br><img src="http://oeptotikb.bkt.clouddn.com/20180129200028-mysql-role.jpg" alt="mysql"></p>
<h3 id="Cloudera-Manager-安装"><a href="#Cloudera-Manager-安装" class="headerlink" title="Cloudera Manager 安装"></a>Cloudera Manager 安装</h3><ul>
<li><p>在master节点安装Cloudera Manager Server并启动。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ yum install cloudera-manager-daemons cloudera-manager-server</div><div class="line">$ systemctl start cloudera-scm-server</div></pre></td></tr></table></figure>
</li>
<li><p>在master和node节点安装Cloudera Manager Agent。修改 /etc/cloudera-scm-agent/config.ini 中的server_host为master的IP。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ yum install cloudera-manager-agent cloudera-manager-daemons</div><div class="line">$ systemctl start cloudera-scm-agent</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="CDH-安装"><a href="#CDH-安装" class="headerlink" title="CDH 安装"></a>CDH 安装</h3><p>进入 Cloudera Manager的console，<a href="http://Server" target="_blank" rel="external">http://Server</a> host:7180,登录后便可以进入CDH的安装部署了。</p>
<p>该过程没有截图，且因为web界面看着比较直白不在赘述。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_install_path_b.html#id_z2h_pnm_25" target="_blank" rel="external">Installation Path B - Installation Using Cloudera Manager Parcels or Packages</a></p>
<p><a href="https://www.cloudera.com/documentation/enterprise/latest/topics/hue_dbs_mysql.html#concept_tq4_tbt_zw" target="_blank" rel="external">Connect Hue to MySQL or MariaDB</a></p>
<p><a href="https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_troubleshooting.html#cmig_topic_19" target="_blank" rel="external">Troubleshooting Installation and Upgrade Problems</a></p>
<p><a href="https://segmentfault.com/a/1190000011341408" target="_blank" rel="external">离线部署 Cloudera Manager 5 和 CDH 5.12.1 及使用 CDH 部署 Hadoop 集群服务</a></p>
<p><a href="https://www.cmgine.com/archives/19107.html" target="_blank" rel="external">Centos 7安装CDH 5.13.0总结</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/01/20/create-rpm-for-python-flask-application/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/20/create-rpm-for-python-flask-application/" itemprop="url">
                  Ops-- 将Flask APP 打包为rpm包
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-20T15:57:10+08:00">
                2018-01-20
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/20/create-rpm-for-python-flask-application/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/01/20/create-rpm-for-python-flask-application/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>为了实现无人值守安装，需要将我们用Python研发的一个WEB做成一个RPM 包，这里简单记录一下。<br>先简单介绍下需要打包的这个Python应用，是我们为了安装CDH 大数据平台做的一个辅助WEB，使用Flask开发，除了用cherry起的一个WEB 服务外，还有一个celery的worker 进程。 </p>
<h2 id="构建思路"><a href="#构建思路" class="headerlink" title="构建思路"></a>构建思路</h2><ul>
<li>首先是该Python应用的依赖包，有两种解决方案，一种是全部打包到一个RPM包里，简单粗暴，不容易起冲突，但是不灵活，文件大，每做一次升级比较麻烦，第二种方案是将该应用的依赖包做成RPM包（其实都有现成的），在SPEC文件中注明依赖包，这样在RPM 安装时会自动安装依赖包，这种方案比较灵活，不过需要花时间去找到所有依赖包的RPM 包并放到YUM REPO中。我们采用的是第二种方案。</li>
<li>因为要起两个服务，所以要写两个启动文件。</li>
<li>Python 的setuptools 有一个 python setup.py bdist_rpm 命令用于构建rpm包，不过还是需要自己定制SPEC文件，所以这里直接使用rpmbuild。</li>
<li>本次构建的系统环境是centos6.9。</li>
</ul>
<h2 id="具体实践"><a href="#具体实践" class="headerlink" title="具体实践"></a>具体实践</h2><ul>
<li><p>安装rpmbuild</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ yum install -y rpm-build</div></pre></td></tr></table></figure>
</li>
<li><p>使用普通用户并修改topdir目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ useradd rpmbuilder</div><div class="line">$ su - rpmbuilder</div><div class="line">$ vim ~/.rpmmacros    <span class="comment"># 修改工作目录</span></div><div class="line">  %_topdir        /home/rpmbuilder/rpmbuild</div><div class="line"></div><div class="line">$ mkdir -pv ~/rpmbuild/&#123;BUILD,RPMS,SOURCES,SPECS,SRPMS&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>简单介绍下工作目录中的几个目录的作用：<br><img src="http://oeptotikb.bkt.clouddn.com/20180120rpm-dir.jpg" alt="rpm-dir"></p>
<ul>
<li><p>准备源码文件，主要包括三个文件，一个是Flask源码文件全部打包压缩成一个tar.gz包，还有两个启动文件。将这三个文件放到SOURCES目录。启动文件示例如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></div><div class="line"></div><div class="line">runuser=root</div><div class="line">prog=cdhboot-web</div><div class="line">worker_num=10</div><div class="line"><span class="built_in">export</span> C_FORCE_ROOT=True</div><div class="line"><span class="built_in">exec</span>=<span class="string">"/opt/cdhboot/supervisor/server_cherrypy.py"</span>  <span class="comment"># 我们将所有源码文件安装到/opt/cdhboot/目录，后面会提到。</span></div><div class="line">pidfile=<span class="string">"/var/run/cdhboot/<span class="variable">$prog</span>.pid"</span></div><div class="line"></div><div class="line"><span class="function"><span class="title">start</span></span>() &#123;</div><div class="line">    [ <span class="_">-f</span> <span class="variable">$exec</span> ] || <span class="built_in">exit</span> 5</div><div class="line">    <span class="built_in">echo</span> -n $<span class="string">"Starting <span class="variable">$prog</span>: "</span></div><div class="line">    daemon --user <span class="variable">$runuser</span> --pidfile <span class="variable">$pidfile</span> <span class="string">"python <span class="variable">$exec</span> &amp;&gt;/dev/null &amp; echo \$! &gt; <span class="variable">$pidfile</span>"</span></div><div class="line">    retval=$?</div><div class="line">    <span class="built_in">echo</span></div><div class="line">    <span class="built_in">return</span> <span class="variable">$retval</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">stop</span></span>() &#123;</div><div class="line">    <span class="built_in">echo</span> -n $<span class="string">"Stopping <span class="variable">$prog</span>: "</span></div><div class="line">    killproc -p <span class="variable">$pidfile</span> <span class="variable">$prog</span></div><div class="line">    retval=$?</div><div class="line">    <span class="built_in">echo</span></div><div class="line">    <span class="built_in">return</span> <span class="variable">$retval</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">restart</span></span>() &#123;</div><div class="line">    stop</div><div class="line">    start</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">reload</span></span>() &#123;</div><div class="line">    restart</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="title">force_reload</span></span>() &#123;</div><div class="line">    restart</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">rh_status</span></span>() &#123;</div><div class="line">    status -p <span class="variable">$pidfile</span> <span class="variable">$prog</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">rh_status_q</span></span>() &#123;</div><div class="line">    rh_status &gt;/dev/null 2&gt;&amp;1</div><div class="line">&#125;</div><div class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></div><div class="line">    start)</div><div class="line">        rh_status_q &amp;&amp; <span class="built_in">exit</span> 0</div><div class="line">        <span class="variable">$1</span></div><div class="line">        ;;</div><div class="line">    stop)</div><div class="line">        rh_status_q || <span class="built_in">exit</span> 0</div><div class="line">        <span class="variable">$1</span></div><div class="line">        ;;</div><div class="line">    restart)</div><div class="line">        <span class="variable">$1</span></div><div class="line">        ;;</div><div class="line">    reload)</div><div class="line">        rh_status_q || <span class="built_in">exit</span> 7</div><div class="line">        <span class="variable">$1</span></div><div class="line">        ;;</div><div class="line">    force-reload)</div><div class="line">        force_reload</div><div class="line">        ;;</div><div class="line">    status)</div><div class="line">        rh_status</div><div class="line">    condrestart|try-restart)</div><div class="line">        rh_status_q || <span class="built_in">exit</span> 0</div><div class="line">        restart</div><div class="line">        ;;</div><div class="line">    *)</div><div class="line">        <span class="built_in">echo</span> $<span class="string">"Usage: <span class="variable">$0</span> &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;"</span></div><div class="line">        <span class="built_in">exit</span> 2</div><div class="line"><span class="keyword">esac</span></div><div class="line"><span class="built_in">exit</span> $?</div></pre></td></tr></table></figure>
</li>
<li><p>编写SPEC文件，SPEC文件有几个部分组成，也代表着rpm打包时的几个步骤。先看下rpm打包的四个步骤：</p>
</li>
</ul>
<p><img src="http://oeptotikb.bkt.clouddn.com/rpmbulld-step-20180122133542.jpg" alt="rpm-build-step"><br>对应的SPEC文件示例如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 第一部分：自定义的变量，通常是包名，版本等信息</span></div><div class="line">%define name cdhboot</div><div class="line">%define version 0.1</div><div class="line">%define unmangled_version 0.1</div><div class="line">%define unmangled_version 0.1</div><div class="line">%define release 1</div><div class="line"></div><div class="line"><span class="comment"># 第二部分：定义rpm包的信息，三个源文件，依赖包，以及BuildRoot</span></div><div class="line">Summary: cdh boot</div><div class="line">Name: %&#123;name&#125;</div><div class="line">Version: %&#123;version&#125;</div><div class="line">Release: %&#123;release&#125;</div><div class="line">Source0: %&#123;name&#125;-%&#123;unmangled_version&#125;.tar.gz </div><div class="line">Source1: cdhboot-worker</div><div class="line">Source2: cdhboot-web</div><div class="line">License: MIT</div><div class="line">Group: Development/Libraries</div><div class="line">BuildRoot: /root/rpmbuild/  </div><div class="line">Prefix: %&#123;_prefix&#125;</div><div class="line">BuildArch: noarch</div><div class="line">Vendor: pekingzcc &lt;pekingzcc@gmail.com&gt;</div><div class="line">Url: https://github.com/zhangchenchen</div><div class="line">Requires: python-celery,python-mongoengine,python-prettytable,python-cherrypy,python-argparse,pytz,python-flask,python-flask-login  <span class="comment"># 依赖包，使用yum安装时会先下载安装依赖包</span></div><div class="line">%description</div><div class="line">WEB TO BOOT CDH</div><div class="line"></div><div class="line"><span class="comment"># 第三部分：准备阶段，%setup是一个宏命令，解压缩包到cdhboot目录，并cd到该目录下。</span></div><div class="line">%prep</div><div class="line">%setup -n %&#123;name&#125;-%&#123;unmangled_version&#125; -n cdhboot</div><div class="line"></div><div class="line"><span class="comment"># 第四部分：安装之前的操作，添加一个sysadmin用户</span></div><div class="line">%pre</div><div class="line"><span class="keyword">if</span> [ <span class="variable">$1</span> == 1 ];<span class="keyword">then</span></div><div class="line">    /usr/sbin/useradd  sysadmin <span class="_">-s</span> /sbin/nologin 2&gt; /dev/null</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># 第五部分：安装阶段，创建相应目录。并将源文件复制到相应目录。%&#123;__install&#125;是一个宏命令，类似于cp命令。</span></div><div class="line">%install</div><div class="line">mkdir -p %&#123;buildroot&#125;/opt/cdhboot</div><div class="line">cp -r ./* %&#123;buildroot&#125;/opt/cdhboot/</div><div class="line">mkdir -p  %&#123;buildroot&#125;/var/run/cdhboot</div><div class="line">mkdir -p  %&#123;buildroot&#125;/var/<span class="built_in">log</span>/cdhboot</div><div class="line">%&#123;__install&#125; -p -D -m 0755 %&#123;SOURCE1&#125; %&#123;buildroot&#125;/etc/rc.d/init.d/cdhboot-worker</div><div class="line">%&#123;__install&#125; -p -D -m 0755 %&#123;SOURCE2&#125; %&#123;buildroot&#125;/etc/rc.d/init.d/cdhboot-web</div><div class="line"></div><div class="line"><span class="comment"># 第六部分：安转之后的操作，加入开机启动服务</span></div><div class="line">%post</div><div class="line"><span class="keyword">if</span> [ <span class="variable">$1</span> == 1 ];<span class="keyword">then</span></div><div class="line">    /sbin/chkconfig --add cdhboot-worker</div><div class="line">    /sbin/chkconfig cdhboot-worker on</div><div class="line">    /sbin/chkconfig --add cdhboot-web</div><div class="line">    /sbin/chkconfig cdhboot-web on</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># 第七部分：卸载之后的操作，删除sysadmin用户，并停止服务 </span></div><div class="line">%preun</div><div class="line"><span class="keyword">if</span> [ <span class="variable">$1</span> == 0 ];<span class="keyword">then</span></div><div class="line">        /usr/sbin/userdel  sysadmin 2&gt; /dev/null</div><div class="line">        /etc/init.d/cdhboot-worker stop &gt; /dev/null 2&gt;&amp;1</div><div class="line">        /etc/init.d/cdhboot-web stop &gt; /dev/null 2&gt;&amp;1</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># 第八部分：构建完成后删除临时构建目录内容</span></div><div class="line">%clean</div><div class="line">rm -rf <span class="variable">$RPM_BUILD_ROOT</span></div><div class="line"></div><div class="line"><span class="comment"># 第九部分：文件部分，但凡上文构建过程中出现的文件或目录，这里都要对这些文件或目录注明属性</span></div><div class="line">%files </div><div class="line">%defattr(-,root,root)</div><div class="line">%attr(0755,root,root) /etc/rc.d/init.d/cdhboot-worker</div><div class="line">%attr(0755,root,root) /etc/rc.d/init.d/cdhboot-web</div><div class="line">/opt</div><div class="line">/var/run</div><div class="line">/var/<span class="built_in">log</span></div></pre></td></tr></table></figure></p>
<ul>
<li>测试SPEC文件。为了测试SPEC文件，我们可以分阶段的执行构建命令。<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">rpmbuild -bp cdhboot.spec 制作到%prep段</div><div class="line">rpmbuild -bc cdhboot.spec 制作到%build段</div><div class="line">rpmbuild -bi cdhboot.spec 执行 spec 文件的 <span class="string">"%install"</span> 阶段 (在执行了 %prep 和 %build 阶段之后)。这通常等价于执行了一次 <span class="string">"make install"</span></div><div class="line">rpmbuild -bb cdhboot.spec 制作二进制包</div><div class="line">rpmbuild -ba cdhboot.spec 表示既制作二进制包又制作src格式包,即全过程。</div></pre></td></tr></table></figure>
</li>
</ul>
<p>通过分阶段的构建来测试对应部分的编写正确性，同时，也可以去临时目录BUILDROOT 下查看构建的文件，临时目录BUILDROOT在构建阶段相当于安装时机器的根目录。<br>构建完成后再RPMS目录下可以看到构建成功的rpm包。</p>
<p>之后可以对rpm包进行签名，就可以放到yum repo中发布了。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://stackoverflow.com/questions/42286786/how-to-create-a-rpm-for-python-application" target="_blank" rel="external">How to create a rpm for python application</a></p>
<p><a href="http://blog.51cto.com/nmshuishui/1583117" target="_blank" rel="external">使用rpm-build制作nginx的rpm包</a></p>
<p><a href="http://www.voidcn.com/article/p-zvfjwgek-up.html" target="_blank" rel="external">记录自己将Python程序打包成rpm包的过程</a></p>
<p><a href="https://wenchao.ren/archives/549" target="_blank" rel="external">rpmbuild spec文件的编写,以及rpm包的打包</a></p>
<p><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn" target="_blank" rel="external">How to create an RPM package/zh-cn</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2018/01/04/auto-install-big-data-platform/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/04/auto-install-big-data-platform/" itemprop="url">
                  Ops-- CDH大数据平台自动化安装部署
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-04T18:00:10+08:00">
                2018-01-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/04/auto-install-big-data-platform/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/01/04/auto-install-big-data-platform/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Cloudera 的CDH应该是目前大数据平台安装部署的首选，不过Cloudermanager只是简化了大数据组件的安装部署，其他的比如操作系统的安装，磁盘raid，seed节点配置，免密登录，ntp安装等都是需要手动或脚本完成，所以这里为了安装部署的方便，便把这一系列过程自动化，实现CDH大数据平台的自动化安装。</p>
<p>使用的工具有：</p>
<ul>
<li>KickStart</li>
<li>Cobbler</li>
<li>SaltStalk</li>
<li>CdhBoot(自研的基于saltstalk的web 平台)</li>
</ul>
<h2 id="安装流程解析"><a href="#安装流程解析" class="headerlink" title="安装流程解析"></a>安装流程解析</h2><p>大致有以下几个过程：</p>
<ul>
<li>磁盘raid（可选）</li>
<li>seed节点操作系统安装</li>
<li>node节点操作系统安装</li>
<li>cdh准备安装工作</li>
<li>cdh安装</li>
</ul>
<p>现在就按这几个顺序大致记录下整过程所需做的工作。</p>
<h3 id="磁盘raid"><a href="#磁盘raid" class="headerlink" title="磁盘raid"></a>磁盘raid</h3><p>规划如下：</p>
<ul>
<li>datenode 系统分区用两块磁盘做raid1。</li>
<li>datenode的数据存储分区用单独一块磁盘做raid0（可选，单独一块磁盘不做raid也是可以的）</li>
<li>namenode 系统分区用两块磁盘做raid1。</li>
<li>namenode 数据存储分区做raid5。</li>
</ul>
<p>磁盘raid这一块因为服务器硬件的不同，做raid方式也不同，博主一直没能找到一个比较通用的自动化方式，所以最终只能手动解决。</p>
<h3 id="seed节点操作系统安装"><a href="#seed节点操作系统安装" class="headerlink" title="seed节点操作系统安装"></a>seed节点操作系统安装</h3><p>这一部分的工作主要是seed节点操作系统的制作，大致步骤如下：</p>
<ul>
<li>安装镜像制作软件包（createrepo &amp; mkisofs）</li>
<li>拷贝系统镜像文件到指定目录</li>
<li>编写Kickstart 文件</li>
<li>生成依赖关系和ISO文件</li>
</ul>
<p>具体操作可以参考<a href="https://wsgzao.github.io/post/kickstart/#" target="_blank" rel="external">基于Kickstart自动化安装CentOS实践</a></p>
<p>这里注意：</p>
<ol>
<li>因为是离线环境，所以这里要把所需要安装的所有rpm包全部放到镜像Packages目录里。</li>
<li>ks文件的编写，可以先手动安装一个系统，然后在安装完成的root目录下会生成一个anaconda-ks.cfg，该文件记录了你手动安装时的操作，然后根据这个文件去更改。这里有一个示例<a href="https://github.com/zhangchenchen/Centos-KickStart-Example" target="_blank" rel="external">Centos-KickStart-Example</a>。</li>
<li>seed节点安装系统后，需要手动配置一下seed节点的IP ，这里也可以写入ks文件，但相对不灵活，所以还是建议单独配置。</li>
</ol>
<h3 id="node节点操作系统安装"><a href="#node节点操作系统安装" class="headerlink" title="node节点操作系统安装"></a>node节点操作系统安装</h3><p>该部分就是要用cobbler去推操作系统，需要我们在seed节点安装cobbler，导入镜像，然后配置待安装node节点的mac地址，最后推系统。为了完成自动化，我们是这样做的：</p>
<ul>
<li>在seed节点安装的ks文件中，我们在post部分加入一个脚本或者salt命令，在seed节点安装并启动CdhBoot。</li>
<li>Cdhboot的web页面配置node mac地址，同时，在后端接收到请求后会调用salt命令进行cobbler的安装部署以及image的导入。</li>
</ul>
<p>这里解释下为什么不把cobbler的安装配置放在ks文件中，因为cobbler依赖我们配置的网卡IP，如果那个网卡没起来，cobbler就会报错，所以我们把cobbler的部署放在配置ip 后。<br>注意，利用cobbler推送的镜像中也要编写相应的ks文件。</p>
<h3 id="cdh准备安装工作"><a href="#cdh准备安装工作" class="headerlink" title="cdh准备安装工作"></a>cdh准备安装工作</h3><p>该部分主要是Cdhboot 调用salt api 完成免密登录，ntp安装，yum源设定等等准备工作</p>
<h3 id="cloudera-manager安装"><a href="#cloudera-manager安装" class="headerlink" title="cloudera-manager安装"></a>cloudera-manager安装</h3><p>同上，这部分也是Cdhboot 调用salt api 完成。</p>
<p>这样，我们的工作大致完成，完成之后，大数据平台的安装步骤如下：</p>
<ul>
<li>各节点做raid</li>
<li>安装seed节点,配置IP</li>
<li>在Cdhboot 界面完成node操作系统安装，cdh准备工作，cloudera-manager安装。</li>
<li>在cloudera-manager界面完成cdh安装。</li>
</ul>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://wsgzao.github.io/post/kickstart/#" target="_blank" rel="external">基于Kickstart自动化安装CentOS实践</a></p>
<p><a href="http://liaoph.com/linux-kickstart/" target="_blank" rel="external">Linux Kickstart 自动安装</a></p>
<p><a href="https://www.centos.bz/2016/12/saltstack-event-reactor/" target="_blank" rel="external">SaltStack事件驱动(4) – event reactor </a></p>
<p><a href="https://groups.google.com/forum/?hl=lt_US&amp;fromgroups#!topic/hadoopors/ekHIDDupnI0" target="_blank" rel="external">namenode datanode 是否有必要做 raid</a></p>
<p><a href="http://blog.51cto.com/1130739/1757208" target="_blank" rel="external">解决PXE批量安装Linux系统时kickstart自动识别硬盘名称的问题</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/12/25/big-data-architeucture/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/25/big-data-architeucture/" itemprop="url">
                  BigData-- 大数据常用开源组件一览
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-25T16:03:10+08:00">
                2017-12-25
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/25/big-data-architeucture/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/12/25/big-data-architeucture/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最近有一个项目是跟公司的大数据平台有关，这里梳理一下常用的大数据组件，做个记录，同时，还有一个原因，就是希望用比较简洁的语言让我女朋友能对大数据的整体架构有个大致了解。<br>大数据平台的架构不一而足，市面上的开源工具非常多，所选用的组件也是因人而异，不过都是为了具体业务应用场景而服务，这里选取一些常用的开源组件,试图从大数据处理的整个流程出发，将各个开源组件的功能特点，适用场景等讲清楚，个人观点，难免纰漏。</p>
<h2 id="大数据处理流程"><a href="#大数据处理流程" class="headerlink" title="大数据处理流程"></a>大数据处理流程</h2><p>在介绍大数据组件之前，先把大数据的整体处理流程梳理一下，因为要想了解整个大数据组件体系，首先得清楚我们要面临的问题，了解了问题才能去找相应的解决方案，如果只是一猛子扎进hadoop 体系里，反而会越看越迷糊。<br>大数据的处理流程大致包括数据收集，数据存储，数据计算与数据分析这四个阶段，其实数据计算与分析算是一个阶段，这里为了以后区分组件的方便将其分开，数据计算可以理解为计算引擎那部分，数据分析就是更上层的BI分析工具等等。接下来就从这四个流程出发，简单介绍下常用工具。</p>
<h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><p>在大数据还未兴盛之前，我们一般是将数据存储到关系型数据库（Mysql等），或者文本文件（日志文件等）中，这种方法在数据量不大的情况下是可以的，但在数据量达到TB，甚至PB级别，这种情况就不适用了。为了能够存储这种量级的数据，大数据存储组件应运而生，这里先暂时不说大数据存储，先说数据收集。出现了大数据存储组件之后，有一个问题就是要将数据收集到大数据存储组件中，于是，相应的组件也就出现了：</p>
<p>以下是收集组件：</p>
<ul>
<li>Sqoop：Sqoop是一个工具，用来在关系型数据库和Hadoop之间传输数据。你可以使用Sqoop来从RDBMS(MySQL or Oracle)导入数据到Hadoop环境里，或者通过MapReduce转换数据，把数据导回到RDBMS。</li>
<li>Flume： Flume 是Cloudera提供的一个高可用的、高可靠的、分布式的海量日志采集、聚合和传输的系统。Flume支持在日志系统中定制各类数据发送方，用于收集数据。同时，Flume支持对数据进行简单处理，并写入各种数据接受方（可定制）。</li>
<li>Logstash：也是一个应用程序日志、事件的传输、处理、管理和搜索的平台。可以用它来统一对应用程序日志进行收集管理，提供了Web接口用于查询和统计。</li>
</ul>
<p>除了收集之外，因为巨大的IO压力，我们通常会在收集组件与数据存储组件之间加一层消息队列用于削峰填谷，降低IO压力，常用的组件包括：</p>
<ul>
<li>Kafka 是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模网站中的所有动作流数据，目前已成为大数据系统在异步和分布式消息之间的最佳选择。</li>
<li>RabbitMQ 是一个受欢迎的消息代理系统，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。RabbitMQ提供可靠的应用消息发送、易于使用、支持所有主流操作系统、支持大量开发者平台。</li>
<li>ActiveMQ 是Apache出品，号称“最流行的，最强大”的开源消息集成模式服务器。ActiveMQ特点是速度快，支持多种跨语言的客户端和协议，其企业集成模式和许多先进的功能易于使用，是一个完全支持JMS1.1和J2EE 1.4规范的JMS Provider实现。</li>
</ul>
<p>MQ组件的对比可以参考阿里中间件团队做的压测<a href="http://jm.taobao.org/2016/03/24/rmq-vs-kafka/" target="_blank" rel="external">RocketMQ与kafka对比（18项差异）</a>,<a href="http://jm.taobao.org/2016/04/01/kafka-vs-rabbitmq-vs-rocketmq-message-send-performance/" target="_blank" rel="external">Kafka、RabbitMQ、RocketMQ消息中间件的对比 —— 消息发送性能</a></p>
<h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><p>数据存储这块分为两个部分，一部分是底层的文件系统，还有一部分就是之上的数据库或数据仓库。</p>
<h4 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h4><p>大数据文件系统其实是大数据平台架构最为基础的组件，其他的组件或多或少都会依赖这个基础组件，</p>
<p>目前应用最为广泛的大数据存储文件系统非Hadoop 的HDFS莫属，除此之外，简单介绍下号称可以取代HDFS的Ceph。</p>
<ul>
<li>HDFS：HDFS是一个高度容错性（多副本，自恢复）的分布式文件系统，能提供高吞吐量的数据访问，非常适合大规模数据集上的访问，不支持低延迟数据访问，不支持多用户写入、任意修改文件。HDFS是Hadoop 大数据工具栈里最基础有也是最重要的一个组件，基于Google的GFS开发。</li>
<li>Ceph：Ceph是一个符合POSIX、开源的分布式存储系统。最早是加州大学圣克鲁兹分校（USSC）博士生 Sage Weil 博士期间的一项有关存储系统的研究项目，Ceph的主要目标是设计成基于POSIX的没有单点故障的分布式文件系统，使数据能容错和无缝的复制。真正让ceph叱咤风云的是开源云计算解决方案Openstack，Openstack+Ceph的方案已被业界广泛使用。 </li>
</ul>
<h4 id="数据库或数据仓库"><a href="#数据库或数据仓库" class="headerlink" title="数据库或数据仓库"></a>数据库或数据仓库</h4><p>针对大数据的数据库大部分是NOSQL数据库，这里顺便澄清一下，NOSQL的真正意义是“ not only sql”，并非NOSQL是RMDB的对立面。</p>
<ul>
<li>Hbase：是一个开源的面向列的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable规模的服务。因此，它可以容错地存储海量稀疏的数据。</li>
<li>MongoDB：一个基于分布式文件存储的数据库，面向文件，旨在为web应用提供可扩展的高性能数据存储解决方案。介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富、最像关系数据库的产品。</li>
<li>Cassandra：是一个混合型的非关系的数据库，类似于Google的BigTable，由Facebook开发。</li>
<li>Neo4j：一个高性能的，NOSQL图形数据库，它将结构化数据存储在网络上而不是表中。</li>
</ul>
<h3 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h3><p>简单介绍以下目前比较流行的几种大数据计算框架：</p>
<ul>
<li>MapReduce：最为知名的当属MapReduce，MapReduce属于一种批处理计算框架，借助于HDFS，基于磁盘进行数据计算，MapReduce的容错能力超强，适合处理巨大规模集群（几百上千个节点）下长时间非实时的大计算任务；但其实时性较差。Hadoop系列的Hive,Pig等数据仓库都是基于MapReduce做的。</li>
<li>Spark：是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性,同时保证了高容错性和高可伸缩性,允许用户将Spark部署在大量的廉价硬件之上,形成集群。Spark是MapReduce的替代方案，而且兼容HDFS等分布式存储层，可融入Hadoop的生态系统，以弥补缺失MapReduce的不足。适合迭代计算（常见于machine learning领域，比如PageRank）和交互式计算（data mining领域，比如SQL查询）。</li>
<li>Storm：典型的流计算系统，会对随时进入系统的数据进行计算,近实时处理需求的任务很适合使用流处理模式,适于处理必须对变动或峰值做出响应，并且关注一段时间内变化趋势的数据，类似框架还有 spark streaming。</li>
</ul>
<p>除了计算框架外，因为是分布式系统，我们还需要对计算资源进行分配调度，以及各种服务间的协调，发现，配置管理等，所以这里又出现了两个重要的组件：</p>
<ul>
<li>Yarn：Hadoop 2.0中推出的非常重要的资源管理框架，负责集群资源管理和调度，MapReduce就是运行在YARN上的离线处理框架。</li>
<li>Zookeeper：是Google的Chubby一个开源的实现，是Apache软件基金会的一个软件项目，他为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。</li>
</ul>
<p>两者的区别是：Yarn是resource management，解决的问题是怎样提高整个集群的资源利用率。Zookeeper是 Coordination，解决的是集群中各种服务的发现，同步，协调配合以保持整个集群的稳定。</p>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>数据分析的工具就更多了，这里列举一些业界用的比较多的，相对成熟的工具：</p>
<ul>
<li>Hive,Pig：两者都是Hadoop开源的分析工具，将这两个工具放在一起的原因是，他们底层都是基于MapReduce实现的，不过Hive是采用SQL的形式调用，而Pig是用脚本的形式，因为SQL的便利易用，Hive已逐渐取代Pig。</li>
<li>Impala： Impala是Cloudera开发的一款用来进行大数据实时查询分析的开源工具，它能够实现通过SQL风格来操作数据，Impala没有再使用缓慢的 Hive+MapReduce批处理，而是通过使用与商用并行关系数据库中类似的分布式查询引擎（由Query Planner、Query Coordinator和Query Exec Engine三部分组成），可以直接从HDFS或HBase中用SELECT、JOIN和统计函数查询数据，从而大大降低了延迟。</li>
<li>Presto：随着数据越来越多，使用Hive进行一个简单的数据查询可能要花费几分到几小时，显然不能满足交互式查询的需求，Facebook开发人员便开发了Presto，Presto依赖于Hive meta，摒弃了MapReduce方法，通过使用分布式查询，可以快速高效的完成海量数据的查询。</li>
<li>Spark：这里又提了Spark是因为Spark的应用越来越广泛，而且Spark 集成了很多机器学习的框架，可以很方便的调用。</li>
<li>Kylin：Apache Kylin是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。</li>
</ul>
<h2 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h2><p>以上是按照数据处理的流程来区分的，这里从网上找到一张由下而上的整体架构：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017-12-27-databricks.jpg" alt="data-bricks"></p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.slideshare.net/welkaim/big-data-architecture-part-1" target="_blank" rel="external">Big data architecture - Introduction</a></p>
<p><a href="https://content.pivotal.io/blog/exploring-big-data-solutions-when-to-use-hadoop-vs-in-memory-vs-mpp" target="_blank" rel="external">Exploring Big Data Solutions: When To Use Hadoop vs In-Memory vs MPP</a></p>
<p><a href="https://www.jianshu.com/p/0e8642e47fd2" target="_blank" rel="external">Hadoop大数据平台架构与实践 | hadoop概述与安装 </a></p>
<p><a href="http://minzhulou.com/74.html" target="_blank" rel="external">大数据领域常用的技术、框架</a></p>
<p><a href="http://www.cnblogs.com/sammyliu/p/4396225.html" target="_blank" rel="external">Hadoop 分布式文件系统 - HDFS</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25757213" target="_blank" rel="external">链家网大数据平台建设，平台枢纽——工具链</a></p>
<p><a href="http://www.10tiao.com/html/157/201608/2653160359/1.html" target="_blank" rel="external">美团大数据平台架构实践 </a></p>
<p><a href="http://blog.csdn.net/u010039929/article/details/70157376" target="_blank" rel="external">大数据开源组件图谱</a></p>
<p><a href="http://www.infoq.com/cn/articles/hadoop-storm-samza-spark-flink" target="_blank" rel="external">大数据框架对比：Hadoop、Storm、Samza、Spark和Flink</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/12/17/achieve-cicd-in-kubernetes-with-jenkins/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/17/achieve-cicd-in-kubernetes-with-jenkins/" itemprop="url">
                  Kuberbetes-- 利用Jenkins在Kubernetes中实践CI/CD
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-17T20:20:11+08:00">
                2017-12-17
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/17/achieve-cicd-in-kubernetes-with-jenkins/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/12/17/achieve-cicd-in-kubernetes-with-jenkins/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文利用jenkins在k8s中简单实践了一下CI/CD，部分实验内容来自<a href="https://www.linux.com/blog/learn/chapter/Intro-to-Kubernetes/2017/5/set-cicd-pipeline-kubernetes-part-1-overview" target="_blank" rel="external">Set Up a CI/CD Pipeline with Kubernetes </a>，除此外，还试验了一把利用jenkins kubernetes plugin实现动态分配资源构建。</p>
<h2 id="在kubernetes中简单实践jenkins"><a href="#在kubernetes中简单实践jenkins" class="headerlink" title="在kubernetes中简单实践jenkins"></a>在kubernetes中简单实践jenkins</h2><p>首先简单介绍下jenkins,jenkins是一个java编写的开源的持续集成工具。具体来说，他可以将软件构建，测试，发布等一系列流程自动化，达到一键部署的目的。在进行本实验前，首先要有一个k8s环境，这里不再赘述。</p>
<h3 id="部署jenkins"><a href="#部署jenkins" class="headerlink" title="部署jenkins"></a>部署jenkins</h3><p>这里存储用的是ceph rbd，所以先创建一个PVC：</p>
<p>jenkins-pvc.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="attr">kind:</span> PersistentVolumeClaim</div><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr"> name:</span> jenkins-pvc</div><div class="line"><span class="attr"> namespace:</span> cicd</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr"> accessModes:</span></div><div class="line"><span class="bullet">    -</span> ReadWriteOnce</div><div class="line"><span class="attr"> resources:</span></div><div class="line"><span class="attr">   requests:</span></div><div class="line"><span class="attr">     storage:</span> <span class="number">20</span>Gi</div><div class="line"><span class="attr"> storageClassName:</span> ceph-web</div></pre></td></tr></table></figure></p>
<p>部署jenkins:</p>
<p>jenkins-deployment.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">kind:</span> Deployment</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> jenkins</div><div class="line"><span class="attr">  namespace:</span> cicd</div><div class="line"><span class="attr">  labels:</span></div><div class="line"><span class="attr">    app:</span> jenkins</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  strategy:</span></div><div class="line"><span class="attr">    type:</span> Recreate</div><div class="line"><span class="attr">  template:</span></div><div class="line"><span class="attr">    metadata:</span></div><div class="line"><span class="attr">      labels:</span></div><div class="line"><span class="attr">        app:</span> jenkins</div><div class="line"><span class="attr">        tier:</span> jenkins</div><div class="line"><span class="attr">    spec:</span></div><div class="line"><span class="attr">      containers:</span></div><div class="line"><span class="attr">      - image:</span> chadmoon/jenkins-docker-kubectl:latest</div><div class="line"><span class="attr">        name:</span> jenkins</div><div class="line"><span class="attr">        securityContext:</span></div><div class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></div><div class="line"><span class="attr">        ports:</span></div><div class="line"><span class="attr">        - containerPort:</span> <span class="number">8080</span></div><div class="line"><span class="attr">          name:</span> jenkins</div><div class="line"><span class="attr">        - containerPort:</span> <span class="number">50000</span></div><div class="line"><span class="attr">          name:</span> agent</div><div class="line"><span class="attr">          protocol:</span> TCP</div><div class="line"><span class="attr">        volumeMounts:</span></div><div class="line"><span class="attr">        - name:</span> docker</div><div class="line"><span class="attr">          mountPath:</span> /var/run/docker.sock</div><div class="line"><span class="attr">        - name:</span> jenkins-persistent-storage</div><div class="line"><span class="attr">          mountPath:</span> /root/.jenkins</div><div class="line"><span class="attr">        - name:</span> kube-config</div><div class="line"><span class="attr">          mountPath:</span> /root/.kube/config</div><div class="line"><span class="attr">        - name:</span> image-registry</div><div class="line"><span class="attr">          mountPath:</span> /root/.docker</div><div class="line"><span class="attr">      volumes:</span></div><div class="line"><span class="attr">      - name:</span> docker</div><div class="line"><span class="attr">        hostPath:</span></div><div class="line"><span class="attr">          path:</span> /var/run/docker.sock</div><div class="line"><span class="attr">      - name:</span> jenkins-persistent-storage</div><div class="line"><span class="attr">        persistentVolumeClaim:</span></div><div class="line"><span class="attr">          claimName:</span> jenkins-pvc</div><div class="line"><span class="attr">      - name:</span> kube-config</div><div class="line"><span class="attr">        hostPath:</span></div><div class="line"><span class="attr">          path:</span> /root/.kube/config</div><div class="line"><span class="attr">      - name:</span> image-registry</div><div class="line"><span class="attr">        configMap:</span></div><div class="line"><span class="attr">          name:</span> image-registry-auth</div></pre></td></tr></table></figure></p>
<p>简单解释一下：</p>
<ul>
<li>该镜像除了安装jenkins，还装了docker cli（与host docker daemon交互），kubectl（与k8s apiserver交互）</li>
<li>容器开了两个端口，一个用于web-ui,一个用于后面实验jenkins kubernetes plugin时与JNLP slave agents 交互。</li>
<li>挂载了四个volume，依次是，一个用于docker cli，一个用于存储jenkins数据，一个用于kubectl与k8s交互验证，最后挂载了一个configmap，与image registry（我们用的harbor）交互验证。 </li>
</ul>
<p>部署jenkins service &amp; ingress:</p>
<p>jenkins-service-ingress.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">kind:</span> Service</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> jenkins-web-ui</div><div class="line"><span class="attr">  namespace:</span> cicd</div><div class="line"><span class="attr">  labels:</span></div><div class="line"><span class="attr">    app:</span> jenkins</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  ports:</span></div><div class="line"><span class="attr">    - port:</span> <span class="number">80</span></div><div class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></div><div class="line"><span class="attr">      name:</span> web-ui</div><div class="line"><span class="attr">    - port:</span> <span class="number">50000</span></div><div class="line"><span class="attr">      targetPort:</span> <span class="number">50000</span></div><div class="line"><span class="attr">      name:</span> agent</div><div class="line"><span class="attr">  selector:</span></div><div class="line"><span class="attr">    app:</span> jenkins</div><div class="line"><span class="attr">    tier:</span> jenkins</div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">kind:</span> Ingress</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> jenkins-web-ui</div><div class="line"><span class="attr">  namespace:</span> cicd</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  rules:</span></div><div class="line"><span class="attr">  - host:</span> jenkins.com</div><div class="line"><span class="attr">    http:</span></div><div class="line"><span class="attr">      paths:</span></div><div class="line"><span class="attr">      - backend:</span></div><div class="line"><span class="attr">          serviceName:</span> jenkins-web-ui</div><div class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></div></pre></td></tr></table></figure></p>
<p>完成上述所有操作后，查看一下对应的pod 是否running。</p>
<h3 id="配置pipeline"><a href="#配置pipeline" class="headerlink" title="配置pipeline"></a>配置pipeline</h3><p>按照ingress的配置，修改本地host，然后浏览器中输入<a href="http://jenkins.com" target="_blank" rel="external">http://jenkins.com</a> ，就进入到jenkins 的web-ui了。</p>
<p>按照提示创建完用户后，开始进入CICD 的实验环节：</p>
<p>新建一个item，命名并选中pipeline:</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218184207-new-item.jpg" alt="new-item"></p>
<p>pipeline 配置如下：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/2017121818480-pipeline.jpg" alt="pipeline"></p>
<p>在Git Repository URL部分添加github url,这里用的是<a href="https://github.com/zhangchenchen/kubernetes-ci-cd" target="_blank" rel="external">我的github-test-kubernetes-ci-cd</a>，是直接fork自<a href="https://github.com/kenzanlabs/kubernetes-ci-cd" target="_blank" rel="external">kubernetes-ci-cd</a>，并做了一些更改,之后保存就可以了。<br>进入刚创建的item，点击立即构建：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218185344-build.jpg" alt="build"></p>
<p>之后就可以看到构建信息了，如果出错也可以查看对应步骤的log。<br>同时，我们的应用也已经部署到k8s中了。<br><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218190117-test-jenkins.jpg" alt="test-jenkins"></p>
<h3 id="步骤详解"><a href="#步骤详解" class="headerlink" title="步骤详解"></a>步骤详解</h3><p>接下来看一下点击“立即构建”后发生了什么，点击后，jenkins首先是从github检出项目代码，然后根据检出的项目中根目录下的Jenkinsfile进行项目构建，看下该项目的Jenkinsfile。<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">node &#123;</div><div class="line"></div><div class="line">    checkout scm</div><div class="line"></div><div class="line">    env.DOCKER_API_VERSION=<span class="string">"1.23"</span></div><div class="line">    </div><div class="line">    sh <span class="string">"git rev-parse --short HEAD &gt; commit-id"</span></div><div class="line"></div><div class="line">    tag = readFile(<span class="string">'commit-id'</span>).replace(<span class="string">"\n"</span>, <span class="string">""</span>).replace(<span class="string">"\r"</span>, <span class="string">""</span>)</div><div class="line">    appName = <span class="string">"hello-kenzan"</span></div><div class="line">    registryHost = <span class="string">"172.16.21.253:10080/library/"</span></div><div class="line">    imageName = <span class="string">"$&#123;registryHost&#125;$&#123;appName&#125;:$&#123;tag&#125;"</span></div><div class="line">    env.BUILDIMG=imageName</div><div class="line"></div><div class="line">    stage <span class="string">"Build"</span></div><div class="line">    </div><div class="line">        sh <span class="string">"docker build -t $&#123;imageName&#125; -f applications/hello-kenzan/Dockerfile applications/hello-kenzan"</span></div><div class="line">    </div><div class="line">    stage <span class="string">"Push"</span></div><div class="line"></div><div class="line">        sh <span class="string">"docker push $&#123;imageName&#125;"</span></div><div class="line"></div><div class="line">    stage <span class="string">"Deploy"</span></div><div class="line"></div><div class="line">        sh <span class="string">"sed 's#127.0.0.1:30400/hello-kenzan:latest#'$BUILDIMG'#' applications/hello-kenzan/k8s/deployment.yaml | kubectl apply -f -"</span></div><div class="line">        sh <span class="string">"kubectl rollout status deployment/hello-kenzan"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以看到，Jenkinsfile定义了三个阶段，第一个阶段是“Build”,这个阶段是根据给定的Dockerfile创建一个镜像，第二个阶段“Push”,把生成的镜像push到我们的镜像仓库中，最后一个阶段是”Deploy”，编辑了一下deployment.yaml模板，然后调用kubectl命令进行部署。<br>看一下“Build”阶段的dockerfile:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">FROM nginx:latest</div><div class="line"></div><div class="line">COPY index.html /usr/share/nginx/html/index.html</div><div class="line">COPY DockerFileEx.jpg /usr/share/nginx/html/DockerFileEx.jpg</div><div class="line"></div><div class="line">EXPOSE <span class="number">80</span></div></pre></td></tr></table></figure></p>
<p>就是一个很简单的nginx应用。<br>再看下deployment.yaml：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">kind:</span> Service</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> hello-kenzan</div><div class="line"><span class="attr">  labels:</span></div><div class="line"><span class="attr">    app:</span> hello-kenzan</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  ports:</span></div><div class="line"><span class="attr">    - port:</span> <span class="number">80</span></div><div class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></div><div class="line"><span class="attr">  selector:</span></div><div class="line"><span class="attr">    app:</span> hello-kenzan</div><div class="line"><span class="attr">    tier:</span> hello-kenzan</div><div class="line"><span class="attr">  type:</span> NodePort</div><div class="line"></div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">kind:</span> Deployment</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> hello-kenzan</div><div class="line"><span class="attr">  labels:</span></div><div class="line"><span class="attr">    app:</span> hello-kenzan</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  strategy:</span></div><div class="line"><span class="attr">    type:</span> Recreate</div><div class="line"><span class="attr">  template:</span></div><div class="line"><span class="attr">    metadata:</span></div><div class="line"><span class="attr">      labels:</span></div><div class="line"><span class="attr">        app:</span> hello-kenzan</div><div class="line"><span class="attr">        tier:</span> hello-kenzan</div><div class="line"><span class="attr">    spec:</span></div><div class="line"><span class="attr">      containers:</span></div><div class="line"><span class="attr">      - image:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">30400</span>/hello-kenzan:latest</div><div class="line"><span class="attr">        name:</span> hello-kenzan</div><div class="line"><span class="attr">        ports:</span></div><div class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></div><div class="line"><span class="attr">          name:</span> hello-kenzan</div></pre></td></tr></table></figure></p>
<p>这里服务发现使用的nodeport，可以改为其他方式（比如ingress）。</p>
<p>接下来，可以试着修改一下index.html，然后push到github中，再构建一下，看看内容是否改变。</p>
<h2 id="利用jenkins-kubernetes-plugin实现动态分配资源构建"><a href="#利用jenkins-kubernetes-plugin实现动态分配资源构建" class="headerlink" title="利用jenkins kubernetes plugin实现动态分配资源构建"></a>利用jenkins kubernetes plugin实现动态分配资源构建</h2><p>在上述实例中，我们利用jenkins实现了一个小应用的CI/CD，这个小应用非常简单，“build”阶段就是直接在本地调用host docker构建的镜像，设想一下，如果这个应用需要编译，需要测试，那么这个时间就长了，而且如果都在本地构建的话，一个人使用还好，如果多个人一起构建，就会造成拥塞。<br>为了解决上述问题，我们可以充分利用k8s的容器编排功能，jenkins接收到任务后，调用k8s api，创造新的 agent pod，将任务分发给这些agent pod，agent pod执行任务，任务完成后将结果汇总给jenkins pod，同时删除完成任务的agent pod。<br>为了实现上述功能，我们需要给jenkins安装一个插件，叫做<a href="https://github.com/carlossg/jenkins-kubernetes-plugin" target="_blank" rel="external">jenkins kubernetes plugin</a>。</p>
<h3 id="插件安装与配置"><a href="#插件安装与配置" class="headerlink" title="插件安装与配置"></a>插件安装与配置</h3><p>安装比较简单，直接到jenkins 界面的系统管理，插件管理界面进行安装就可以了。<br>安装好之后，进入系统管理—–&gt;系统设置，最下面有一个“云”，选择“新增一个云”—-&gt;kubernetes。</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218194329-jenkins-k8s.jpg" alt="jenkins-k8s"><br>这里没有配置k8s，因为如果不配置api-server的话，jenkins会默认使用~/.kube/config下的配置，而我们已经在~/.kube/config做过配置了，所以这里就不做了。Jenkins URL我们使用的是集群内的服务地址。<br>再往下看 kubernetes pod template配置：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218195151jenkins-pod-template.jpg" alt="jenkins-pod-template"></p>
<p>这个pod tempalte就是之后我们创建 agent使用的模板，镜像使用“jenkins/jnlp-slave:alpine”，配置完成后，点击保存。<br>然后还要配置一下agent与jenkins通信的端口，在系统管理—-&gt;Configure Global Security，指定端口为我们之前设定的5000端口：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218195724-jenkins-port.jpg" alt="jenkins-port"></p>
<h3 id="简单测试"><a href="#简单测试" class="headerlink" title="简单测试"></a>简单测试</h3><p>配置完成后做一个简单的测试。</p>
<p>新建一个item，这里选择“构建一个自由风格的软件项目”：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218200215test-jnlp.jpg" alt="test-jnlp"></p>
<p>配置时注意在General部分有一个restrict：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218200511-general.jpg" alt="jenkins-general"><br>Label Expression就写之前我们k8s podtemplate 的label。</p>
<p>在构建部分我们写一个简单的测试命令：echo TRUE</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218200831-jenkins-build.jpg" alt="jenkins-build"></p>
<p>点击立即构建，如果成功的话，我们在“管理主机”模块会看到新增了一个主机：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218162939-multi-host.jpg" alt="add-host"><br>同时，也会在k8s中发现新创建了一个名为jnlp-slave-8bq5m的pod。<br>任务结束后，pod删除，主机消失，在console output 会看到执行结果：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171218201618-console-output.jpg" alt="console-optput"></p>
<h2 id="出现问题总结"><a href="#出现问题总结" class="headerlink" title="出现问题总结"></a>出现问题总结</h2><h3 id="jnlp-slave-pod创建失败"><a href="#jnlp-slave-pod创建失败" class="headerlink" title="jnlp-slave pod创建失败"></a>jnlp-slave pod创建失败</h3><p>查看pod日志，发现是连接不上jenkins ，通过修改Configure Global Security的启用安全，TCP port for JNLP agents<br>指定端口解决。</p>
<h3 id="jnlp-slave-pod-无法删除"><a href="#jnlp-slave-pod-无法删除" class="headerlink" title="jnlp-slave pod 无法删除"></a>jnlp-slave pod 无法删除</h3><p>因为我们执行构建后，如果 jnlp-slave pod创建失败，它会不断的尝试创建新的pod，并试图连接jenkins，一段时间后，就会创造很多失败的jnlp-slave pod。如果遇到这种情况，需要尽早中断任务并删除失败的pod。<br>在删除某个pod时 ，该pod一直处于termating阶段，kubectl delete无法删除。后来参考<a href="https://stackoverflow.com/questions/35453792/pods-stuck-at-terminated-status" target="_blank" rel="external">Pods stuck at terminated status</a>，使用如下命令解决：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl delete pod NAME --grace-period=0 --force</div></pre></td></tr></table></figure></p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.linux.com/blog/learn/chapter/Intro-to-Kubernetes/2017/6/set-cicd-pipeline-jenkins-pod-kubernetes-part-2" target="_blank" rel="external">Set Up a CI/CD Pipeline with a Jenkins Pod in Kubernetes </a></p>
<p><a href="http://blog.sonatype.com/achieving-ci/cd-with-kubernetes" target="_blank" rel="external">Achieving CI/CD with Kubernetes</a></p>
<p><a href="http://blog.csdn.net/WaltonWang/article/details/73477812" target="_blank" rel="external">容器时代CI/CD平台中的Kubernetes调度器定制方法</a></p>
<p><a href="https://www.w3cschool.cn/jenkins/jenkins-qc8a28op.html" target="_blank" rel="external">Jenkinsfile使用</a></p>
<p><a href="http://kubernetes.kansea.com/docs/user-guide/prereqs/" target="_blank" rel="external">安装和设置 kubectl</a></p>
<p><a href="https://github.com/jenkinsci/kubernetes-plugin" target="_blank" rel="external">jenkins-kubernetes-plugin</a></p>
<p><a href="http://www.cnblogs.com/hahp/p/5812455.html" target="_blank" rel="external">基于Kubernetes 部署 jenkins 并动态分配资源</a></p>
<p><a href="https://www.kubernetes.org.cn/1791.html" target="_blank" rel="external">使用Kubernetes-Jenkins实现CI/CD</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/12/15/kubernetes-ingress-intro/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/15/kubernetes-ingress-intro/" itemprop="url">
                  Kuberbetes-- kubernetes ingress 实践
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-15T19:08:12+08:00">
                2017-12-15
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/15/kubernetes-ingress-intro/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/12/15/kubernetes-ingress-intro/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>k8s集群暴露内部服务有多种方式：</p>
<ul>
<li>Nodeport Service: 通过host port做端口映射，由kube-proxy实现。</li>
<li>LoadBalancer Service: 利用云平台提供的LoadBalancer服务，也是由kube-proxy实现。</li>
<li>Ingress: k8s1.2版本新增功能，由反向代理负载均衡器，Ingress Controller，ingress配置共同实现。</li>
<li>Port Proxy: 起一个pod专门做端口转发，可以将pod/host port 转发给k8s service，参考<a href="https://github.com/kubernetes/contrib/tree/master/for-demos/proxy-to-service" target="_blank" rel="external">Proxy a pod port or host port to a kubernetes Service</a></li>
<li>Service loadbalancer: 在物理机上部署一套Service loadbalancer，参考<a href="https://github.com/kubernetes/contrib/tree/master/service-loadbalancer" target="_blank" rel="external">Bare Metal Service Load Balancers</a></li>
</ul>
<p>其中，后两种方法因为相对比较复杂，逐渐被遗弃。目前用的比较多的就是前三种,LoadBalancer Service需要云服务的参与，NodePort 方式在集群内服务数量可控的情况下可以使用，当服务数量增多时需要注意端口管理，防止端口冲突。Ingress方式需要我们自行部署ingress controller服务，本篇文章详述一下Ingress方式。</p>
<h2 id="Ingress-原理"><a href="#Ingress-原理" class="headerlink" title="Ingress 原理"></a>Ingress 原理</h2><p>在讲Ingres实现原理时，我们可以从NodePort入手，NodePort最大的弊端就是端口多了之后难以管理，我们自然而然的就会想到利用反向代理工具（比如 nginx）只监听host上一个端口，然后再根据请求的域名转发给集群内部服务，这就要求这个nginx能够转发到集群内部，这个简单，我们直接将nginx部署到集群内部就可以了。<br>接下来的问题就是如何配置nginx了，这就要借助k8s中的ingress了，ingress实际上就是一个yaml文件，真正执行配置nginx的是叫做ingress controller的程序，它会调用k8s 的api，获取ingress，然后根据这个yaml文件生成nginx 配置模板，写入nginx。除此之外，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的目的。</p>
<p>贴一张图，图片来自<a href="https://mritd.me/2016/12/06/try-traefik-on-kubernetes/#13ingress" target="_blank" rel="external">这里</a></p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171214-ingress-arch.jpg" alt="ingress-arch"></p>
<h2 id="Ingress-实践"><a href="#Ingress-实践" class="headerlink" title="Ingress 实践"></a>Ingress 实践</h2><p>ingress包括反向代理负载均衡器，Ingress Controller，ingress三部分，通常反向代理负载均衡器与Ingress Controller会部署到同一个pod中，一个负责反向代理，一个负责与k8s交互并更新配置。不过随着微服务的流行，有人将这两个功能合在了一块，就是traefik。这样，大致结构就是这样：</p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171214traffic.jpg" alt="traffic"></p>
<p>接下来开始部署：</p>
<p>因为有RBAC，所以先部署相应角色：<br>traefik-rbac.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">kind:</span> ClusterRole</div><div class="line"><span class="attr">apiVersion:</span> rbac.authorization.k8s.io/v1beta1</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">rules:</span></div><div class="line"><span class="attr">  - apiGroups:</span></div><div class="line"><span class="bullet">      -</span> <span class="string">""</span></div><div class="line"><span class="attr">    resources:</span></div><div class="line"><span class="bullet">      -</span> services</div><div class="line"><span class="bullet">      -</span> endpoints</div><div class="line"><span class="bullet">      -</span> secrets</div><div class="line"><span class="attr">    verbs:</span></div><div class="line"><span class="bullet">      -</span> get</div><div class="line"><span class="bullet">      -</span> list</div><div class="line"><span class="bullet">      -</span> watch</div><div class="line"><span class="attr">  - apiGroups:</span></div><div class="line"><span class="bullet">      -</span> extensions</div><div class="line"><span class="attr">    resources:</span></div><div class="line"><span class="bullet">      -</span> ingresses</div><div class="line"><span class="attr">    verbs:</span></div><div class="line"><span class="bullet">      -</span> get</div><div class="line"><span class="bullet">      -</span> list</div><div class="line"><span class="bullet">      -</span> watch</div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">kind:</span> ClusterRoleBinding</div><div class="line"><span class="attr">apiVersion:</span> rbac.authorization.k8s.io/v1beta1</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">roleRef:</span></div><div class="line"><span class="attr">  apiGroup:</span> rbac.authorization.k8s.io</div><div class="line"><span class="attr">  kind:</span> ClusterRole</div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">subjects:</span></div><div class="line"><span class="attr">- kind:</span> ServiceAccount</div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">  namespace:</span> kube-system</div></pre></td></tr></table></figure></p>
<p>接下来开始部署traefik(可以使用deployment或DaemonSet):</p>
<p>traefik-daemonset.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">kind:</span> ServiceAccount</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">  namespace:</span> kube-system</div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">kind:</span> DaemonSet</div><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-ingress-controller</div><div class="line"><span class="attr">  namespace:</span> kube-system</div><div class="line"><span class="attr">  labels:</span></div><div class="line"><span class="attr">    k8s-app:</span> traefik-ingress-lb</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  template:</span></div><div class="line"><span class="attr">    metadata:</span></div><div class="line"><span class="attr">      labels:</span></div><div class="line"><span class="attr">        k8s-app:</span> traefik-ingress-lb</div><div class="line"><span class="attr">        name:</span> traefik-ingress-lb</div><div class="line"><span class="attr">    spec:</span></div><div class="line"><span class="attr">      serviceAccountName:</span> traefik-ingress-controller</div><div class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">60</span></div><div class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></div><div class="line"><span class="attr">      containers:</span></div><div class="line"><span class="attr">      - image:</span> traefik</div><div class="line"><span class="attr">        name:</span> traefik-ingress-lb</div><div class="line"><span class="attr">        ports:</span></div><div class="line"><span class="attr">        - name:</span> http</div><div class="line"><span class="attr">          containerPort:</span> <span class="number">80</span></div><div class="line"><span class="attr">          hostPort:</span> <span class="number">80</span></div><div class="line"><span class="attr">        - name:</span> admin</div><div class="line"><span class="attr">          containerPort:</span> <span class="number">8080</span></div><div class="line"><span class="attr">        securityContext:</span></div><div class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></div><div class="line"><span class="attr">        args:</span></div><div class="line"><span class="bullet">        -</span> -d</div><div class="line"><span class="bullet">        -</span> --web</div><div class="line"><span class="bullet">        -</span> --kubernetes</div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">kind:</span> Service</div><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-ingress-service</div><div class="line"><span class="attr">  namespace:</span> kube-system</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  selector:</span></div><div class="line"><span class="attr">    k8s-app:</span> traefik-ingress-lb</div><div class="line"><span class="attr">  ports:</span></div><div class="line"><span class="attr">    - protocol:</span> TCP</div><div class="line"><span class="attr">      port:</span> <span class="number">80</span></div><div class="line"><span class="attr">      name:</span> web</div><div class="line"><span class="attr">    - protocol:</span> TCP</div><div class="line"><span class="attr">      port:</span> <span class="number">8080</span></div><div class="line"><span class="attr">      name:</span> admin</div><div class="line"><span class="attr">  type:</span> NodePort</div></pre></td></tr></table></figure></p>
<p>创建一个ingress，将traffik的web ui 暴露出来：</p>
<p>traefik-ingress.yaml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="attr">apiVersion:</span> v1</div><div class="line"><span class="attr">kind:</span> Service</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-web-ui</div><div class="line"><span class="attr">  namespace:</span> kube-system</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  selector:</span></div><div class="line"><span class="attr">    k8s-app:</span> traefik-ingress-lb</div><div class="line"><span class="attr">  ports:</span></div><div class="line"><span class="attr">  - port:</span> <span class="number">80</span></div><div class="line"><span class="attr">    targetPort:</span> <span class="number">8080</span></div><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">kind:</span> Ingress</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> traefik-web-ui</div><div class="line"><span class="attr">  namespace:</span> kube-system</div><div class="line"><span class="attr">  annotations:</span></div><div class="line">    kubernetes.io/ingress.class: traefik</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  rules:</span></div><div class="line"><span class="attr">  - host:</span> traefik-ui.minikube</div><div class="line"><span class="attr">    http:</span></div><div class="line"><span class="attr">      paths:</span></div><div class="line"><span class="attr">      - backend:</span></div><div class="line"><span class="attr">          serviceName:</span> traefik-web-ui</div><div class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></div></pre></td></tr></table></figure></p>
<p>Ingress spec 中包含配置一个loadbalancer或proxy server的所有信息。最重要的是，它包含了一个匹配所有入站请求的规则列表。目前ingress只支持http规则。每条http规则包含以下信息：一个host配置项（比如traefik-ui.minikube，默认是*），path列表（比如：/testpath，默认是:/），每个path都关联一个backend(比如traefik-web-ui:80)。在loadbalancer将流量转发到backend之前，所有的入站请求都要先匹配host和path。<br>如果没有rules，可以指定一个默认backend（例如404 page）。</p>
<p>部署完成，修改本地host，将traefik-ui.minikube 指向host ip。浏览器中输入<a href="http://traefik-ui.minikube/dashboard/#/即可：" target="_blank" rel="external">http://traefik-ui.minikube/dashboard/#/即可：</a></p>
<p><img src="http://7xrnwq.com1.z0.glb.clouddn.com/20171214-traffic-web-ui.jpg" alt="traffic-web-ui"></p>
<p>生产环境中可以利用dns再做一层负载均衡。</p>
<p>如果需要部署 https，可以参考<a href="https://medium.com/@patrickeasters/using-traefik-with-tls-on-kubernetes-cb67fb43a948" target="_blank" rel="external">Using Traefik with TLS on Kubernete</a></p>
<p>最后贴一个trouble shooting 的案例<a href="http://blog.wercker.com/troubleshooting-ingress-kubernetes" target="_blank" rel="external">Kubernetes: troubleshooting ingress and services traffic flows</a></p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="external">Ingress</a></p>
<p><a href="https://docs.traefik.io/user-guide/kubernetes/" target="_blank" rel="external">Kubernetes Ingress Controller</a></p>
<p><a href="http://blog.wercker.com/troubleshooting-ingress-kubernetes" target="_blank" rel="external">Kubernetes: troubleshooting ingress and services traffic flows</a></p>
<p><a href="https://mritd.me/2016/12/06/try-traefik-on-kubernetes/" target="_blank" rel="external">Traefik-kubernetes 初试</a></p>
<p><a href="https://mritd.me/2017/03/04/how-to-use-nginx-ingress/" target="_blank" rel="external">Kubernetes Nginx Ingress 教程</a></p>
<p><a href="https://www.kubernetes.org.cn/1885.html" target="_blank" rel="external">Kubernetes Ingress解析</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhangchenchen.github.io/2017/12/14/kubernetes-network-summary-2/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="pekingzcc">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Solar">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Solar" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/14/kubernetes-network-summary-2/" itemprop="url">
                  Kuberbetes-- kubernetes网络方案总结（二）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-14T14:00:11+08:00">
                2017-12-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/14/kubernetes-network-summary-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/12/14/kubernetes-network-summary-2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>上篇文章对k8s的几种网络方案做了详细对比，本篇文章主要探究下两种典型的网络方案flannel和calico。</p>
<h2 id="flannel"><a href="#flannel" class="headerlink" title="flannel"></a>flannel</h2><p>flannel是coreos为k8s设计的一个非常简洁的多节点3层容器网络互联方案。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>flannel 旨在解决不同host上的容器网络互联问题，大致原理是每个 host 分配一个 subnet，容器从此 subnet 中分配 IP，这些 IP 可以在 host 间路由，容器间无需 NAT 和 port mapping 就可以跨主机通信。每个 subnet 都是从一个更大的 IP 池中划分的，flannel 会在每个主机上运行一个叫 flanneld 的 agent，其职责就是从池子中分配 subnet。为了在各个主机间共享信息，flannel 用 etcd（如果是k8s集群会直接调用k8s api）存放网络配置、已分配的 subnet、host 的 IP 等信息。节点间的通信有以下多种backen支持。</p>
<ul>
<li>VXLAN：推荐配置，利用内核级别的VXLAN来封装host之间传送的包。</li>
<li>host-gw：对于性能有要求的推荐配置，但是不支持云环境。通过在host的路由表中直接创建到其他主机 subnet 的路由条目，从而实现容器跨主机通信。要求所有host在二层互联。</li>
<li>udp：默认模式，通常用于debug，或以上两种条件都不具备。</li>
</ul>
<p>找了一张有容云博客中的图：</p>
<p><img src="http://oeptotikb.bkt.clouddn.com/20171212140335-flannel.jpg" alt="flannel"></p>
<p>图中backend是用udp作为示例，我们可以换成其他任意两种，原理类似。</p>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>在docker 中的实践可以参考<a href="http://www.cnblogs.com/CloudMan6/p/7424858.html" target="_blank" rel="external">安装配置 flannel - 每天5分钟玩转 Docker 容器技术（59）</a>系列文章。</p>
<p>在k8s中，如果是使用kubeadm安装k8s集群的话，可以参考<a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md" target="_blank" rel="external">kubeadm</a>,其实最主要的就是<a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml" target="_blank" rel="external">这个文件</a>，默认是vxlan，博主之前安装就是用的vxlan,就不重复操作了，大致解释下yaml文件中的内容：</p>
<ul>
<li>创建对应clusterrole,clusterrolebinding。</li>
<li>创建一个flannel service account。</li>
<li>创建一个configmap用作cni和flannel的配置。其中flannel的network 要与之前kubeadm安装k8s时的pod network CIDR符合，默认backend是vxlan，可以改成其他的。</li>
<li>创建flannel daemonset在每台host上起一个pod，每个pod有两个容器，一个跑flanneld 程序，另一个initcontainer部署一些cni配置以便kubelet可以读取。</li>
</ul>
<h2 id="calico"><a href="#calico" class="headerlink" title="calico"></a>calico</h2><p>相对于flannel的小而美，calico是一个比较完整的项目，官网的title是“Secure networking for the cloud native era”，可见calico是专为云环境设置，且比较注重安全性，也就是网络隔离，ACL控制等都是可以实现的。列一下官网中的feature:</p>
<ul>
<li>可扩展，分布式的控制组件</li>
<li>基于可配置policy的网络安全</li>
<li>无需overlay</li>
<li>可以集成所有的云平台（From Kubernetes to OpenStack, AWS to GCE）</li>
<li>经过生产环境认证。</li>
</ul>
<h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>calico是一个纯三层的数据中心网络方案，实现类似于flannel host-gw,不过它没有复用docker 的docker0 bridge，而是自己实现的。<br>Calico在每一个计算节点利用Linux Kernel实现了一个高效的vRouter来负责数据转发，而每个vRouter通过BGP协议负责把自己上运行的workload的路由信息像整个Calico网络内传播——小规模部署可以直接互联，大规模下可通过指定的BGP route reflector来完成。<br>Calico基于iptables还提供了丰富而灵活的网络Policy，保证通过各个节点上的ACLs来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。<br>对于有IP限制的host，也可以使用calico的IPIP方案（overlay方式）。</p>
<p>calico 的架构：<br><img src="http://oeptotikb.bkt.clouddn.com/20171212-calico-arch.jpg" alt="calico-arch"></p>
<p>具体通信流程可以结合实践，参考<a href="http://www.cnblogs.com/CloudMan6/p/7509975.html" target="_blank" rel="external">如何部署 Calico 网络？- 每天5分钟玩转 Docker 容器技术（67）</a></p>
<h3 id="实践-1"><a href="#实践-1" class="headerlink" title="实践"></a>实践</h3><p>在docker上的实践参考<a href="https://docs.projectcalico.org/v2.6/getting-started/docker/" target="_blank" rel="external">Calico with Docker</a>,嫌麻烦直接看<a href="http://www.cnblogs.com/CloudMan6/p/7509975.html" target="_blank" rel="external">如何部署 Calico 网络？- 每天5分钟玩转 Docker 容器技术（67）</a></p>
<p>在k8s上的部署可以参考<a href="https://docs.projectcalico.org/v1.5/getting-started/kubernetes/installation/#kubernetes-hosted-installation" target="_blank" rel="external">Adding Calico to an Existing Kubernetes Cluster</a></p>
<p>tips: calico 可以通过profile 来实现ACL控制，结合k8s的NetworkPolicy可以实现租户网络隔离,这对公有云还是很有必要的，参考<a href="https://zhuanlan.zhihu.com/p/26614324" target="_blank" rel="external">容器编排之Kubernetes多租户网络隔离</a>。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md" target="_blank" rel="external">coreos/flannel</a></p>
<p><a href="https://www.projectcalico.org/#getstarted" target="_blank" rel="external">calico</a></p>
<p><a href="http://www.youruncloud.com/blog/131.html" target="_blank" rel="external">Kubernetes网络原理及方案</a></p>
<p><a href="http://www.cnblogs.com/CloudMan6/p/7424858.html" target="_blank" rel="external">安装配置 flannel - 每天5分钟玩转 Docker 容器技术（59）</a></p>
<p><a href="http://blog.shurenyun.com/shurenyun-docker-133/" target="_blank" rel="external">最新实践 | 将Docker网络方案进行到底</a></p>
<p><strong><em>本篇文章由<a href="https://zhangchenchen.github.io/">pekingzcc</a>采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可,转载请注明。</em></strong></p>
<p> <strong><em>END</em></strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="pekingzcc" />
          <p class="site-author-name" itemprop="name">pekingzcc</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">95</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">42</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zhangchenchen" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">pekingzcc</span>
</div>


<div class="powered-by">
  powered by <a class="theme-link" href="https://hexo.io">Hexo</a> 
</div>

<div class="theme-info">
  theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user" ></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'pekingzcc';
      var disqus_identifier = 'index.html';

      var disqus_title = "";


      function run_disqus_script(disqus_script) {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');

      

    </script>
  









  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


</body>
</html>
